@THESIS{Quaeghebeur-MA01b,
  ABSTRACT    = {We bestuderen een leermethode voor eindige spelen in de strategische vorm. Hierbij maken de spelers gebruik van een geschiedenis van reeds gespeelde sessies om inschattingen te maken over de waarschijnlijke strategiekeuze van een tegenspeler. Op die waarschijnlijk geachte strategiekeuze baseren de spelers zich om een eigen strategie te kiezen. We bestuderen hiervoor eerst de wetenschapsdiscipline genaamd speltheorie. We gaan hier in op kenmerkende elementen van spelen en bekijken mogelijke voorstellingswijzen. We gaan dieper in op de voorstelling van een spel in de strategische vorm. Een strategie, een geheel aan regels die de keuze van acties binnen een spel volledig bepalen, en de opbrengstfunctie, die de uitslag van een spel voor de speler vastlegt, worden gedefinieerd. We bekijken hoe we de strategieën van een spel kunnen onderverdelen en welke strategieën optimaal zijn voor een speler. Zo komen we tot volgende concepten: beste antwoord, wat de verzameling van strategieën is die de opbrengst van de speler maximaliseert voor een gegeven strategie van zijn tegenspeler; evenwicht, wat een strategiecombinatie is waar geen enkele speler er voordeel bij heeft om van strategie te veranderen; dominantie, wat een methode is om strategieën te identificeren die het best niet gespeeld worden en maximin-strategie, wat een voorzichtige strategiekeuze is. In tweede instantie bespreken we imprecieze waarschijnlijkheden, wat een onzekerheidsmodel is waar niet alleen rekening kan worden gehouden met onzekerheid, maar ook met onbepaaldheid. We gaan in op de gevolgen van rationaliteitvereisten voor dit model en zijn rekenregels. Er wordt tevens een interpretatie op basis van gokgedrag gegeven aan de grootheden die we gebruiken om waarschijnlijkheden uit te drukken. Voortbouwend op het voorgaande wordt onderzocht hoe we een beslissing kunnen maken tussen keuzes voor verschillende mogelijke strategieën. Dit leidt tot de definitie van maximale strategieën, die goede keuzes zijn voor een speler. Deze beslissingen worden gebaseerd op het Dirichletmodel, dat inschattingen weergeeft over de strategiekeuze van een tegenspeler. We leggen ook uit hoe dit model bijgesteld kan worden door verrekening van de informatie bekomen uit reeds gespeelde sessies. Door het voorgaande te combineren kunnen we de beoogde leermethode formuleren. We maken hier een onderscheid tussen een precieze methode, waarbij er geen rekening wordt gehouden met eventuele onbepaaldheid en twee imprecieze methodes, waarbij dit wel gebeurt. Uiteindelijk bekijken we de dynamica van de leermethode, namelijk de evolutie van de inschattingen van spelers en de door hen gespeelde strategieën. We onderzoeken voornamelijk onder welke voorwaarden er enkel convergentie naar een evenwicht zal optreden.},
  ADDENDUM    = {Supervisor: Gert de Cooman},
  AUTHOR      = {Erik Quaeghebeur},
  EDITOR      = {Gert de Cooman},
  EPRINT      = {1854/LU-469938},
  EPRINTTYPE  = {hdl},
  FILE        = {files/Quaeghebeur-MA01.pdf},
  INSTITUTION = {Ghent University},
  KEYWORDS    = {evenwicht; fictief spelen; imprecieze waarschijnlijkheden; leren; speltheorie},
  TITLE       = {Speltheoretisch leren met imprecieze waarschijnlijkheden: dynamische aspecten},
  TITLEADDON  = {(Game-theoretic learning using imprecise probabilities: dynamical aspects)},
  TYPE        = {mathesis},
  YEAR        = {2001},
}

@THESIS{Quaeghebeur-MA02b,
  ABSTRACT    = {This text treats of the problem of predicting the flow of a river using past flow measurements, rainfall measurements and rainfall predictions. The objective is to generalize a forecasting method already used to predict daily consumption of electricity. The developed method will be compared to Hydromax, an existing riverflow forecasting model. The developed method simultaneously generates a series of consecutive flow predictions called a flow curve. This is done by combining separate forecasts for the mean, standard deviation and the normalized profile of the flow curve. Therefore, three separate forecasting models will be used, one for each of the aforementioned flow curve components. To understand the difficulties involved in riverflow forecasting we first take a look at the relevant hydrological concepts and the data used in constructing and testing the forecasting method. We will principally be interested in the prediction of floods, as these phenomena can have dire socioeconomic consequences if they take place without a timely warning. Some of the forecasting models will be based on mathematical techniques derived from the field of artificial neural networks. As an introduction we will shortly elaborate on this field before presenting a more profound study of the two derived techniques we will use. These are the so-called `self-organizing maps' and `radial basis function networks'. An essential part of the forecasting method are linear and nonlinear regression models. We shall take a look at these parameterized prediction models, the associated prediction errors and the parameter estimation involved in constructing them. Thus being well prepared, we will have at this stage a close look at the Hydromax model and explain the forecasting method we have developed. They will be compared in terms of the data needed and the hydrological knowledge involved. Finally, we will show how the developed method is used in practice. The obtained results will be compared with those obtained by Hydromax, and remarks will be made about possible improvements. We will conclude with showing that the developed method holds promise, but is not yet suitable for practical applications. Suggestions for further research are also included.},
  ADDENDUM    = {Supervisor: Vincent Wertz},
  AUTHOR      = {Erik Quaeghebeur},
  FILE        = {files/Quaeghebeur-MA02b.pdf},
  INSTITUTION = {Catholic University of Louvain},
  TITLE       = {Analyse et prédiction de débit de rivières par des méthodes non linéaires},
  TITLEADDON  = {(Analysis and prediction of river flow using non-linear methods)},
  TYPE        = {mathesis},
  YEAR        = {2002},
}

@THESIS{Quaeghebeur-PhD09b,
  ABSTRACT    = {This thesis's main subject is deriving, proposing, and studying predictive and parametric inference models that are based on the theory of coherent lower previsions. One important side subject also appears: obtaining and discussing extreme lower probabilities. In the chapter ‘Modeling uncertainty’, I give an introductory overview of the theory of coherent lower previsions ─ also called the theory of imprecise probabilities ─ and its underlying ideas. This theory allows us to give a more expressive ─ and a more cautious ─ description of uncertainty. This overview is original in the sense that ─ more than other introductions ─ it is based on the intuitive theory of coherent sets of desirable gambles. I show in the chapter ‘Extreme lower probabilities’ how to obtain the most extreme forms of uncertainty that can be modeled using lower probabilities. Every other state of uncertainty describable by lower probabilities can be formulated in terms of these extreme ones. The importance of the results in this area obtained and extensively discussed by me is currently mostly theoretical. The chapter ‘Inference models’ treats learning from samples from a finite, categorical space. My most basic assumption about the sampling process is that it is exchangeable, for which I give a novel definition in terms of desirable gambles. My investigation of the consequences of this assumption leads us to some important representation theorems: uncertainty about (in)finite sample sequences can be modeled entirely in terms of category counts (frequencies). I build on this to give an elucidating derivation from first principles for two popular inference models for categorical data ─ the predictive imprecise Dirichlet-multinomial model and the parametric imprecise Dirichlet model; I apply these models to game theory and learning Markov chains. In the last chapter, ‘Inference models for exponential families’, I enlarge the scope to exponential family sampling models; examples are normal sampling and Poisson sampling. I first thoroughly investigate exponential families and the related conjugate parametric and predictive previsions used in classical Bayesian inference models based on conjugate updating. These previsions serve as a basis for the new imprecise-probabilistic inference models I propose. Compared to the classical Bayesian approach, mine allows to be much more cautious when trying to express what we know about the sampling model; this caution is reflected in behavior (conclusions drawn, predictions made, decisions made) based on these models. Lastly, I show how the proposed inference models can be used for classification with the naive credal classifier.},
  AUTHOR      = {Erik Quaeghebeur},
  ADDENDUM    = {Supervisor: Gert de Cooman},
  EPRINT      = {1854/LU-495650},
  EPRINTTYPE  = {hdl},
  INSTITUTION = {Ghent University},
  ISBN        = {9789085782490},
  KEYWORDS    = {exponential family; imprecise Dirichlet model; inference; desirable gambles; extreme points; coherence; exchangeability; imprecise probability; sample; updating; lower prevision; representation insensitivity; learning},
  FILE        = {files/Quaeghebeur-PhD09b.pdf},
  PUBLISHER   = {Ghent University Faculty of Engineering},
  TITLE       = {Learning from samples using coherent lower previsions},
  TYPE        = {phdthesis},
  YEAR        = {2009},
}

@THESIS{Quaeghebeur-PhD10b,
  AUTHOR      = {Liesbet Quaeghebeur},
  INSTITUTION = {Universiteit Antwerpen},
  FILE        = {files/Quaeghebeur-PhD10b.pdf},
  TITLE       = {A philosophy of everyday, face-to-face conversation},
  TYPE        = {phdthesis},
  YEAR        = {2010},
}

@XDATA{JRSSB,
  ISSN         = {0035-9246},
  JOURNALTITLE = {Journal of the Royal Statistical Society. Series B (Methodological)},
  SHORTJOURNAL = {J. R. Stat. Soc. B},
}

@ARTICLE{Smith-JRSSB61j,
  ABSTRACT     = {It is suggested that the strength of a person's beliefs may be tested by finding at what odds he is prepared to bet on them. This leads to a system of numerical "medial personal probabilities" obeying the classical laws of probability. However, these do not have precisely defined values, but are contained within specified intervals. The appropriate method of inference is Bayes's Theorem. This leads to generally accepted statistical procedures in large samples, except that the "weight of evidence" and not significance level is the measure of conviction in a significance test. Under very general conditions decisions are made by maximizing expected utility.},
  AUTHOR       = {Cedric A. B. Smith},
  EPRINT       = {2983842},
  EPRINTTYPE   = {jstor},
  FILE         = {files/Smith-JRSSB61j.pdf},
  NUMBER       = {1},
  PAGES        = {1–37},
  TITLE        = {Consistency in statistical inference and decision},
  VOLUME       = {23},
  XDATA        = {JRSSB},
  YEAR         = {1961},
}

@ARTICLE{Dempster-JRSSB68j,
  ABSTRACT     = {Procedures of statistical inference are described which generalize Bayesian inference in specific ways. Probability is used in such a way that in general only bounds may be placed on the probabilities of given events, and probability systems of this kind are suggested both for sample information and for prior information. These systems are then combined using a specified rule. Illustrations are given for inferences about trinomial probabilities, and for inferences about a monotone sequence of binomial p\_i. Finally, some comments are made on the general class of models which produce upper and lower probabilities, and on the specific models which underlie the suggested inference procedures.},
  ANNOTATION   = {with discussion},
  AUTHOR       = {Arthur P. Dempster},
  EPRINT       = {2984504},
  EPRINTTYPE   = {jstor},
  FILE         = {files/Dempster-JRSSB68j.pdf},
  NUMBER       = {2},
  PAGES        = {205–247},
  TITLE        = {A generalization of Bayesian inference},
  VOLUME       = {30},
  XDATA        = {JRSSB},
  YEAR         = {1968},
}

@ARTICLE{Lauritzen+Spiegelhalter-JRSSB88j,
  ABSTRACT   = {A causal network is used in a number of areas as a depiction of patterns of `influence' among sets of variables. In expert systems it is common to perform `inference' by means of local computations on such large but sparse networks. In general, non-probabilistic methods are used to handle uncertainty when propagating the effects of evidence, and it has appeared that exact probabilistic methods are not computationally feasible. Motivated by an application in electromyography, we counter this claim by exploiting a range of local representations for the joint probability distribution, combined with topological changes to the original network termed `marrying' and `filling-in'. The resulting structure allows efficient algorithms for transfer between representations, providing rapid absorption and propagation of evidence. The scheme is first illustrated on a small, fictitious but challenging example, and the underlying theory and computational aspects are then discussed.},
  AUTHOR     = {Lauritzen, S. L. and Spiegelhalter, D. J.},
  EPRINT     = {2345762},
  EPRINTTYPE = {jstor},
  FILE       = {files/Lauritzen+Spiegelhalter-JRSSB88j.pdf},
  NUMBER     = {2},
  PAGES      = {157–224},
  TITLE      = {Local computations with probabilities on graphical structures and their application to expert systems},
  VOLUME     = {50},
  XDATA      = {JRSSB},
  YEAR       = {1988},
}

@ARTICLE{Erven+GR-JRSSB12j,
  ABSTRACT = {Summary.  Prediction and estimation based on Bayesian model selection and model averaging, and derived methods such as the Bayesian information criterion BIC, do not always converge at the fastest possible rate. We identify the catch-up phenomenon as a novel explanation for the slow convergence of Bayesian methods, which inspires a modification of the Bayesian predictive distribution, called the switch distribution. When used as an adaptive estimator, the switch distribution does achieve optimal cumulative risk convergence rates in non-parametric density estimation and Gaussian regression problems. We show that the minimax cumulative risk is obtained under very weak conditions and without knowledge of the underlying degree of smoothness. Unlike other adaptive model selection procedures such as the Akaike information criterion AIC and leave-one-out cross-validation, BIC and Bayes factor model selection are typically statistically consistent. We show that this property is retained by the switch distribution, which thus solves the AIC–BIC dilemma for cumulative risk. The switch distribution has an efficient implementation. We compare its performance with AIC, BIC and Bayesian model selection and averaging on a regression problem with simulated data.},
  AUTHOR   = {Tim van Erven and Peter Grünwald and Steven de Rooij},
  DOI      = {10.1111/j.1467-9868.2011.01025.x},
  FILE     = {files/Erven+GR-JRSSB12j.pdf},
  TITLE    = {Catching up faster by switching sooner: a predictive approach to adaptive estimation with an application to the AIC–BIC dilemma},
  VOLUME   = {74},
  NUMBER   = {3},
  PAGES    = {361–417},
  KEYWORDS = {Adaptive estimation, AIC, Bayesian model averaging, BIC, Model selection, Risk convergence},
  YEAR     = {2012},
  XDATA    = {JRSSB},
}


@XDATA{JRSSD,
  ISSN         = {0039-0526},
  JOURNALTITLE = {Journal of the Royal Statistical Society. Series D (The Statistician)},
  PUBLISHER    = {Blackwell Publishing for the Royal Statistical Society},
  SHORTJOURNAL = {J. R. Stat. Soc. D},
}

@ARTICLE{Kadane+Wolfson-JRSSD98j,
  ABSTRACT = {Elicitation of expert opinion is becoming increasingly important in the elicitation of prior distributions. In this paper, the psychology of elicitation and the currently available methods are briefly reviewed, but the primary discussion is on the distinction between 'general' elicitation methods for a class of problems and 'application-specific' methods which are useful only once. Examples of both types of elicitation are given, along with a discussion about general versus application-specific methods, and predictive versus structural elicitation.},
  AUTHOR     = {Joseph B. Kadane and Lara J. Wolfson},
  EPRINT     = {2988424},
  EPRINTTYPE = {jstor},
  FILE       = {files/Kadane+Wolfson-JRSSD98j.pdf},
  NUMBER     = {1},
  PAGES      = {3–19},
  TITLE      = {Experiences in Elicitation},
  VOLUME     = {47},
  XDATA      = {JRSSD},
  YEAR       = {1998},
}

@XDATA{IJAR,
  JOURNALTITLE = {International Journal of Approximate Reasoning},
  ISSN         = {0888-613X},
  PUBLISHER    = {Elsevier},
  SHORTJOURNAL = {Int. J. Approx. Reason.},
}

@ARTICLE{Pearl-IJAR88j,
  ABSTRACT = {The apparent failure of individual probabilistic expressions to distinguish between uncertainty and ignorance, and between certainty and confidence, have swayed researchers to seek alternative formalisms, where confidence measures are provided explicit notation. This paper summarizes how a causal networks formulation of probabilities facilitates the representation of confidence measures as an integral part of a knowledge system that does not require the use of higher order probabilities. We also examine whether Dempster-Shafer intervals represent confidence about probabilities.},
  AUTHOR   = {Judea Pearl},
  DOI      = {10.1016/0888-613X(88)90117-X},
  KEYWORDS = {Dempster-Shafer theory; ca; interval probability},
  FILE     = {files/Pearl-IJAR88j.pdf},
  NUMBER   = {3},
  PAGES    = {211–216},
  TITLE    = {On probability intervals},
  VOLUME   = {2},
  XDATA    = {IJAR},
  YEAR     = {1988},
}

@ARTICLE{Tessem-IJAR92j,
  ABSTRACT = {Belief networks are tried as a method for propagation of singleton interval probabilities. A convex polytope representation of the interval probabilities is shown to make the problem intractable even for small parameters. A solution to this is to use the interval bounds directly in computations of the propagation algorithm. The algorithm presented leads to approximative results but has the advantage of being polynomial in time. It is shown that the method gives fairly good results.},
  AUTHOR   = {Bjørnar Tessem},
  DOI      = {10.1016/0888-613X(92)90006-L},
  NUMBER   = {3-4},
  PAGES    = {95–120},
  TITLE    = {Interval probability propagation},
  VOLUME   = {7},
  XDATA    = {IJAR},
  YEAR     = {1992},
}

@ARTICLE{Walley+Cooman-IJAR99j,
  ABSTRACT = {Possibility measures and conditional possibility measures are given a behavioural interpretation as marginal betting rates against events. Under this interpretation, possibility measures should satisfy two consistency criteria, known as ‘avoiding sure loss’ and ‘coherence’. We survey the rules that have been proposed for defining conditional possibilities and investigate which of them satisfy our consistency criteria in two situations of practical interest. Only two of these rules satisfy the criteria in both cases studied, and the conditional possibilities produced by these rules are highly uninformative. We introduce a new rule that is more informative and is also coherent in both cases.},
  AUTHOR   = {Peter Walley and Gert de Cooman},
  DOI      = {10.1016/S0888-613X(99)00007-9},
  KEYWORDS = {Dempster's rule; coherence; conditional possibility; imprecise probabilities; natural extension; possibility measure; possibility theory; upper probability},
  FILE     = {files/Walley+Cooman-IJAR99j.pdf},
  PAGES    = {63–107},
  TITLE    = {Coherence of rules for defining conditional possibility},
  VOLUME   = {21},
  XDATA    = {IJAR},
  YEAR     = {1999},
}

@ARTICLE{Renooij+Witteman-IJAR99j,
  ABSTRACT = {The number of knowledge-based systems that build on Bayesian belief networks is increasing. The construction of such a network however requires a large number of probabilities in numerical form. This is often considered a major obstacle, one of the reasons being that experts are reluctant to provide numerical probabilities. The use of verbal probability expressions as an additional method of eliciting probabilistic information may to some extent remove this obstacle. In this paper, we review studies that address the communication of probabilities in words and/or numbers. We then describe our own experiments concerning the development of a probability scale that contains words as well as numbers. This scale appears to be an aid for researchers and domain experts during the elicitation phase of building a belief network and might help users understand the output of the network.},
  AUTHOR   = {Silja Renooij and Cilia L. M. Witteman},
  DOI      = {10.1016/S0888-613X(99)00027-4},
  KEYWORDS = {Communicating probability; Expert systems; Knowledge elicitation; Explanation},
  NUMBER   = {3},
  PAGES    = {169–194},
  TITLE    = {Talking probabilities: communicating probabilistic information with words and numbers},
  VOLUME   = {22},
  XDATA    = {IJAR},
  YEAR     = {1999},
}

@ARTICLE{Walley-IJAR00j,
  AUTHOR   = {Peter Walley},
  DOI      = {10.1016/S0888-613X(00)00031-1},
  KEYWORDS = {Choquet capacity; Comparative probability; coherence; credal sets; desirable gambles; foundations of probability; interval-valued probability; lower prevision; lower probability; partial preference ordering; uncertainty measures},
  FILE     = {files/Walley-IJAR00j.pdf},
  NUMBER   = {2–3},
  PAGES    = {125–148},
  TITLE    = {Towards a unified theory of imprecise probability},
  VOLUME   = {24},
  YEAR     = {2000},
  XDATA    = {IJAR},
}

@ARTICLE{Weichselberger-IJAR00j,
  ABSTRACT = {The concept of interval-probability is motivated by the goal to generalize classical-probability so that it can be used for describing uncertainty in general. The foundations of the theory are based on a system of three axioms — in addition to Kolmogorov's axioms — and definitions of independence as well as of conditional-probability. The resulting theory does not depend upon interpretations of the probability concept. As an example of generalising classical results Bayes' theorem is described — other theorems are only mentioned.},
  AUTHOR   = {Kurt Weichselberger},
  DOI      = {10.1016/S0888-613X(00)00032-3},
  KEYWORDS = {Interval-probability; Uncertainty; Conditional-probability; Theorem of Bayes},
  FILE     = {files/Weichselberger-IJAR00j.pdf},
  NUMBER   = {2–3},
  PAGES    = {149–170},
  TITLE    = {The theory of interval-probability as a unifying concept for uncertainty},
  VOLUME   = {24},
  XDATA    = {IJAR},
  YEAR     = {2000},
}

@ARTICLE{Hansen+JACP-IJAR00j,
  ABSTRACT = {Treatment of imprecise probabilities within the probabilistic satisfiability approach to uncertainty in knowledge-based systems is surveyed and discussed. Both probability intervals and qualitative probabilities are considered. Analytical and numerical methods to test coherence and bound the probability of a conclusion are reviewed. They use polyhedral combinatorics and advanced methods of linear programming.},
  AUTHOR   = {Pierre Hansen and Brigitte Jaumard and Marcus Poggi de Aragão and Fabien Chauny and Sylvain Perron},
  DOI      = {10.1016/S0888-613X(00)00033-5},
  KEYWORDS = {Satisfiability; Probability intervals; Qualitative probabilities; Polyhedra; Linear programming; Column generation; Nonlinear 0–1 programming},
  FILE     = {files/Hansen+JACP-IJAR00j.pdf},
  NUMBER   = {2–3},
  PAGES    = {171–189},
  TITLE    = {Probabilistic satisfiability with imprecise probabilities},
  VOLUME   = {24},
  YEAR     = {2000},
  XDATA    = {IJAR},
}

@ARTICLE{Biazzo+Gilio-IJAR00j,
  ABSTRACT = {In this paper, we consider coherent imprecise probability assessments on finite families of conditional events and we study the problem of their extension. With this aim, we adopt a generalized definition of coherence, called g-coherence, which is based on a suitable generalization of the coherence principle of de Finetti. At first, we recall some theoretical results and an algorithm obtained in some previous papers where the case of precise conditional probability assessments has been studied. Then, we extend these results to the case of imprecise probabilistic assessments and we obtain a theorem which can be looked at as a generalization of the version of the fundamental theorem of de Finetti given by some authors for the case of conditional events. Our algorithm can also be exploited to produce lower and upper probabilities which are coherent in the sense of Walley and Williams. Moreover, we compare our approach to similar ones, like probability logic or probabilistic deduction. Finally, we apply our algorithm to some well-known inference rules assuming some logical relations among the given events.},
  AUTHOR   = {Veronica Biazzo and Angelo Gilio},
  DOI      = {10.1016/S0888-613X(00)00038-4},
  KEYWORDS = {Conditional events; Imprecise probabilities; Coherence; Generalized coherence; Natural extension; Extensions; Algorithms; Probability logic; Probabilistic deduction; Probabilistic satisfiability},
  LOCAL    = {files/Biazzo+Gilio-IJAR00j.pdf},
  NUMBER   = {2–3},
  PAGES    = {251–272},
  TITLE    = {A generalization of the fundamental theorem of de Finetti for imprecise conditional probability assessments},
  VOLUME   = {24},
  XDATA    = {IJAR},
  YEAR     = {2000},
}

@ARTICLE{Miranda+Cooman-IJAR03j,
  ABSTRACT = {Numerical possibility measures can be interpreted as systems of upper betting rates for events. As such, they have a special part in the unifying behavioural theory of imprecise probabilities, proposed by Walley. On this interpretation, they should arguably satisfy certain rationality, or consistency, requirements, such as avoiding sure loss and coherence. Using a version of Walley's notion of epistemic independence suitable for possibility measures, we study in detail what these rationality requirements tell us about the construction of independent product possibility measures from given marginals, and we obtain necessary and sufficient conditions for a product to satisfy these criteria. In particular, we show that the well-known minimum and product rules for forming independent joint distributions from marginal ones, are only coherent when at least one of these distributions assume just the values zero and one.},
  AUTHOR   = {Enrique Miranda and Gert de Cooman},
  DOI      = {10.1016/S0888-613X(02)00087-7},
  KEYWORDS = {Coherence; Conditioning; Epistemic independence; Independent product; Possibility theory; Upper probability},
  FILE     = {files/Miranda+Cooman-IJAR03j.pdf},
  PAGES    = {23–42},
  TITLE    = {Epistemic independence in numerical possibility theory},
  VOLUME   = {32},
  XDATA    = {IJAR},
  YEAR     = {2003},
}

@ARTICLE{Witteman+Renooij-IJAR03j,
  ABSTRACT = {For purposes such as the development of decision support systems, the probabilities that model the uncertainties in the domain of application are usually elicited from domain experts. A number of elicitation methods is available. While constructing a real-life system, we however found none of these methods to be quite usable: they turned out to be too time-consuming and difficult for experts. In an earlier paper we described a verbal–numerical response scale we developed to facilitate elicitation of a large number of probabilities. In this paper we describe a study that justifies our claim that use of this verbal–numerical scale generally facilitates the assessment process.},
  AUTHOR   = {Cilia L. M. Witteman and Silja Renooij},
  DOI      = {10.1016/S0888-613X(02)00151-2},
  KEYWORDS = {Probability elicitation; Decision support systems; Accuracy of assessments; Response scale},
  NUMBER   = {2},
  PAGES    = {117–131},
  TITLE    = {Evaluation of a verbal–numerical probability scale},
  VOLUME   = {33},
  XDATA    = {IJAR},
  YEAR     = {2003},
}

@article{Liu+Wellman-IJAR04j,
  ABSTRACT = {We present conditions under which one can bound the probabilistic relationships between random variables in a Bayesian network by exploiting known or induced qualitative relationships. Generic strengthening and weakening operations produce bounds on cumulative distributions, and the directions of these bounds are maintained through qualitative influences. We show how to incorporate these operations in a state-space abstraction method, so that bounds provably tighten as an approximate network is refined. We apply these techniques to qualitative tradeoff resolution demonstrating an ability to identify qualitative relationships among random variables without exhaustively using the probabilistic information encoded in the given network. In an application to path planning, we present an anytime algorithm with run-time computable error bounds.},
  AUTHOR   = {Chao-Lin Liu and Michael P. Wellman},
  DOI      = {10.1016/j.ijar.2003.06.002},
  FILE     = {files/Liu+Wellman-IJAR04j.pdf},
  NUMBER   = {1},
  PAGES    = {31–73},
  TITLE    = {Bounding probabilistic relationships in Bayesian networks using qualitative influences: methods and applications},
  VOLUME   = {36},
  XDATA    = {IJAR},
  YEAR     = {2004},
}

@ARTICLE{Bolt+GR-IJAR05j,
  ABSTRACT = {A qualitative probabilistic network is a graphical model of the probabilistic influences among a set of statistical variables, in which each influence is associated with a qualitative sign. A non-monotonic influence between two variables is associated with the ambiguous sign ‘?’, which indicates that the actual sign of the influence depends on the state of the network. The presence of such ambiguous signs is undesirable as it tends to lead to uninformative results upon inference. In this paper, we argue that, although a non-monotonic influence may have varying effects, in each specific state of the network, its effect is unambiguous. To capture the current effect of the influence, we introduce the concept of situational sign. We show how situational signs can be used upon inference and how they are updated as the state of the network changes. By means of a real-life qualitative network in oncology, we show that the use of situational signs can effectively forestall uninformative results upon inference.},
  AUTHOR   = {Janneke H. Bolt and Linda C. van der Gaag and Silja Renooij},
  DOI      = {10.1016/j.ijar.2004.05.009},
  NUMBER   = {3},
  PAGES    = {333–354},
  TITLE    = {Introducing situational signs in qualitative probabilistic networks},
  VOLUME   = {38},
  XDATA    = {IJAR},
  YEAR     = {2005},
}

@ARTICLE{Bernard-IJAR05j,
  ABSTRACT = {The imprecise Dirichlet model (IDM) was recently proposed by Walley as a model for objective statistical inference from multinomial data with chances θ. In the IDM, prior or posterior uncertainty about θ is described by a set of Dirichlet distributions, and inferences about events are summarized by lower and upper probabilities. The IDM avoids shortcomings of alternative objective models, either frequentist or Bayesian. We review the properties of the model, for both parametric and predictive inferences, and some of its recent applications to various statistical problems.},
  AUTHOR   = {Jean-Marc Bernard},
  DOI      = {10.1016/j.ijar.2004.10.002},
  KEYWORDS = {Bayesian inference; Dirichlet distribution; Frequentist inference; IDM; Lower and upper probabilities; Predictive inference; Prior ignorance},
  FILE     = {files/Bernard-IJAR05j.pdf},
  PAGES    = {123–150},
  TITLE    = {An introduction to the imprecise Dirichlet model for multinomial data},
  VOLUME   = {39},
  XDATA    = {IJAR},
  YEAR     = {2005},
}

@ARTICLE{Cozman-IJAR05j,
  ABSTRACT = {This paper presents an overview of graphical models that can handle imprecision in probability values. The paper first reviews basic concepts and presents a brief historical account of the field. The main characteristics of the credal network model are then discussed, as this model has received considerable attention in the literature.},
  AUTHOR   = {Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2004.10.003},
  KEYWORDS = {Credal network; Graphical models; Sets of probability distributions; imprecise probability},
  FILE     = {files/Cozman-IJAR05j.pdf},
  NUMBER   = {2-3},
  PAGES    = {167–184},
  TITLE    = {Graphical models for imprecise probabilities},
  VOLUME   = {39},
  YEAR     = {2005},
  XDATA    = {IJAR},
}

@ARTICLE{Ferreira+Cozman-IJAR05j,
  ABSTRACT = {A credal network is a graphical representation for a set of joint probability distributions. In this paper we discuss algorithms for exact and approximate inferences in credal networks. We propose a branch-and-bound framework for inference, and focus on inferences for polytree-shaped networks. We also propose a new algorithm, A/R+, for outer approximations in polytree-shaped credal networks.},
  AUTHOR   = {José Carlos {Ferreira da Rocha} and Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2004.10.009},
  FILE     = {files/Ferreira+Cozman-IJAR05j.pdf},
  NUMBER   = {2-3},
  PAGES    = {279–296},
  TITLE    = {Inference in credal networks: branch-and-bound methods and the A/R+ algorithm},
  VOLUME   = {39},
  XDATA    = {IJAR},
  YEAR     = {2005},
}

@ARTICLE{Pelessoni+Vicig-IJAR05j,
  ABSTRACT = {Two classes of imprecise previsions, which we termed convex and centered convex previsions, are studied in this paper in a framework close to Walley's and Williams' theory of imprecise previsions. We show that convex previsions are related with a concept of convex natural extension, which is useful in correcting a large class of inconsistent imprecise probability assessments, characterised by a condition of avoiding unbounded sure loss. Convexity further provides a conceptual framework for some uncertainty models and devices, like unnormalised supremum preserving functions. Centered convex previsions are intermediate between coherent previsions and previsions avoiding sure loss, and their not requiring positive homogeneity is a relevant feature for potential applications. We discuss in particular their usage in (financial) risk measurement. In a final part we introduce convex imprecise previsions in a conditional environment and investigate their basic properties, showing how several of the preceding notions may be extended and the way the generalised Bayes rule applies.},
  AUTHOR   = {Renato Pelessoni and Paolo Vicig},
  DOI      = {10.1016/j.ijar.2004.10.007},
  KEYWORDS = {Convex conditional imprecise previsions; Convex imprecise previsions; Convex natural extension; Generalised Bayes rule; Risk measures},
  FILE     = {files/Pelessoni+Vicig-IJAR05j.pdf},
  NUMBER   = {2-3},
  PAGES    = {297–319},
  TITLE    = {Uncertainty modelling and conditioning with convex imprecise previsions},
  VOLUME   = {39},
  XDATA    = {IJAR},
  YEAR     = {2005},
}

@ARTICLE{Baroni+Vicig-IJAR05j,
  ABSTRACT = {This paper addresses the problem of exchanging uncertainty assessments in multi-agent systems. Since it is assumed that each agent might completely ignore the internal representation of its partners, a common interchange format is needed. We analyze the case of an interchange format defined by means of imprecise probabilities, pointing out the reasons of this choice. A core problem with the interchange format concerns transformations from imprecise probabilities into other formalisms (in particular, precise probabilities, possibilities, belief functions). We discuss this so far little investigated question, analyzing how previous proposals, mostly regarding special instances of imprecise probabilities, would fit into this problem. We then propose some general transformation procedures, which take also account of the fact that information can be partial, i.e. may concern an arbitrary (finite) set of events.},
  AUTHOR   = {Pietro Baroni and Paolo Vicig},
  DOI      = {10.1016/j.ijar.2005.03.001},
  KEYWORDS = {Imprecise probability theory; Multi-agent systems; Partial possibilities; Pignistic probability; Uncertainty transformations},
  FILE     = {files/Baroni+Vicig-IJAR05j.pdf},
  PAGES    = {147–180},
  TITLE    = {An uncertainty interchange format with imprecise probabilities},
  VOLUME   = {40},
  XDATA    = {IJAR},
  YEAR     = {2005},
}

@ARTICLE{Feelders+Gaag-IJAR06j,
  ABSTRACT = {We consider the problem of learning the parameters of a Bayesian network from data, while taking into account prior knowledge about the signs of influences between variables. Such prior knowledge can be readily obtained from domain experts. We show that this problem of parameter learning is a special case of isotonic regression and provide a simple algorithm for computing isotonic estimates. Our experimental results for a small Bayesian network in the medical domain show that taking prior knowledge about the signs of influences into account leads to an improved fit of the true distribution, especially when only a small sample of data is available. More importantly, however, the isotonic estimator provides parameter estimates that are consistent with the specified prior knowledge, thereby resulting in a network that is more likely to be accepted by experts in its domain of application.},
  AUTHOR   = {Ad Feelders and Linda C. van der Gaag},
  DOI      = {10.1016/j.ijar.2005.10.003},
  KEYWORDS = {Bayesian networks; Parameter learning; Order-constrained estimation},
  NUMBER   = {1-2},
  PAGES    = {37–53},
  TITLE    = {Learning Bayesian network parameters under order constraints},
  VOLUME   = {42},
  XDATA    = {IJAR},
  YEAR     = {2006},
}

@ARTICLE{Kreinovich+XF-IJAR06j,
  ABSTRACT = {In many real-life situations, we only have partial information about the actual probability distribution. For example, under Dempster-Shafer uncertainty, we only know the masses m1,...,mn assigned to different sets S1,...,Sn, but we do not know the distribution within each set Si. Because of this uncertainty, there are many possible probability distributions consistent with our knowledge; different distributions have, in general, different values of standard statistical characteristics such as mean and variance. It is therefore desirable, given a Dempster-Shafer knowledge base, to compute the ranges and of possible values of mean E and of variance V. In their recent paper, Langewisch and Choobineh show how to compute these ranges in polynomial time. In particular, they reduce the problem of computing to the problem of minimizing a convex quadratic function, a problem which can be solved in time O(n^2 log(n)). We show that the corresponding quadratic optimization problem can be actually solved faster, in time O(n log(n)); thus, we can compute the bounds V and in time O(n log(n)).},
  AUTHOR   = {Vladik Kreinovich and Gang Xiang and Scott Ferson},
  DOI      = {10.1016/j.ijar.2005.12.001},
  FILE     = {files/Kreinovich+XF-IJAR06j.pdf},
  NUMBER   = {3},
  PAGES    = {212–227},
  TITLE    = {Computing mean and variance under Dempster-Shafer uncertainty: Towards faster algorithms},
  VOLUME   = {42},
  XDATA    = {IJAR},
  YEAR     = {2006},
}

@ARTICLE{Campos+Cozman-IJAR07j,
  ABSTRACT = {This paper investigates the computation of lower/upper expectations that must cohere with a collection of probabilistic assessments and a collection of judgements of epistemic independence. New algorithms, based on multilinear programming, are presented, both for independence among events and among random variables. Separation properties of graphical models are also investigated.},
  AUTHOR   = {Cassio Polpo de Campos and Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2006.07.013},
  KEYWORDS = {concepts of independence; epistemic independence; imprecise probabilities; multilinear programming; sets of probability measures},
  FILE     = {files/Campos+Cozman-IJAR07j.pdf},
  NUMBER   = {3},
  PAGES    = {244–260},
  TITLE    = {Computing lower and upper expectations under epistemic independence},
  VOLUME   = {44},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Cano+GMA-IJAR07j,
  ABSTRACT = {This paper proposes two new algorithms for inference in credal networks. These algorithms enable probability intervals to be obtained for the states of a given query variable. The first algorithm is approximate and uses the hill-climbing technique in the Shenoy-Shafer architecture to propagate in join trees ; the second is exact and is a modification of Rocha and Cozman's branch-and-bound algorithm, but applied to general directed acyclic graphs.},
  AUTHOR   = {Andrés Cano and Manuel Gómez and Serafín Moral and Joaquín Abellán},
  DOI      = {10.1016/j.ijar.2006.07.020},
  KEYWORDS = {Bayesian networks; branch-and-bound algorithms; credal network; hill-climbing; probability intervals; strong independence},
  FILE     = {files/Cano+GMA-IJAR07j.pdf},
  NUMBER   = {3},
  PAGES    = {261–280},
  TITLE    = {Hill-climbing and branch-and-bound algorithms for exact and approximate inference in credal networks},
  VOLUME   = {44},
  YEAR     = {2007},
}

@ARTICLE{Gillett+SS-IJAR07j,
  ABSTRACT   = {This article presents a probabilistic logic whose sentences can be interpreted as asserting the acceptability of gambles described in terms of an underlying logic. This probabilistic logic has a concrete syntax and a complete inference procedure, and it handles conditional as well as unconditional probabilities. It synthesizes Nilsson's probabilistic logic and Frisch and Haddawy's anytime inference procedure with Wilson and Moral's logic of gambles. Two distinct semantics can be used for our probabilistic logic: (1) the measure-theoretic semantics used by the prior logics already mentioned and also by the more expressive logic of Fagin, Halpern, and Meggido and (2) a behavioral semantics. Under the measure-theoretic semantics, sentences of our probabilistic logic are interpreted as assertions about a probability distribution over interpretations of the underlying logic. Under the behavioral semantics, these sentences are interpreted only as asserting the acceptability of gambles, and this suggests different directions for generalization.},
  ANNOTATION = {Reasoning with Imprecise Probabilities},
  AUTHOR     = {Peter R. Gillett and Richard B. Scherl and Glenn Shafer},
  DOI        = {10.1016/j.ijar.2006.07.014},
  KEYWORDS   = {Anytime deduction; Behavioral semantics; Gambles; Measure–theoretic; Probabilistic logic},
  FILE       = {files/Gillett+SS-IJAR07j.pdf},
  NUMBER     = {3},
  PAGES      = {281–300},
  TITLE      = {A probabilistic logic based on the acceptability of gambles},
  VOLUME     = {44},
  XDATA      = {IJAR},
  YEAR       = {2007},
}

@ARTICLE{Utkin+Augustin-IJAR07j,
  ABSTRACT = {The paper presents an efficient solution to decision problems where direct partial information on the distribution of the states of nature is available, either by observations of previous repetitions of the decision problem or by direct expert judgements. To process this information we use a recent generalization of Walley's imprecise Dirichlet model, allowing us also to handle incomplete observations or imprecise judgements, including missing data. We derive efficient algorithms and discuss properties of the optimal solutions with respect to several criteria, including Gamma-maximinity and E-admissibility. In the case of precise data and pure actions the former surprisingly leads us to a frequency-based variant of the Hodges–Lehmann criterion, which was developed in classical decision theory as a compromise between Bayesian and minimax procedures.},
  AUTHOR   = {Lev V. Utkin and Thomas Augustin},
  KEYWORDS = {Belief functions; Coarse data; Decision making; E-admissibility; Imprecise Dirichlet model (IDM); Imprecise probabilities; Incomplete data; Interval probability; Interval statistical models; Missing or set-valued statistical data},
  FILE     = {files/Utkin+Augustin-IJAR07j.pdf},
  NUMBER   = {3},
  PAGES    = {322–338},
  TITLE    = {Decision making under incomplete data using the imprecise Dirichlet model},
  VOLUME   = {44},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Wallner-IJAR07j,
  ABSTRACT = {Every coherent probability (= F-probability) \mathcal{F} on a finite sample space Ω\_k with k elements defines a set of classical probabilities in accordance with the interval limits. This set, called "structure" of , is a convex polytope having dimension \leq k - 1. We prove that the maximal number of extreme points of structures is exactly k!.},
  AUTHOR   = {Anton Wallner},
  DOI      = {10.1016/j.ijar.2006.07.017},
  KEYWORDS = {0/1-Matrix; Coherent probability; Core; Credal set; Extreme point; F-probability; Interval probability; Polyhedron; Polytope; Structure; Vertex},
  FILE     = {files/Wallner-IJAR07j.pdf},
  NUMBER   = {3},
  PAGES    = {339–357},
  TITLE    = {Extreme points of coherent probabilities in finite spaces},
  VOLUME   = {44},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Vicig+ZC-IJAR07j,
  ABSTRACT = {These notes comment on Williams' fundamental essay Notes on Conditional Previsions, written as a research report in 1975 and published in the present issue. Basic aspects of that work are discussed, including historical background and relevance to the foundations of probability; examples are supplied to help understanding.},
  AUTHOR   = {Paolo Vicig and Marco Zaffalon and Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2006.07.018},
  FILE     = {files/Vicig+ZC-IJAR07j.pdf},
  PAGES    = {358–365},
  TITLE    = {Notes on “Notes on conditional previsions”},
  VOLUME   = {44},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Williams-IJAR07j,
  ABSTRACT = {The personalist conception of probability is often explicated in terms of betting rates acceptable to an individual. A common approach, that of de Finetti for example, assumes that the individual is willing to take either side of the bet, so that the bet is “fair” from the individual's point of view. This can sometimes be unrealistic, and leads to difficulties in the case of conditional probabilities or previsions. An alternative conception is presented in which it is only assumed that the collection of acceptable bets forms a convex cone, rather than a linear space. This leads to the more general conception of an upper conditional prevision. The main concerns of the paper are with the extension of upper conditional previsions. The main result is that any upper conditional prevision is the upper envelope of a family of additive conditional previsions.},
  AUTHOR   = {Peter M. Williams},
  DOI      = {10.1016/j.ijar.2006.07.019},
  KEYWORDS = {Coherence; Conditional prevision; Imprecise probabilities; de Finetti},
  FILE     = {files/Williams-IJAR07j.pdf},
  NOTE     = {Published version of \parencite{Williams-UoS75r}},
  PAGES    = {366–383},
  TITLE    = {Notes on conditional previsions},
  VOLUME   = {44},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Troffaes-IJAR07j,
  ABSTRACT = {Various ways for decision making with imprecise probabilities—admissibility, maximal expected utility, maximality, E-admissibility, Γ-maximax, Γ-maximin, all of which are well known from the literature—are discussed and compared. We generalise a well-known sufficient condition for existence of optimal decisions. A simple numerical example shows how these criteria can work in practice, and demonstrates their differences. Finally, we suggest an efficient approach to calculate optimal decisions under these decision criteria.},
  AUTHOR   = {Matthias C. M. Troffaes},
  DOI      = {10.1016/j.ijar.2006.06.001},
  KEYWORDS = {Decision; E-admissibility; Lower prevision; Maximality; Maximin; Optimality; Probability; Uncertainty},
  FILE     = {files/Troffaes-IJAR07j.pdf},
  NUMBER   = {1},
  PAGES    = {17–29},
  TITLE    = {Decision making under uncertainty using imprecise probabilities},
  VOLUME   = {45},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Miranda+Cooman-IJAR07j,
  ABSTRACT = {We generalise Walley's Marginal Extension Theorem to the case of any finite number of conditional lower previsions. Unlike the procedure of natural extension, our marginal extension always provides the smallest (most conservative) coherent extensions. We show that they can also be calculated as lower envelopes of marginal extensions of conditional linear (precise) previsions. Finally, we use our version of the theorem to study the so-called forward irrelevant product and forward irrelevant natural extension of a number of marginal lower previsions.},
  AUTHOR   = {Enrique Miranda and Gert de Cooman},
  DOI      = {10.1016/j.ijar.2006.12.009},
  KEYWORDS = {Coherence; Epistemic irrelevance; Forward irrelevance; Forward irrelevant natural extension; Forward irrelevant product; Imprecise probabilities; Lower previsions; Marginal extension; Natural extension},
  FILE     = {files/Miranda+Cooman-IJAR07j},
  NUMBER   = {1},
  PAGES    = {188–225},
  TITLE    = {Marginal extension in the theory of coherent lower previsions},
  VOLUME   = {46},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Charitos+WG-IJAR07j,
  ABSTRACT = {Sequential statistical models such as dynamic Bayesian networks and hidden Markov models more specifically, model stochastic processes over time. In this paper, we study for these models the effect of consecutive similar observations on the posterior probability distribution of the represented process. We show that, given such observations, the posterior distribution converges to a limit distribution. Building upon the rate of the convergence, we further show that, given some wished-for level of accuracy, part of the inference can be forestalled. To evaluate our theoretical results, we study their implications for a real-life model from the medical domain and for a benchmark model for agricultural purposes. Our results indicate that whenever consecutive similar observations arise, the computational requirements of inference in Markovian models can be drastically reduced.},
  AUTHOR   = {Theodore Charitos and Peter R. de Waal and Linda C. van der Gaag},
  DOI      = {10.1016/j.ijar.2006.09.011},
  KEYWORDS = {Markovian models; Consecutive similar observations; Convergence; Inference; Efficiency},
  FILE     = {files/Charitos+WG-IJAR07j.pdf},
  NUMBER   = {2},
  PAGES    = {300–319},
  TITLE    = {Convergence in Markovian models with implications for efficiency of inference},
  VOLUME   = {46},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Miranda+CQ-IJAR08j,
  ABSTRACT   = {We study the information that a distribution function provides about the finitely additive probability measure inducing it. We show that in general there is an infinite number of finitely additive probabilities associated with the same distribution function. Secondly, we investigate the relationship between a distribution function and its given sequence of moments. We provide formulae for the sets of distribution functions, and finitely additive probabilities, associated with some moment sequence, and determine under which conditions the moments determine the distribution function uniquely. We show that all these problems can be addressed efficiently using the theory of coherent lower previsions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  DATE       = {2008-04},
  DOI        = {10.1016/j.ijar.2007.07.007},
  EPRINT     = {1854/LU-397873},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {lower distribution function; coherent lower prevision; lower Riemann–Stieltjes integral; complete monotonicity; moment sequence},
  FILE       = {files/Miranda+CQ-IJAR08j.pdf},
  NUMBER     = {1},
  PAGES      = {132–155},
  TITLE      = {Finitely additive extensions of distribution functions and moment sequences: The coherent lower prevision approach},
  VOLUME     = {48},
  XDATA      = {IJAR},
}

@ARTICLE{Ide+Cozman-IJAR08j,
  ABSTRACT = {This paper presents a family of algorithms for approximate inference in credal networks (that is, models based on directed acyclic graphs and set-valued probabilities) that contain only binary variables. Such networks can represent incomplete or vague beliefs, lack of data, and disagreements among experts; they can also encode models based on belief functions and possibilistic measures. All algorithms for approximate inference in this paper rely on exact inferences in credal networks based on polytrees with binary variables, as these inferences have polynomial complexity. We are inspired by approximate algorithms for Bayesian networks; thus the Loopy 2U algorithm resembles Loopy Belief Propagation, while the Iterated Partial Evaluation and Structured Variational 2U algorithms are, respectively, based on Localized Partial Evaluation and variational techniques.},
  AUTHOR   = {Jaime Shinsuke Ide and Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2007.09.003},
  KEYWORDS = {2U algorithm; Credal networks; Loopy Belief Propagation; Variational methods},
  FILE     = {files/Ide+Cozman-IJAR08j.pdf},
  NUMBER   = {1},
  PAGES    = {275–296},
  TITLE    = {Approximate algorithms for credal networks with binary variables},
  VOLUME   = {48},
  XDATA    = {IJAR},
  YEAR     = {2008},
}

@ARTICLE{Miranda-IJAR08j,
  ABSTRACT = {This paper presents a summary of Peter Walley's theory of coherent lower previsions. We introduce three representations of coherent assessments: coherent lower and upper previsions, closed and convex sets of linear previsions, and sets of desirable gambles. We show also how the notion of coherence can be used to update our beliefs with new information, and a number of possibilities to model the notion of independence with coherent lower previsions. Next, we comment on the connection with other approaches in the literature: de Finetti's and Williams' earlier work, Kuznetsov's and Weischelberger's work on interval-valued probabilities, Dempster-Shafer theory of evidence and Shafer and Vovk's game-theoretic approach. Finally, we present a brief survey of some applications and summarize the main strengths and challenges of the theory.},
  AUTHOR   = {Enrique Miranda},
  DOI      = {10.1016/j.ijar.2007.12.001},
  KEYWORDS = {Avoiding sure loss; Coherence; Conditional lower previsions; Desirability; Imprecision; Independence; Subjective probability},
  FILE     = {files/Miranda-IJAR08j.pdf},
  NUMBER   = {2},
  PAGES    = {628–658},
  TITLE    = {A survey of the theory of coherent lower previsions},
  VOLUME   = {48},
  XDATA    = {IJAR},
  YEAR     = {2008},
}

@ARTICLE{Brüning+Dennenberg-IJAR08j,
  ABSTRACT   = {It is known that the σ-additive Möbius transform of a belief function (we prefer to call it belief measure) can be derived from Choquet's Theorem. One has to show that the extreme points of the compact convex set of belief measures are the {0,1}-valued belief measures, which are called filter games as well. A proof is implicit in the famous 1953/54 paper of Choquet but it is hard to read it. We present a direct proof and – for the sake of completeness – derive the Möbius transform.},
  ANNOTATION = {explicitation of an implicit result of Choquet-1954},
  AUTHOR     = {Martin Brüning and Dieter Denneberg},
  DOI        = {10.1016/j.ijar.2006.11.003},
  FILE       = {files/Brüning+Dennenberg-IJAR08j.pdf},
  NUMBER     = {3},
  PAGES      = {670–675},
  TITLE      = {The extreme points of the set of belief measures},
  VOLUME     = {48},
  XDATA      = {IJAR},
  YEAR       = {2008},
}

@ARTICLE{Antonucci+Zaffalon-IJAR08j,
  ABSTRACT = {Credal networks are models that extend Bayesian nets to deal with imprecision in probability, and can actually be regarded as sets of Bayesian nets. Credal nets appear to be powerful means to represent and deal with many important and challenging problems in uncertain reasoning. We give examples to show that some of these problems can only be modeled by credal nets called non-separately specified. These, however, are still missing a graphical representation language and updating algorithms. The situation is quite the opposite with separately specified credal nets, which have been the subject of much study and algorithmic development. This paper gives two major contributions. First, it delivers a new graphical language to formulate any type of credal network, both separately and non-separately specified. Second, it shows that any non-separately specified net represented with the new language can be easily transformed into an equivalent separately specified net, defined over a larger domain. This result opens up a number of new outlooks and concrete outcomes: first of all, it immediately enables the existing algorithms for separately specified credal nets to be applied to non-separately specified ones. We explore this possibility for the 2U algorithm: an algorithm for exact updating of singly connected credal nets, which is extended by our results to a class of non-separately specified models. We also consider the problem of inference on Bayesian networks, when the reason that prevents some of the variables from being observed is unknown. The problem is first reformulated in the new graphical language, and then mapped into an equivalent problem on a separately specified net. This provides a first algorithmic approach to this kind of inference, which is also proved to be NP-hard by similar transformations based on our formalism.},
  AUTHOR   = {Alessandro Antonucci and Marco Zaffalon},
  DOI      = {10.1016/j.ijar.2008.02.005},
  KEYWORDS = {Bayesian networks; Conservative inference rule; Conservative updating; Credal networks; Credal sets; Imprecise probabilities; Probabilistic graphical models},
  FILE     = {files/Antonucci+Zaffalon-IJAR08j.pdf},
  NUMBER   = {2},
  PAGES    = {345–361},
  TITLE    = {Decision-theoretic specification of credal networks: A unified language for uncertain modeling with sets of Bayesian networks},
  VOLUME   = {49},
  XDATA    = {IJAR},
  YEAR     = {2008},
}

@ARTICLE{Renooij+Gaag-IJAR08j,
  ABSTRACT = {Empirical evidence shows that naive Bayesian classifiers perform quite well compared to more sophisticated classifiers, even in view of inaccuracies in their parameters. In this paper, we study the effects of such parameter inaccuracies by investigating the sensitivity functions of a naive Bayesian network. We show that, as a consequence of the network’s independence properties, these sensitivity functions are highly constrained. We further investigate whether the patterns of sensitivity that follow from these functions support the observed robustness of naive Bayesian classifiers. In addition to standard sensitivities given available evidence, we also study the effect of parameter inaccuracies in view of scenarios of additional evidence. We show that standard sensitivity functions suffice to describe such scenario sensitivities.},
  AUTHOR   = {Silja Renooij and Linda C. van der Gaag},
  DOI      = {10.1016/j.ijar.2008.02.008},
  KEYWORDS = {Naive Bayesian classifiers; Sensitivity; Robustness},
  FILE     = {files/Renooij+Gaag-IJAR08j.pdf},
  NUMBER   = {2},
  PAGES    = {398–416},
  TITLE    = {Evidence and scenario sensitivities in naive Bayesian classifiers},
  VOLUME   = {49},
  XDATA    = {IJAR},
  YEAR     = {2008},
}

@ARTICLE{Destercke+DC-IJAR08j_pboxes,
  AUTHOR = {Sébastien Destercke and Didier Dubois and E. Chojnacki},
  DOI    = {10.1016/j.ijar.2008.07.003},
  FILE   = {files/Destercke+DC-IJAR08j_pboxes.pdf},
  PAGES  = {649–663},
  TITLE  = {Unifying practical uncertainty representations: I. Generalized p-boxes},
  VOLUME = {49},
  XDATA  = {IJAR},
  YEAR   = {2008},
}

@ARTICLE{Destercke+DC-IJAR08j_clouds,
  ABSTRACT = {There exist many simple tools for jointly capturing variability and incomplete information by means of uncertainty representations. Among them are random sets, possibility distributions, probability intervals, and the more recent Ferson’s p-boxes and Neumaier’s clouds, both defined by pairs of possibility distributions. In the companion paper, we have extensively studied a generalized form of p-box and situated it with respect to other models. This paper focuses on the links between clouds and other representations. Generalized p-boxes are shown to be clouds with comonotonic distributions. In general, clouds cannot always be represented by random sets, in fact not even by two-monotone (convex) capacities.},
  AUTHOR   = {Sébastien Destercke and Didier Dubois and E. Chojnacki},
  DOI      = {10.1016/j.ijar.2008.07.004},
  KEYWORDS = {Imprecise probability representations; p-Boxes; Possibility theory; Random sets; Clouds; Probability intervals},
  FILE     = {files/Destercke+DC-IJAR08j_clouds.pdf},
  NUMBER   = {3},
  PAGES    = {664–677},
  TITLE    = {Unifying practical uncertainty representations. II: Clouds},
  VOLUME   = {49},
  XDATA    = {IJAR},
  YEAR     = {2008},
}

@ARTICLE{Cooman+MQ-IJAR08j,
  ABSTRACT   = {We consider immediate predictive inference, where a subject, using a number of observations of a finite number of exchangeable random variables, is asked to coherently model his beliefs about the next observation, in terms of a predictive lower prevision. We study when such predictive lower previsions are representation insensitive, meaning that they are essentially independent of the choice of the (finite) set of possible values for the random variables. We establish that such representation insensitive predictive models have very interesting properties, and show that among such models, the ones produced by the Imprecise Dirichlet-Multinomial Model are quite special in a number of ways. In the Conclusion, we discuss the open question as to how unique the predictive lower previsions of the Imprecise Dirichlet-Multinomial Model are in being representation insensitive.},
  AUTHOR     = {Gert de Cooman and Enrique Miranda and Erik Quaeghebeur},
  DOI        = {10.1016/j.ijar.2008.03.010},
  EPRINT     = {1854/LU-497890},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Coherence; Exchangeability; Immediate prediction; Imprecise Dirichlet-Multinomial Model; Imprecise probabilities; Johnson’s sufficientness postulate; Lower prevision; Predictive inference; Representation insensitivity; Representation invariance principle; Rule of Succession},
  FILE       = {files/Cooman+MQ-IJAR08j.pdf},
  NUMBER     = {2},
  PAGES      = {204–216},
  TITLE      = {Representation insensitivity in immediate prediction under exchangeability},
  VOLUME     = {50},
  XDATA      = {IJAR},
  YEAR       = {2009},
}

@ARTICLE{Coolen-Augustin-IJAR09j,
  ABSTRACT   = {Nonparametric predictive inference (NPI) is a general methodology to learn from data in the absence of prior knowledge and without adding unjustified assumptions. This paper develops NPI for multinomial data when the total number of possible categories for the data is known. We present the upper and lower probabilities for events involving the next observation and several of their properties. We also comment on differences between this NPI approach and corresponding inferences based on Walley's Imprecise Dirichlet Model.},
  ANNOTATION = {Special Section on The Imprecise Dirichlet Model and Special Section on Bayesian Robustness (Issues in Imprecise Probability)},
  AUTHOR     = {Frank P. A. Coolen and Thomas Augustin},
  DOI        = {10.1016/j.ijar.2008.03.011},
  KEYWORDS   = {Circular A(n); Imprecise Dirichlet Model; Imprecise probabilities; Interval probability; Lower and upper probabilities; Multinomial data; Nonparametric predictive inference; Rule of succession},
  LOCALFILE  = {files/Coolen-Augustin-IJAR09j.pdf},
  NUMBER     = {2},
  PAGES      = {217–230},
  TITLE      = {A nonparametric predictive alternative to the Imprecise Dirichlet Model: the case of a known number of categories},
  VOLUME     = {50},
  XDATA      = {IJAR},
  YEAR       = {2009},
}

@ARTICLE{Quaeghebeur+Cooman-IJAR09j,
  ABSTRACT   = {We propose a new learning model for finite strategic-form two-player games based on fictitious play and Walley's imprecise Dirichlet model [P. Walley, Inferences from multinomial data: learning about a bag of marbles, J. Roy. Statist. Soc. B 58 (1996) 3–57]. This model allows the initial beliefs of the players about their opponent’s strategy choice to be near-vacuous or imprecise instead of being precisely defined. A similar generalization can be made as the one proposed by Fudenberg and Kreps [D. Fudenberg, D.M. Kreps, Learning mixed equilibria, Games Econ. Behav. 5 (1993) 320–367] for fictitious play, where assumptions about immediate behavior are replaced with assumptions about asymptotic behavior. We also obtain similar convergence results for this generalization: if there is convergence, it will be to an equilibrium.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  DOI        = {10.1016/j.ijar.2008.03.012},
  EPRINT     = {1854/LU-495971},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Fictitious play; Imprecise probability models; Imprecise Dirichlet model; Decision making; Two-player games; Learning},
  NUMBER     = {2},
  PAGES      = {243–256},
  TITLE      = {Learning in games using the imprecise Dirichlet-model},
  VOLUME     = {50},
  XDATA      = {IJAR},
  YEAR       = {2009},
}

@ARTICLE{Gaag+TG-IJAR09j,
  ABSTRACT = {In many realistic problem domains, the main variable of interest behaves monotonically in the observable variables, in the sense that higher values for the variable of interest become more likely with higher-ordered observations. This type of knowledge appears to naturally emerge from experts during knowledge elicitation, without explicit prompting from the knowledge engineer. The experts’ concept of monotonicity, however, may not correspond to the mathematical concept of monotonicity in Bayesian networks. We present a method that provides both for verifying whether or not a network exhibits the properties of monotonicity suggested by the experts and for studying the violated properties with the experts. We illustrate the application of our method for a real Bayesian network in veterinary science.},
  AUTHOR   = {Linda C. van der Gaag and Hermina J. M. Tabachneck-Schijf and Petra L. Geenen},
  DOI      = {10.1016/j.ijar.2008.04.008},
  KEYWORDS = {Bayesian networks; Knowledge engineering},
  FILE     = {files/Gaag+TG-IJAR09j.pdf},
  NUMBER   = {3},
  PAGES    = {429–436},
  TITLE    = {Verifying monotonicity of Bayesian networks with domain experts},
  VOLUME   = {50},
  XDATA    = {IJAR},
  YEAR     = {2009},
}

@ARTICLE{Antonucci+BPZ-IJAR09j,
  ABSTRACT = {Credal networks are imprecise probabilistic graphical models generalizing Bayesian networks to convex sets of probability mass functions. This makes credal networks particularly suited to model expert knowledge under very general conditions, including states of qualitative and incomplete knowledge. In this paper, we present a credal network for risk evaluation in case of intrusion of civil aircrafts into a restricted flight area. The different factors relevant for this evaluation, together with an independence structure over them, are initially identified. These factors are observed by sensors, whose reliabilities can be affected by variable external factors, and even by the behaviour of the intruder. A model of these observation processes, and the necessary fusion scheme for the information returned by the sensors measuring the same factor, are both completely embedded into the structure of the credal network. A pool of experts, facilitated in their task by specific techniques to convert qualitative judgements into imprecise probabilistic assessments, has made possible the quantification of the network. We show the capabilities of the proposed model by means of some preliminary tests referred to simulated scenarios. Overall, we can regard this application as a useful tool to support military experts in their decision, but also as a quite general imprecise-probability paradigm for information fusion.},
  AUTHOR   = {Alessandro Antonucci and Ralph Brühlmann and Alberto Piatti and Marco Zaffalon},
  DATE     = {2009-04},
  DOI      = {10.1016/j.ijar.2009.01.005},
  KEYWORDS = {Credal networks; Information fusion; Sensor management; Tracking systems},
  FILE     = {files/Antonucci+BPZ-IJAR09j.pdf},
  NUMBER   = {4},
  PAGES    = {666–679},
  TITLE    = {Credal networks for military identification problems},
  VOLUME   = {50},
  XDATA    = {IJAR},
}

@article{Kouwen+RS-IJAR09j,
  ABSTRACT = {Qualitative probabilistic networks (QPNs) are basically qualitative derivations of Bayesian belief networks. Originally, QPNs were designed to improve the speed of the construction and calculation of these networks, at the cost of specificity of the result. The formalism can also be used to facilitate cognitive mapping by means of inference in sign-based causal diagrams. Whatever the type of application, any computer based use of QPNs requires an algorithm capable of propagating information throughout the networks. Such an algorithm was developed in the 1990s. This polynomial time sign-propagation algorithm is explicitly or implicitly used in most existing QPN studies. This paper firstly shows that two types of undesired results may occur with the original sign-propagation algorithm: the results can be (1) less specific than possible at the given level of abstraction, or, more seriously (2) incorrect. Secondly, the paper identifies the causes underlying these problems. Thirdly, this paper presents an adapted sign-propagation algorithm. The worst-case running time of the adapted algorithm is still polynomial in the number of arrows. The results of the new algorithm have been compared with those of the original algorithm by applying both algorithms to a real-life constructed cognitive map. It is shown that the problems of the original algorithm are indeed prevented with the adapted algorithm.},
  AUTHOR   = {Frank van Kouwen and Silja Renooij and Paul Schot},
  DATE     = {2009-05},
  DOI      = {10.1016/j.ijar.2008.12.001},
  KEYWORDS = {Qualitative probabilistic network; Inference; Cognitive mapping},
  FILE     = {files/Kouwen+RS-IJAR09j.pdf},
  NUMBER   = {5},
  PAGES    = {708–720},
  TITLE    = {Inference in qualitative probabilistic networks revisited},
  VOLUME   = {50},
  XDATA    = {IJAR},
}

@ARTICLE{Skulj-IJAR09j,
  ABSTRACT = {The parameters of Markov chain models are often not known precisely. Instead of ignoring this problem, a better way to cope with it is to incorporate the imprecision into the models. This has become possible with the development of models of imprecise probabilities, such as the interval probability model. In this paper we discuss some modelling approaches which range from simple probability intervals to the general interval probability models and further to the models allowing completely general convex sets of probabilities. The basic idea is that precisely known initial distributions and transition matrices are replaced by imprecise ones, which effectively means that sets of possible candidates are considered. Consequently, sets of possible results are obtained and represented using similar imprecise probability models. We first set up the model and then show how to perform calculations of the distributions corresponding to the consecutive steps of a Markov chain. We present several approaches to such calculations and compare them with respect to the accuracy of the results. Next we consider a generalisation of the concept of regularity and study the convergence of regular imprecise Markov chains. We also give some numerical examples to compare different approaches to calculations of the sets of probabilities.},
  AUTHOR   = {Damjan Škulj},
  DOI      = {10.1016/j.ijar.2009.06.007},
  KEYWORDS = {Imprecise Markov chains; Imprecise probabilities; Interval probabilities; Markov chains; Regularity},
  FILE     = {files/Skulj-IJAR09j.pdf},
  NUMBER   = {8},
  PAGES    = {1314–1329},
  TITLE    = {Discrete time Markov chains with interval probabilities},
  VOLUME   = {50},
  XDATA    = {IJAR},
  YEAR     = {2009},
}

@ARTICLE{Gaag+Tabachneck-IJAR10j,
  ABSTRACT = {The next development in building Bayesian networks will most likely entail constructing multi-purpose models that can be employed for varying tasks and by different types of user. In this position paper, we argue that the development of a special type of ontology to organize the knowledge involved in such a multi-purpose model is crucial for the management of the model’s content. This ontology should preserve all knowledge elicited for the construction of the model and be accessible to domain experts and knowledge engineers alike. Based on the different ways in which people learn and gain expertise, we further argue that knowledge elicitation will result in task-specific knowledge mostly, which is best stored in the format in which it is elicited. To support varying model views for different tasks and different types of user, we propose that the elicited knowledge be organized in a library-style ontology of separate modules.},
  AUTHOR   = {Linda C. van der Gaag and Hermina J. M. Tabachneck-Schijf},
  DOI      = {10.1016/j.ijar.2009.05.008},
  KEYWORDS = {Bayesian networks; Engineering; Task model views; Ontology},
  FILE     = {files/Gaag+Tabachneck-IJAR10j.pdf},
  NUMBER   = {2},
  PAGES    = {196–208},
  TITLE    = {Library-style ontologies to support varying model views},
  VOLUME   = {51},
  XDATA    = {IJAR},
  YEAR     = {2010},
}

@ARTICLE{Antonucci+SCZ-IJAR10j,
  ABSTRACT = {Credal networks generalize Bayesian networks by relaxing the requirement of precision of probabilities. Credal networks are considerably more expressive than Bayesian networks, but this makes belief updating NP-hard even on polytrees. We develop a new efficient algorithm for approximate belief updating in credal networks. The algorithm is based on an important representation result we prove for general credal networks: that any credal network can be equivalently reformulated as a credal network with binary variables; moreover, the transformation, which is considerably more complex than in the Bayesian case, can be implemented in polynomial time. The equivalent binary credal network is then updated by L2U, a loopy approximate algorithm for binary credal networks. Overall, we generalize L2U to non-binary credal networks, obtaining a scalable algorithm for the general case, which is approximate only because of its loopy nature. The accuracy of the inferences with respect to other state-of-the-art algorithms is evaluated by extensive numerical tests.},
  AUTHOR   = {Alessandro Antonucci and Yi Sun and Cassio Polpo de Campos and Marco Zaffalon},
  DOI      = {10.1016/j.ijar.2010.01.007},
  FILE     = {files/Antonucci+SCZ-IJAR10j.pdf},
  NUMBER   = {5},
  PAGES    = {474–484},
  TITLE    = {Generalized loopy 2U: a new algorithm for approximate inference in credal networks},
  VOLUME   = {51},
  XDATA    = {IJAR},
  YEAR     = {2010},
}

@ARTICLE{Cooman+HAZ-IJAR10j,
  ABSTRACT = {We focus on credal nets, which are graphical models that generalise Bayesian nets to imprecise probability. We replace the notion of strong independence commonly used in credal nets with the weaker notion of epistemic irrelevance, which is arguably more suited for a behavioural theory of probability. Focusing on directed trees, we show how to combine the given local uncertainty models in the nodes of the graph into a global model, and we use this to construct and justify an exact message-passing algorithm that computes updated beliefs for a variable in the tree. The algorithm, which is linear in the number of nodes, is formulated entirely in terms of coherent lower previsions, and is shown to satisfy a number of rationality requirements. We supply examples of the algorithm's operation, and report an application to on-line character recognition that illustrates the advantages of our approach for prediction. We comment on the perspectives, opened by the availability, for the first time, of a truly efficient algorithm based on epistemic irrelevance.},
  AUTHOR   = {Gert de Cooman and Filip Hermans and Alessandro Antonucci and Marco Zaffalon},
  DATE     = {2010-11},
  DOI      = {10.1016/j.ijar.2010.08.011},
  KEYWORDS = {Coherence; Credal net; Epistemic irrelevance; Hidden Markov model; Separation; Strong independence},
  FILE     = {files/Cooman+HAZ-IJAR10j.pdf},
  NUMBER   = {9},
  PAGES    = {1029–1052},
  TITLE    = {Epistemic irrelevance in credal nets: the case of imprecise Markov trees},
  VOLUME   = {51},
  XDATA    = {IJAR},
}

@ARTICLE{Couso+Moral-IJAR11j,
  ABSTRACT = {The theory of sets of desirable gambles is a very general model which covers most of the existing theories for imprecise probability as special cases; it has a clear and simple axiomatic justification; and mathematical definitions are natural and intuitive. However, much work remains to be done until the theory of desirable gambles can be considered as generally applicable to reasoning tasks as other approaches to imprecise probability are. This paper gives an overview of some of the fundamental concepts for reasoning with uncertainty expressed in terms of desirable gambles in the finite case, provides a characterization of regular extension, and studies the nature of maximally coherent sets of desirable gambles, which correspond to finite sequences of probability distributions, each one of them defined on the set where the previous one assigns probability zero.},
  AUTHOR   = {Inés Couso and Serafín Moral},
  DOI      = {10.1016/j.ijar.2011.04.004},
  FILE     = {files/Couso+Moral-IJAR11j.pdf},
  NUMBER   = {7},
  PAGES    = {1034–1055},
  TITLE    = {Sets of desirable gambles: conditioning, representation, and precise probabilities},
  VOLUME   = {52},
  XDATA    = {IJAR},
  YEAR     = {2011},
}

@ARTICLE{Cooman+Quaeghebeur-IJAR12j,
  ABSTRACT   = {Sets of desirable gambles constitute a quite general type of uncertainty model with an interesting geometrical interpretation. We give a general discussion of such models and their rationality criteria. We study exchangeability assessments for them, and prove counterparts of de Finetti's finite and infinite representation theorems. We show that the finite representation in terms of count vectors has a very nice geometrical interpretation, and that the representation in terms of frequency vectors is tied up with multivariate Bernstein (basis) polynomials. We also lay bare the relationships between the representations of updated exchangeable models, and discuss conservative inference (natural extension) under exchangeability and the extension of exchangeable sequences.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur},
  DOI        = {10.1016/j.ijar.2010.12.002},
  EPRINT     = {1854/LU-1106209},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Extending an exchangeable sequence; prevision; Updating; Natural extension; Representation; Exchangeability; Sets of desirable gambles},
  FILE       = {files/Cooman+Quaeghebeur-IJAR12j.pdf},
  NUMBER     = {3},
  PAGES      = {363–395},
  TITLE      = {Exchangeability and sets of desirable gambles},
  VOLUME     = {53},
  YEAR       = {2012},
  XDATA      = {IJAR},
}

@ARTICLE{Renooij-IJAR12j,
  ABSTRACT   = {Sensitivity analysis in hidden Markov models (HMMs) is usually performed by means of a perturbation analysis where a small change is applied to the model parameters, upon which the output of interest is re-computed. Recently it was shown that a simple mathematical function describes the relation between HMM parameters and an output probability of interest; this result was established by representing the HMM as a (dynamic) Bayesian network. To determine this sensitivity function, it was suggested to employ existing Bayesian network algorithms. Up till now, however, no special purpose algorithms for establishing sensitivity functions for HMMs existed. In this paper we discuss the drawbacks of computing HMM sensitivity functions, building only upon existing algorithms. We then present a new and efficient algorithm, which is specially tailored for determining sensitivity functions in HMMs.},
  AUTHOR     = {Silja Renooij},
  DATE       = {2012-12},
  DOI        = {10.1016/j.ijar.2012.06.003},
  ISSUETITLE = {Fifth European Workshop on Probabilistic Graphical Models (PGM-2010)},
  KEYWORDS   = {Sensitivity analysis; Bayesian networks; Hidden Markov models; Sensitivity function},
  NUMBER     = {9},
  PAGES      = {1397–1414},
  TITLE      = {Efficient sensitivity analysis in hidden markov models},
  VOLUME     = {53},
  XDATA      = {IJAR},
}

@XDATA{IJAR56B,
  DATE       = {2015-01},
  ISSUETITLE = {Eighth International Symposium on Imprecise Probability: Theories and Applications (ISIPTA 2013)},
  PART       = {B},
  VOLUME     = {56},
  XDATA      = {IJAR},
}

@ARTICLE{Bock+Cooman-IJAR15j,
  AUTHOR = {De Bock, Jasper and Gert de Cooman},
  FILE   = {files/Bock+Cooman-IJAR15j.pdf},
  DOI    = {10.1016/j.ijar.2014.07.002},
  PAGES  = {178–207},
  TITLE  = {Credal networks under epistemic irrelevance: The sets of desirable gambles approach},
  XDATA  = {IJAR56B},
}

@ARTICLE{Quaeghebeur-IJAR15j,
  ABSTRACT   = {Lower previsions defined on a finite set of gambles can be looked at as points in a finite-dimensional real vector space. Within that vector space, the sets of sure loss avoiding and coherent lower previsions form convex polyhedra. We present procedures for obtaining characterizations of these polyhedra in terms of a minimal, finite number of linear constraints. As compared to the previously known procedure, these procedures are more efficient and much more straightforward. Next, we take a look at a procedure for correcting incoherent lower previsions based on pointwise dominance. This procedure can be formulated as a multi-objective linear program, and the availability of the finite characterizations provide an avenue for making these programs computationally feasible.},
  AUTHOR     = {Erik Quaeghebeur},
  DOI        = {10.1016/j.ijar.2014.03.005},
  KEYWORDS   = {Coherence; Avoiding sure loss; Polytope theory; Multi-objective linear programming; Incoherence; Dominance},
  TITLE      = {Characterizing coherence, correcting incoherence},
  PAGES      = {208–223},
  XDATA      = {IJAR56B},
}

@ARTICLE{Quaeghebeur+CH-IJAR15j,
  ABSTRACT   = {We develop a framework for modelling and reasoning with uncertainty based on accept and reject statements about gambles. It generalises the frameworks found in the literature based on statements of acceptability, desirability, or favourability and clarifies their relative position. Next to the statement-based formulation, we also provide a translation in terms of preference relations, discuss—as a bridge to existing frameworks—a number of simplified variants, and show the relationship with prevision-based uncertainty models. We furthermore provide an application to modelling symmetry judgements.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Filip Hermans},
  DATE       = {2015-02},
  DOI        = {10.1016/j.ijar.2014.12.003},
  EPRINT     = {1208.4462},
  EPRINTTYPE = {arxiv},
  FILE       = {files/Quaeghebeur+CH-IJAR15j.pdf},
  KEYWORDS   = {Acceptability; Indifference; Desirability; Favourability; Preference; Prevision},
  TITLE      = {Accept \& reject statement-based uncertainty models},
  PAGES      = {69–102},
  VOLUME     = {57},
  XDATA      = {IJAR},
}

@XDATA{AIJ,
  ISSN         = {0004-3702},
  JOURNALTITLE = {Artificial Intelligence},
  PUBLISHER    = {Elsevier},
  SHORTJOURNAL = {Artif. Intell.}
}

@ARTICLE{Wellman-AIJ90j,
  ABSTRACT = {Graphical representations for probabilistic relationships have recently received considerable attention in AI. Qualitative probabilistic networks abstract from the usual numeric representations by encoding only qualitative relationships, which are inequality constraints on the joint probability distribution over the variables. Although these constraints are insufficient to determine probabilities uniquely, they are designed to justify the deduction of a class of relative likelihood conclusions that imply useful decision-making properties. Two types of qualitative relationship are defined, each a probabilistic form of monotonicity constraint over a group of variables. Qualitative influences describe the direction of the relationship between two variables. Qualitative synergies describe interactions among influences. The probabilistic definitions chosen justify sound and efficient inference procedures based on graphical manipulations of the network. These procedures answer queries about qualitative relationships among variables separated in the network and determine structural properties of optimal assignments to decision variables.},
  AUTHOR   = {Michael P. Wellman},
  DOI      = {10.1016/0004-3702(90)90026-V},
  FILE     = {files/Wellman-AIJ90j.pdf},
  NUMBER   = {3},
  PAGES    = {257–303},
  TITLE    = {Fundamental concepts of qualitative probabilistic networks},
  VOLUME   = {44},
  XDATA    = {AIJ},
  YEAR     = {1990},
}

@ARTICLE{Walley-AIJ96j,
  ABSTRACT = {This paper compares four measures that have been advocated as models for uncertainty in expert systems. The measures are additive probabilities (used in the Bayesian theory), coherent lower (or upper) previsions, belief functions (used in the Dempster-Shafer theory) and possibility measures (fuzzy logic). Special emphasis is given to the theory of coherent lower previsions, in which upper and lower probabilities, expectations and conditional probabilities are constructed from initial assessments through a technique of natural extension. Mathematically, all the measures can be regarded as types of coherent lower or upper previsions, and this perspective gives some insight into the properties of belief functions and possibility measures. The measures are evaluated according to six criteria: clarity of interpretation; ability to model partial information and imprecise assessments, especially judgements expressed in natural language; rules for combining and updating uncertainty, and their justification; consistency of models and inferences; feasibility of assessment; and feasibility of computations. Each of the four measures seems to be useful in special kinds of problems, but only lower and upper previsions appear to be sufficiently general to model the most common types of uncertainty.},
  AUTHOR   = {Peter Walley},
  DOI      = {10.1016/0004-3702(95)00009-7},
  KEYWORDS = {Bayesian theory; Belief functions; Conditional probability; Decision; Dempster–Shafer theory; Imprecise probabilities; Inference; Lower probability; Possibility theory; Prevision; Upper probability; lndependence},
  FILE     = {files/Walley-AIJ96j.pdf},
  PAGES    = {1–58},
  TITLE    = {Measures of uncertainty in expert systems},
  VOLUME   = {83},
  XDATA    = {AIJ},
  YEAR     = {1996},
}

@ARTICLE{Cozman-AIJ00j,
  ABSTRACT = {This paper presents a complete theory of credal networks, structures that associate convex sets of probability measures with directed acyclic graphs. Credal networks are graphical models for precise/imprecise beliefs. The main contribution of this work is a theory of credal networks that displays as much flexibility and representational power as the theory of standard Bayesian networks. Results in this paper show how to express judgements of irrelevance and independence, and how to compute inferences in credal networks. A credal network admits several extensions–several sets of probability measures comply with the constraints represented by a network. Two types of extensions are investigated. The properties of strong extensions are clarified through a new generalization of d-separation, and exact and approximate inference methods are described for strong extensions. Novel results are presented for natural extensions, and linear fractional programming methods are described for natural extensions. The paper also investigates credal networks that are defined globally through perturbations of a single network.},
  AUTHOR   = {Fabio Gagliardi Cozman},
  DOI      = {10.1016/S0004-3702(00)00029-1},
  KEYWORDS = {Bayesian networks; Convex sets of probability measures; Graphical d-separation relations; Graphical models of inference; Independence relations; Lower and upper expectations; Robust Bayesian analysis},
  FILE     = {files/Cozman-AIJ00j.pdf},
  NUMBER   = {2},
  PAGES    = {199–233},
  TITLE    = {Credal networks},
  VOLUME   = {120},
  XDATA    = {AIJ},
  YEAR     = {2000},
}

@ARTICLE{Renooij+GP-AIJ02j,
  ABSTRACT = {Qualitative probabilistic networks are qualitative abstractions of probabilistic networks, summarising probabilistic influences by qualitative signs. As qualitative networks model influences at the level of variables, knowledge about probabilistic influences that hold only for specific values cannot be expressed. The results computed from a qualitative network, as a consequence, can be weaker than strictly necessary and may in fact be rather uninformative. We extend the basic formalism of qualitative probabilistic networks by providing for the inclusion of context-specific information about influences and show that exploiting this information upon reasoning has the ability to forestall unnecessarily weak results.},
  AUTHOR   = {Silja Renooij and Linda C. van der Gaag and Simon Parsons},
  DOI      = {10.1016/S0004-3702(02)00247-3},
  KEYWORDS = {Probabilistic reasoning; Qualitative reasoning; Context-specific independence; Non-monotonicity},
  NUMBER   = {1-2},
  PAGES    = {207–230},
  TITLE    = {Context-specific sign-propagation in qualitative probabilistic networks},
  VOLUME   = {140},
  XDATA    = {AIJ},
  YEAR     = {2002},
}


@ARTICLE{Cooman+Hermans-AIJ08,
  ABSTRACT = {We give an overview of two approaches to probability theory where lower and upper probabilities, rather than probabilities, are used: Walley's behavioural theory of imprecise probabilities, and Shafer and Vovk's game-theoretic account of probability. We show that the two theories are more closely related than would be suspected at first sight, and we establish a correspondence between them that (i) has an interesting interpretation, and (ii) allows us to freely import results from one theory into the other. Our approach leads to an account of probability trees and random processes in the framework of Walley's theory. We indicate how our results can be used to reduce the computational complexity of dealing with imprecision in probability trees, and we prove an interesting and quite general version of the weak law of large numbers.},
  AUTHOR   = {Gert de Cooman and Filip Hermans},
  DOI      = {10.1016/j.artint.2008.03.001},
  KEYWORDS = {Coherence; Conglomerability; Event tree; Game-theoretic probability; Hoeffding’s inequality; Immediate prediction; Imprecise probabilities; Imprecise probability tree; Law of large numbers; Lower prevision; Markov chain; Prequential Principle; Probability tree; Random process},
  FILE     = {files/Cooman+Hermans-AIJ08.pdf},
  NUMBER   = {11},
  PAGES    = {1400–1427},
  TITLE    = {Imprecise probability trees: Bridging two theories of imprecise probability},
  VOLUME   = {172},
  XDATA    = {AIJ},
  YEAR     = {2008},
}

@ARTICLE{Renooij+Gaag-AIJ08j,
  ABSTRACT = {Qualitative probabilistic networks were designed to overcome, to at least some extent, the quantification problem known to probabilistic networks. Qualitative networks abstract from the numerical probabilities of their quantitative counterparts by using signs to summarise the probabilistic influences between their variables. One of the major drawbacks of these qualitative abstractions, however, is the coarse level of representation detail that does not provide for indicating strengths of influences. As a result, the trade-offs modelled in a network remain unresolved upon inference. We present an enhanced formalism of qualitative probabilistic networks to provide for a finer level of representation detail. An enhanced qualitative probabilistic network differs from a basic qualitative network in that it distinguishes between strong and weak influences. Now, if a strong influence is combined, upon inference, with a conflicting weak influence, the sign of the net influence may be readily determined. Enhanced qualitative networks are purely qualitative in nature, as basic qualitative networks are, yet allow for resolving some trade-offs upon inference.},
  AUTHOR   = {Silja Renooij and Linda C. van der Gaag},
  DOI      = {10.1016/j.artint.2008.04.001},
  KEYWORDS = {Probabilistic reasoning; Qualitative reasoning; Trade-off resolution},
  NUMBER   = {12-13},
  PAGES    = {1470–1494},
  TITLE    = {Enhanced qualitative probabilistic networks for resolving trade-offs},
  VOLUME   = {172},
  XDATA    = {AIJ},
  YEAR     = {2008},
}

@ARTICLE{Miranda+Zaffalon-AIJ09j,
  ABSTRACT = {We study the consistency of a number of probability distributions, which are allowed to be imprecise. To make the treatment as general as possible, we represent those probabilistic assessments as a collection of conditional lower previsions. The problem then becomes proving Walley's (strong) coherence of the assessments. In order to maintain generality in the analysis, we assume to be given nearly no information about the numbers that make up the lower previsions in the collection. Under this condition, we investigate the extent to which the above global task can be decomposed into simpler and more local ones. This is done by introducing a graphical representation of the conditional lower previsions that we call the coherence graph: we show that the coherence graph allows one to isolate some subsets of the collection whose coherence is sufficient for the coherence of all the assessments; and we provide a polynomial-time algorithm that finds the subsets efficiently. We show some of the implications of our results by focusing on three models and problems: Bayesian and credal networks, of which we prove coherence; the compatibility problem, for which we provide an optimal graphical decomposition; probabilistic satisfiability, of which we show that some intractable instances can instead be solved efficiently by exploiting coherence graphs.},
  AUTHOR   = {Enrique Miranda and Marco Zaffalon},
  DOI      = {10.1016/j.artint.2008.09.001},
  KEYWORDS = {Walley's strong and weak coherence; Coherent lower previsions; Graphical models; Probabilistic logic; Satisfiability},
  FILE     = {files/Miranda+Zaffalon-AIJ09j.pdf},
  NUMBER   = {1},
  PAGES    = {104–144},
  TITLE    = {Coherence graphs},
  VOLUME   = {173},
  XDATA    = {AIJ},
  YEAR     = {2009},
}

@ARTICLE{Cooman+MZ-AIJ11j,
  ABSTRACT = {There is no unique extension of the standard notion of probabilistic independence to the case where probabilities are indeterminate or imprecisely specified. Epistemic independence is an extension that formalises the intuitive idea of mutual irrelevance between different sources of information. This gives epistemic independence very wide scope as well as appeal: this interpretation of independence is often taken as natural also in precise-probabilistic contexts. Nevertheless, epistemic independence has received little attention so far. This paper develops the foundations of this notion for variables assuming values in finite spaces. We define (epistemically) independent products of marginals (or possibly conditionals) and show that there always is a unique least-committal such independent product, which we call the independent natural extension. We supply an explicit formula for it, and study some of its properties, such as associativity, marginalisation and external additivity, which are basic tools to work with the independent natural extension. Additionally, we consider a number of ways in which the standard factorisation formula for independence can be generalised to an imprecise-probabilistic context. We show, under some mild conditions, that when the focus is on least-committal models, using the independent natural extension is equivalent to imposing a so-called strong factorisation property. This is an important outcome for applications as it gives a simple tool to make sure that inferences are consistent with epistemic independence judgements. We discuss the potential of our results for applications in Artificial Intelligence by recalling recent work by some of us, where the independent natural extension was applied to graphical models. It has allowed, for the first time, the development of an exact linear-time algorithm for the imprecise probability updating of credal trees.},
  AUTHOR   = {Gert de Cooman and Enrique Miranda and Marco Zaffalon},
  DOI      = {10.1016/j.artint.2011.06.001},
  KEYWORDS = {Epistemic irrelevance; Epistemic independence; Independent natural extension; Strong product; Factorisation; Coherent lower previsions},
  FILE     = {files/Cooman+MZ-AIJ11j.pdf},
  NUMBER   = {12–13},
  PAGES    = {1911–1950},
  TITLE    = {Independent natural extension},
  VOLUME   = {175},
  XDATA    = {AIJ},
  YEAR     = {2011},
}

@ARTICLE{Zaffalon+Miranda-AIJ13j,
  ABSTRACT     = {Probabilistic reasoning is often attributed a temporal meaning, in which conditioning is regarded as a normative rule to compute future beliefs out of current beliefs and observations. However, the well-established ‘updating interpretation’ of conditioning is not concerned with beliefs that evolve in time, and in particular with future beliefs. On the other hand, a temporal justification of conditioning was proposed already by De Moivre and Bayes, by requiring that current and future beliefs be consistent. We reconsider the latter approach while dealing with a generalised version of the problem, using a behavioural theory of imprecise probability in the form of coherent lower previsions as well as of coherent sets of desirable gambles, and letting the possibility space be finite or infinite. We obtain that using conditioning is normative, in the imprecise case, only if one establishes future behavioural commitments at the same time of current beliefs. In this case it is also normative that present beliefs be conglomerable, which is a result that touches on a long-term controversy at the foundations of probability. In the remaining case, where one commits to some future behaviour after establishing present beliefs, we characterise the several possibilities to define consistent future assessments; this shows in particular that temporal consistency does not preclude changes of mind. And yet, our analysis does not support that rationality requires consistency in general, even though pursuing consistency makes sense and is useful, at least as a way to guide and evaluate the assessment process. These considerations narrow down in the special case of precise probability, because this formalism cannot distinguish the two different situations illustrated above: it turns out that the only consistent rule is conditioning and moreover that it is not rational to be willing to stick to precise probability while using a rule different from conditioning to compute future beliefs; rationality requires in addition the disintegrability of the present-time probability.},
  AUTHOR       = {Marco Zaffalon and Enrique Miranda},
  DOI          = {10.1016/j.artint.2013.02.005},
  KEYWORDS     = {Temporal reasoning; Imprecise probabilities; Conditioning; Lower previsions; Sets of desirable gambles; Coherence; Conglomerability},
  FILE    = {files/Zaffalon+Miranda-AIJ13j.pdf},
  PAGES        = {1–51},
  TITLE        = {Probability and time},
  VOLUME       = {198},
  XDATA     = {AIJ},
  YEAR         = {2013},
}

@XDATA{JAIR,
  JOURNALTITLE = {Journal of Artificial Intelligence Research},
  SHORTJOURNAL = {J. Artif. Intell. Res.},
}

@ARTICLE{Lubin+JCLSP-JAIR08j,
  ABSTRACT = {We present the design and analysis of the first fully expressive, iterative combinatorial exchange (ICE). The exchange incorporates a tree-based bidding language (TBBL) that is concise and expressive for CEs. Bidders specify lower and upper bounds in TBBL on their value for different trades and refine these bounds across rounds. These bounds allow price discovery and useful preference elicitation in early rounds, and allow termination with an efficient trade despite partial information on bidder valuations. All computation in the exchange is carefully optimized to exploit the structure of the bid-trees and to avoid enumerating trades. A proxied interpretation of a revealed-preference activity rule, coupled with simple linear prices, ensures progress across rounds. The exchange is fully implemented, and we give results demonstrating several aspects of its scalability and economic properties with simulated bidding strategies.},
  AUTHOR   = {B. Lubin and A. I. Juda and R. Cavallo and S. Lahaie and J. Shneidman and D. C. Parkes},
  DOI      = {10.1613/jair.2440},
  FILE     = {files/Lubin+JCLSP-JAIR08j.pdf},
  PAGES    = {33–77},
  TITLE    = {ICE: An expressive iterative combinatorial exchange},
  VOLUME   = {33},
  XDATA    = {JAIR},
  YEAR     = {2008},
}

@ARTICLE{Jurca+Faltings-JAIR09j,
  ABSTRACT = {We consider schemes for obtaining truthful reports on a common but hidden signal from large groups of rational, self-interested agents. One example are online feedback mechanisms, where users provide observations about the quality of a product or service so that other users can have an accurate idea of what quality they can expect. However, (i) providing such feedback is costly, and (ii) there are many motivations for providing incorrect feedback.

  Both problems can be addressed by reward schemes which (i) cover the cost of obtaining and reporting feedback, and (ii) maximize the expected reward of a rational agent who reports truthfully. We address the design of such incentive-compatible rewards for feedback generated in environments with pure adverse selection. Here, the correlation between the true knowledge of an agent and her beliefs regarding the likelihoods of reports of other agents can be exploited to make honest reporting a Nash equilibrium.

  In this paper we extend existing methods for designing incentive-compatible rewards by also considering collusion. We analyze different scenarios, where, for example, some or all of the agents collude. For each scenario we investigate whether a collusion-resistant, incentive-compatible reward scheme exists, and use automated mechanism design to specify an algorithm for deriving an efficient reward mechanism.},
  AUTHOR   = {R. Jurca and B. Faltings},
  DOI      = {10.1613/jair.2621},
  FILE     = {files/Jurca+Faltings-JAIR09j.pdf},
  PAGES    = {209–253},
  TITLE    = {Mechanisms for Making Crowds Truthful},
  VOLUME   = {34},
  XDATA    = {JAIR},
  YEAR     = {2009},
}

@ARTICLE{Cooman+Miranda-JAIR12j,
  ABSTRACT = {The results in this paper add useful tools to the theory of sets of desirable gambles, a growing toolbox for reasoning with partial probability assessments. We investigate how to combine a number of marginal coherent sets of desirable gambles into a joint set using the properties of epistemic irrelevance and independence. We provide formulas for the smallest such joint, called their independent natural extension, and study its main properties. The independent natural extension of maximal coherent sets of desirable gambles allows us to define the strong product of sets of desirable gambles. Finally, we explore an easy way to generalise these results to also apply for the conditional versions of epistemic irrelevance and independence. Having such a set of tools that are easily implemented in computer programs is clearly beneficial to fields, like AI, with a clear interest in coherent reasoning under uncertainty using general and robust uncertainty models that require no full specification.},
  AUTHOR   = {Gert de Cooman and Enrique Miranda},
  DOI      = {10.1613/jair.3770},
  FILE     = {files/Cooman+Miranda-JAIR12j.pdf},
  PAGES    = {601–640},
  TITLE    = {Irrelevant and independent natural extension for sets of desirable gambles},
  VOLUME   = {45},
  XDATA    = {JAIR},
  YEAR     = {2012},
}

@ARTICLE{Greco+Scarcello-JAIR14j,
  ABSTRACT = {Mechanism design is considered in the context of fair allocations of indivisible goods with monetary compensation, by focusing on problems where agents' declarations on allocated goods can be verified before payments are performed. A setting is considered where verification might be subject to errors, so that payments have to be awarded under the presumption of innocence, as incorrect declared values do not necessarily mean manipulation attempts by the agents. Within this setting, a mechanism is designed that is shown to be truthful, efficient, and budget-balanced. Moreover, agents' utilities are fairly determined by the Shapley value of suitable coalitional games, and enjoy highly desirable properties such as equal treatment of equals, envy-freeness, and a stronger one called individual-optimality. In particular, the latter property guarantees that, for every agent, her/his utility is the maximum possible one over any alternative optimal allocation.

  The computational complexity of the proposed mechanism is also studied. It turns out that it is \#P-complete so that, to deal with applications with many agents involved, two polynomial-time randomized variants are also proposed: one that is still truthful and efficient, and which is approximately budget-balanced with high probability, and another one that is truthful in expectation, while still budget-balanced and efficient.},
  AUTHOR   = {G. Greco and F. Scarcello},
  DOI      = {10.1613/jair.4224},
  FILE     = {files/Greco+Scarcello-JAIR14j.pdf},
  PAGES    = {403–403},
  TITLE    = {Mechanisms for fair allocation problems: no-punishment payment rules in verifiable settings},
  VOLUME   = {49},
  XDATA    = {JAIR},
  YEAR     = {2014},
}

@ARTICLE{Cooman+BD-JAIR15j,
  ABSTRACT = {Coherent reasoning under uncertainty can be represented in a very general manner by coherent sets of desirable gambles. In a context that does not allow for indecision, this leads to an approach that is mathematically equivalent to working with coherent conditional probabilities. If we do allow for indecision, this leads to a more general foundation for coherent (imprecise-)probabilistic inference. In this framework, and for a given finite category set, coherent predictive inference under exchangeability can be represented using Bernstein coherent cones of multivariate polynomials on the simplex generated by this category set. This is a powerful generalisation of de Finetti's Representation Theorem allowing for both imprecision and indecision.

  We define an inference system as a map that associates a Bernstein coherent cone of polynomials with every finite category set. Many inference principles encountered in the literature can then be interpreted, and represented mathematically, as restrictions on such maps. We discuss, as particular examples, two important inference principles: representation insensitivity—a strengthened version of Walley's representation invariance—and specificity. We show that there is an infinity of inference systems that satisfy these two principles, amongst which we discuss in particular the skeptically cautious inference system, the inference systems corresponding to (a modified version of) Walley and Bernard's Imprecise Dirichlet Multinomial Models (IDMM), the skeptical IDMM inference systems, and the Haldane inference system. We also prove that the latter produces the same posterior inferences as would be obtained using Haldane's improper prior, implying that there is an infinity of proper priors that produce the same coherent posterior inferences as Haldane's improper one. Finally, we impose an additional inference principle that allows us to characterise uniquely the immediate predictions for the IDMM inference systems.},
  AUTHOR   = {Gert de Cooman and De Bock, Jasper and Márcio Alves Diniz},
  DOI      = {10.1613/jair.4490},
  FILE     = {files/Cooman+BD-JAIR15j.pdf},
  PAGES    = {1–95},
  TITLE    = {Coherent predictive inference under exchangeability with imprecise probabilities},
  VOLUME   = {52},
  XDATA    = {JAIR},
  YEAR     = {2015},
}


@XDATA{AOS,
  JOURNALTITLE = {The Annals of Statistics},
  PUBLISHER    = {Institute of Mathematical Statistics},
  SHORTJOURNAL = {Ann. Stat.},
}

@ARTICLE{Seidenfeld+SK-AOS95j,
  AUTHOR   = {Teddy Seidenfeld and Mark J. Schervish and Joseph B. Kadane},
  DOI      = {10.1214/aos/1034713653},
  KEYWORDS = {Axioms of decision theory; partial order; robust},
  FILE     = {files/Seidenfeld+SK-AOS95j.pdf},
  MONTH    = {12},
  NUMBER   = {6},
  PAGES    = {2168–2217},
  TITLE    = {A representation of partially ordered preferences},
  VOLUME   = {23},
  XDATA    = {AOS},
  YEAR     = {1995},
}

@XDATA{AOMS,
  JOURNALTITLE = {The Annals of Mathematical Statistics},
  PUBLISHER    = {Institute of Mathematical Statistics},
}

@ARTICLE{Dempster-AOMS67j,
  ABSTRACT = {A multivalued mapping from a space X to a space S carries a probability measure defined over subsets of X into a system of upper and lower probabilities over subsets of S. Some basic properties of such systems are explored in Sections 1 and 2. Other approaches to upper and lower probabilities are possible and some of these are related to the present approach in Section 3. A distinctive feature of the present approach is a rule for conditioning, or more generally, a rule for combining sources of information, as discussed in Sections 4 and 5. Finally, the context in statistical inference from which the present theory arose is sketched briefly in Section 6.},
  AUTHOR   = {Arthur P. Dempster},
  DATE     = {1967-04},
  FILE     = {files/Dempster-AOMS67j.pdf},
  NUMBER   = {2},
  PAGES    = {325–339},
  TITLE    = {Upper and lower probabilities induced by a multivalued mapping},
  URL      = {http://www.jstor.org/stable/2239146},
  VOLUME   = {38},
  XDATA    = {AOMS},
}


@XDATA{AMAI,
  JOURNALTITLE = {Annals of Mathematics and Artificial Intelligence},
  SHORTJOURNAL = {Ann. Math. Artif. Intell.},
}

@article{Baioletti+CTV-AMAI02j,
  AUTHOR   = {Baioletti, Marco and Capotorti, Andrea and Tulipani, Sauro and Vantaggi, Barbara},
  DOI      = {10.1023/A:1014585822798},
  FILE     = {files/Baioletti+CTV-AMAI02j.pdf},
  KEYWORDS = {coherent probability assessment; probabilistic satisfiability; simplification rules},
  NUMBER   = {1-4},
  PAGES    = {11-28},
  TITLE    = {Simplification Rules for the Coherent Probability Assessment Problem},
  VOLUME   = {35},
  XDATA    = {AMAI},
  YEAR     = {2002},
}

@article{Pretolani-AMAI05j,
  AUTHOR   = {Pretolani, Daniele},
  DOI      = {10.1007/s10472-005-0430-8},
  FILE     = {files/Pretolani-AMAI05j.pdf},
  KEYWORDS = {probability; logic; CNF formulas; propositional satisfiability; directed graphs; ideal matrices},
  NUMBER   = {1-4},
  PAGES    = {211-221},
  TITLE    = {Probability logic and optimization SAT: The PSAT and CPA models},
  VOLUME   = {43},
  XDATA    = {AMAI},
  YEAR     = {2005},
}

@ARTICLE{Cozman+Walley-AMAI05j,
  ABSTRACT   = {This paper investigates Walley's concepts of epistemic irrelevance and epistemic independence for imprecise probability models. We study the mathematical properties of irrelevance and independence, and their relation to the graphoid axioms. Examples are given to show that epistemic irrelevance can violate the symmetry, contraction and intersection axioms, that epistemic independence can violate contraction and intersection, and that this accords with informal notions of irrelevance and independence.},
  ANNOTATION = {ook op papier},
  AUTHOR     = {Fabio Gagliardi Cozman and Peter Walley},
  DOI        = {10.1007/s10472-005-9004-z},
  FILE       = {files/Cozman+Walley-AMAI05j.pdf},
  NUMBER     = {1},
  PAGES      = {173–195},
  TITLE      = {Graphoid properties of epistemic irrelevance and independence},
  VOLUME     = {45},
  XDATA      = {AMAI},
  YEAR       = {2005},
}

@article{Biazzo+GLS-AMAI05j,
  AUTHOR     = {Biazzo, Veronica and Gilio, Angelo and Lukasiewicz, Thomas and Sanfilippo, Giuseppe},
  DOI        = {10.1007/s10472-005-9005-y},
  FILE       = {files/Biazzo+GLS-AMAI05j.pdf},
  KEYWORDS = {conditional probability assessment; logical constraint; conditional constraint; probabilistic logic under coherence; model-theoretic probabilistic logic; g-coherence; g-coherent entailment; computational complexity; algorithms},
  NUMBER     = {1–2},
  PAGES      = {35–81},
  TITLE      = {Probabilistic logic under coherence: complexity and algorithms},
  VOLUME     = {45},
  XDATA      = {AMAI},
  YEAR       = {2005},
}


@XDATA{JSPI,
  JOURNALTITLE = {Journal of Statistical Planning and Inference},
}

@ARTICLE{Walley+PV-JSPI04j,
  ABSTRACT = {We solve two fundamental problems of probabilistic reasoning: given finitely many conditional probability assessments, how to determine whether the assessments are mutually consistent, and how to determine what they imply about the conditional probabilities of other events? These problems were posed in 1854 by George Boole, who gave a partial solution using algebraic methods. The two problems are fundamental in applications of the Bayesian theory of probability; Bruno de Finetti solved the second problem for the special case of unconditional probability assessments in what he called ‘the fundamental theorem of probability’. We give examples to show that previous attempts to solve the two problems, using probabilistic logic and similar methods, can produce incorrect answers. Using ideas from the theory of imprecise probability, we show that the general problems have simple, direct solutions which can be implemented using linear programming algorithms. Unlike earlier proposals, our methods are formulated directly in terms of the assessments, without introducing unknown probabilities. Our methods work when any of the conditioning events may have probability zero, and they work when the assessments include imprecise (upper and lower) probabilities or previsions. The main methodological contribution of the paper is to provide general algorithms for making inferences from any finite collection of (possibly imprecise) conditional probabilities.},
  AUTHOR   = {Peter Walley and Renato Pelessoni and Paolo Vicig},
  DOI      = {10.1016/j.jspi.2003.09.005},
  FILE     = {files/Walley+PV-JSPI04j.pdf},
  KEYWORDS = {Avoiding uniform loss; Bayesian inference; Coherent probabilities; Fundamental theorem of probability; Imprecise probability; Lower probability; Natural extension; Probabilistic logic; Probabilistic reasoning},
  NUMBER   = {1},
  PAGES    = {119–151},
  TITLE    = {Direct algorithms for checking consistency and making inferences from conditional probability assessments},
  VOLUME   = {126},
  XDATA    = {JSPI},
  YEAR     = {2004},
}


@XDATA{FSS,
  JOURNALTITLE = {Fuzzy Sets and Systems},
  ISSN         = {0165-0114},
  PUBLISHER    = {Elsevier},
  SHORTJOURNAL = {Fuzzy Set. Syst.},
}

@ARTICLE{Buckley+Qu-FSS91j,
  AUTHOR   = {J. J. Buckley and Y. Qu},
  DOI      = {10.1016/0165-0114(91)90019-M},
  KEYWORDS = {algebra; fuzzy number},
  FILE     = {files/Buckley+Qu-FSS91j.pdf},
  NUMBER   = {1},
  PAGES    = {33–43},
  TITLE    = {Solving systems of linear fuzzy equations},
  VOLUME   = {43},
  XDATA    = {FSS},
  YEAR     = {1991},
}

@ARTICLE{Buckley-FSS95j,
  ABSTRACT = {We propose a new solution concept for fuzzy programming problems. It is based on our new method of solving fuzzy equations [10]. For simplicity we discuss in detail only fuzzy linear programming in this paper. We define, and obtain the basic properties of the joint solution (a fuzzy vector in R^n) and the optimal value of the objective function (a fuzzy number). Three examples are presented illustrating these concepts.},
  AUTHOR   = {J. J. Buckley},
  DOI      = {10.1016/0165-0114(94)00353-9},
  KEYWORDS = {mathematical programming},
  FILE     = {files/Buckley-FSS95j.pdf},
  NUMBER   = {2},
  PAGES    = {215–220},
  TITLE    = {Joint solution to fuzzy programming problems},
  VOLUME   = {72},
  XDATA    = {FSS},
  YEAR     = {1995},
}

@ARTICLE{Inuiguchi+Ramik-FSS00j,
  ABSTRACT = {In this paper, we review some fuzzy linear programming methods and techniques from a practical point of view. In the first part, the general history and the approach of fuzzy mathematical programming are introduced. Using a numerical example, some models of fuzzy linear programming are described. In the second part of the paper, fuzzy mathematical programming approaches are compared to stochastic programming ones. The advantages and disadvantages of fuzzy mathematical programming approaches are exemplified in the setting of an optimal portfolio selection problem. Finally, some newly developed ideas and techniques in fuzzy mathematical programming are briefly reviewed.},
  AUTHOR   = {Masahiro Inuiguchi and Jaroslav Ramík},
  DOI      = {10.1016/S0165-0114(98)00449-7},
  KEYWORDS = {Fuzzy constraint; Fuzzy goal; Fuzzy mathematical programming; Necessity measure; Portfolio selection; Possibility measure; Simplex method; Stochastic programming},
  FILE     = {files/Inuiguchi+Ramik-FSS00j.pdf},
  NUMBER   = {1},
  PAGES    = {3–28},
  TITLE    = {Possibilistic linear programming: a brief review of fuzzy mathematical programming and a comparison with stochastic programming in portfolio selection problem},
  VOLUME   = {111},
  XDATA    = {FSS},
  YEAR     = {2000},
}

@ARTICLE{Jamison+Lodwick-FSS01j,
  ABSTRACT = {In this paper we begin with a standard form of the linear programming problem. We replace each constant in the problem with a fuzzy number. We then reformat the objective and constraints into an unconstrained fuzzy function by penalizing the objective for possible constraint violations. The range of this fuzzy function lies in the space of fuzzy numbers. The objective is then redefined as optimizing the expected midpoint of the image of this fuzzy function. We show that this objective defines a concave function which, therefore, can be maximized globally. We present an algorithm for finding the optimum.},
  AUTHOR   = {K. David Jamison and Weldon A. Lodwick},
  DOI      = {10.1016/S0165-0114(99)00082-2},
  KEYWORDS = {Fuzzy function; Fuzzy number; Linear programming; possibility distribution},
  FILE     = {files/Jamison+Lodwick-FSS01j.pdf},
  NUMBER   = {1},
  PAGES    = {97–110},
  TITLE    = {Fuzzy linear programming using a penalty method},
  VOLUME   = {119},
  XDATA    = {FSS},
  YEAR     = {2001},
}

@ARTICLE{Neumaier-FSS03j,
  ABSTRACT = {This paper presents a new approach to fuzzy modeling based on the concept of surprise. The new concept is related to the traditional membership function by an antitone transformation. Advantages of the surprise approach include: 1. It has a consistent semantic interpretation. 2. It allows the joint use of quantitative and qualitative knowledge, using simple rules of logic. 3. It is a direct extension of (and allows combination with) the least-squares approach to reconciling conflicting approximate numerical data. 4. It is ideally suited to optimization under imprecise or conflicting goals, specified by a combination of soft and hard interval constraints. 5. It gives a straightforward approach to constructing families of functions consistent with fuzzy associative memories as used in fuzzy control, with tuning parameters (reflecting linguistic ambiguity) that can be adapted to available performance data.},
  AUTHOR   = {Arnold Neumaier},
  DOI      = {10.1016/S0165-0114(02)00248-8},
  FILE     = {files/Neumaier-FSS03j.pdf},
  NUMBER   = {1},
  PAGES    = {21–38},
  TITLE    = {Fuzzy modeling in terms of surprise},
  VOLUME   = {135},
  XDATA    = {FSS},
  YEAR     = {2003},
}

@ARTICLE{Inuiguchi-FSS07j,
  ABSTRACT = {In this paper, we treat fuzzy linear programming problems with uncertain parameters whose ranges are specified as fuzzy polytopes. The problem is formulated as a necessity measure optimization model. It is shown that the problem can be reduced to a semi-infinite programming problem and solved by a combination of a bisection method and a relaxation procedure. An algorithm in which the bisection method and the relaxation procedure converge simultaneously is proposed. A simple numerical example is given to illustrate the solution procedure.},
  AUTHOR   = {Masahiro Inuiguchi},
  DOI      = {10.1016/j.fss.2007.04.004},
  KEYWORDS = {Bisection method; Fuzzy polytope; Necessity measure; Possibilistic linear programming; Relaxation procedure; Semi-infinite programming},
  FILE     = {files/Inuiguchi-FSS07j.pdf},
  NUMBER   = {17},
  PAGES    = {1882–1891},
  TITLE    = {Necessity measure optimization in linear programming problems with fuzzy polytopes},
  VOLUME   = {158},
  XDATA    = {FSS},
  YEAR     = {2007},
}

@ARTICLE{Combarro+Miranda-FSS08j,
  ABSTRACT = {In this paper we deal with the problem of studying the structure of the polytope of non-additive measures for finite referential sets. We give a necessary and sufficient condition for two extreme points of this polytope to be adjacent. We also show that it is possible to find out in polynomial time whether two vertices are adjacent. These results can be extended to the polytope given by the convex hull of monotone Boolean functions. We also give some results about the facets and edges of the polytope of non-additive measures; we prove that the diameter of the polytope is 3 for referentials of three elements or more. Finally, we show that the polytope is combinatorial and study the corresponding properties; more concretely, we show that the graph of non-additive measures is Hamilton connected if the cardinality of the referential set is not 2.},
  AUTHOR   = {Elías F. Combarro and Pedro Miranda},
  DOI      = {10.1016/j.fss.2007.12.021},
  KEYWORDS = {Adjacency; Combinatorial polytopes; Complexity; Diameter; Monotone Boolean functions; Non-additive measures; Stack filters},
  FILE     = {files/Combarro+Miranda-FSS08j.pdf},
  NUMBER   = {16},
  PAGES    = {2145–2162},
  TITLE    = {On the polytope of non-additive measures},
  VOLUME   = {159},
  XDATA    = {FSS},
  YEAR     = {2008},
}

@ARTICLE{Quaeghebeur+Cooman-FSS08j,
  ABSTRACT   = {We consider lower probabilities on finite possibility spaces as models for the uncertainty about the state. These generalizations of classical probabilities can have some interesting properties; for example: k-monotonicity, avoiding sure loss, coherence, permutation invariance. The sets formed by all the lower probabilities satisfying zero or more of these properties are convex. We show how the extreme points and rays of these sets – the extreme lower probabilities – can be calculated and we give an illustration of our results.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  DATE       = {2008-09},
  DOI        = {10.1016/j.fss.2007.11.020},
  EPRINT     = {1854/LU-429244},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {combinatorial problems; extreme points; imprecise probabilities; lower probabilities; non-additive measures},
  FILE       = {files/Quaeghebeur+Cooman-FSS08j.pdf},
  NUMBER     = {16},
  PAGES      = {2163–2175},
  TITLE      = {Extreme lower probabilities},
  VOLUME     = {159},
  XDATA      = {FSS},
}

@ARTICLE{Baioletti+Petturiti-FSS11j,
  ABSTRACT = {In this paper we study the computational aspects of coherence and extension of partial possibility assessments, both in an unconditional and a conditional setting, providing complexity results and algorithms for each problem. In particular, we propose an algorithm to check the coherence of a partial unconditional assessment which is based on propositional satisfiability. For the conditional case, we firstly prove a new characterization of coherent conditional assessments that allows us to define an algorithm again based on propositional satisfiability. The extension problem, in both settings, is solved by means of a search algorithm which relies on the corresponding coherence procedure.},
  AUTHOR   = {Marco Baioletti and Davide Petturiti},
  DOI      = {10.1016/j.fss.2011.01.001},
  KEYWORDS = {Possibility theory; Conditioning; Coherence; Extension; Algorithms; Complexity},
  FILE     = {files/Baioletti+Petturiti-FSS11j.pdf},
  NUMBER   = {1},
  PAGES    = {1–25},
  TITLE    = {Algorithms for possibility assessments: Coherence and extension},
  VOLUME   = {169},
  XDATA    = {FSS},
  YEAR     = {2011},
}

@ARTICLE{Quaeghebeur+SC-FSS12j,
  ABSTRACT   = {We investigate a constrained optimization problem with uncertainty about constraint parameters. Our aim is to reformulate it as a (constrained) optimization problem without uncertainty. This is done by recasting the original problem as a decision problem under uncertainty. We give results for a number of different types of uncertainty models—linear and vacuous previsions, and possibility distributions—and for two common but different optimality criteria for such decision problems—maximinity and maximality. We compare our approach with other approaches that have appeared in the literature.},
  AUTHOR     = {Erik Quaeghebeur and Keivan Shariatmadar and Gert de Cooman},
  DOI        = {10.1016/j.fss.2012.02.004},
  EPRINT     = {1854/LU-2030199},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Constrained optimization; Maximinity; Maximality; Coherent lower prevision; Linear prevision; Vacuous prevision; Possibility distribution},
  PAGES      = {74–88},
  TITLE      = {Constrained optimization problems under uncertainty with coherent lower previsions},
  VOLUME     = {206},
  YEAR       = {2012},
  XDATA      = {FSS},
}

@XDATA{JSTP,
  ISSN         = {1559-8608},
  JOURNALTITLE = {Journal of Statistical Theory and Practice},
  PUBLISHER    = {Taylor \& Francis},
  SHORTJOURNAL = {J. Stat. Theor. Pract.},
}

@ARTICLE{Danielson+ER-JSTP09j,
  ABSTRACT = {Most current decision analytical tools and elicitation methods are built on the assumption that decision-makers are able to make their probability and utility assessments in a proper manner. This is, however, often not the case. The specification and execution of elicitation processes are in the majority of cases left to the discretion of the users, not least in user-driven cases such as public information and e-democracy projects. A number of studies have shown, among other things, that people's natural choice behaviour deviates from normative assumptions, and that the results display an inertia gap due to differently framed prospects. One reason for the occurrence of the inertia gap is people's inability to express their preferences as single numbers. Instead of considering this as being a human error, this paper uses the gap in order to develop a class of methods more aligned to the observed behaviour. The core idea of the class is to acknowledge the existence of the gap and, as a consequence, not elicit single point numbers.},
  AUTHOR   = {Mats Danielson and Love Ekenberg and Ari Riabacke},
  DATE     = {2009-03},
  DOI      = {10.1080/15598608.2009.10411917},
  KEYWORDS = {Decision analysis; Elicitation method; Imprecise information; Interval assessments},
  FILE     = {files/Danielson+ER-JSTP09j.pdf},
  NUMBER   = {1},
  PAGES    = {157–168},
  TITLE    = {A Prescriptive Approach to Elicitation of Decision Data},
  VOLUME   = {3},
  XDATA    = {JSTP},
}

@ARTICLE{Campos+ZTJ-JSTP09j,
  ABSTRACT = {This paper explores the application of semi-qualitative probabilistic networks (SQPNs) that combine numeric and qualitative information to computer vision problems. Our version of SQPN allows qualitative influences and imprecise probability measures using intervals. We describe an Imprecise Dirichlet model for parameter learning and an iterative algorithm for evaluating posterior probabilities, maximum a posteriori and most probable explanations. Experiments on facial expression recognition and image segmentation problems are performed using real data.},
  AUTHOR   = {Cassio Polpo de Campos and Lei Zhang and Yan Tong and Qiang Ji},
  DATE     = {2009-03},
  DOI      = {10.1080/15598608.2009.10411920},
  KEYWORDS = {Computer vision applications; Imprecise probabilities; Probabilistic networks; Qualitative relations},
  FILE     = {files/Campos+ZTJ-JSTP09j.pdf},
  NUMBER   = {1},
  PAGES    = {197–210},
  TITLE    = {Semi-qualitative probabilistic networks in computer vision problems},
  VOLUME   = {3},
  XDATA    = {JSTP},
}


@XDATA{JTP,
  JOURNALTITLE = {Journal of Theoretical Probability},
  SHORTJOURNAL = {J. Theor. Probab.},
}

@ARTICLE{Miranda+CQ-JTP07j,
  ABSTRACT   = {We investigate to what extent finitely additive probability measures on the unit interval are determined by their moment sequence. We do this by studying the lower envelope of all finitely additive probability measures with a given moment sequence. Our investigation leads to several elegant expressions for this lower envelope, and it allows us to conclude that the information provided by the moments is equivalent to the one given by the associated lower and upper distribution functions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  DATE       = {2007-09-01},
  DOI        = {10.1007/s10959-007-0055-4},
  EPRINT     = {1854/LU-376551},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Hausdorff moment problem; coherent lower prevision; complete monotonicity; lower distribution function},
  FILE       = {files/Miranda+CQ-JTP07j.pdf},
  NUMBER     = {3},
  PAGES      = {663–693},
  TITLE      = {The Hausdorff moment problem under finite additivity},
  VOLUME     = {20},
  XDATA      = {JTP},
}

@XDATA{PES,
  JOURNALTITLE = {Probability in the Engineering and Informational Sciences},
  SHORTJOURNAL = {Probab. Eng. Inform. Sc.},
}

@ARTICLE{Cooman+HQ-PES09j,
  ABSTRACT   = {When the initial and transition probabilities of a finite Markov chain in discrete time are not well known, we should perform a sensitivity analysis. This can be done by considering as basic uncertainty models the so-called credal sets that these probabilities are known or believed to belong to, and by allowing the probabilities to vary over such sets. This leads to the definition of an imprecise Markov chain. We show that the time evolution of such a system can be studied very efficiently using so-called lower and upper expectations, which are equivalent mathematical representations of credal sets. We also study how the inferred credal set about the state at time n evolves as n goes to infinity: under quite unrestrictive conditions, it converges to a uniquely invariant credal set, regardless of the credal set given for the initial state. This leads to a non-trivial generalisation of the classical Perron-Frobenius Theorem to imprecise Markov chains.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  DOI        = {10.1017/S0269964809990039},
  EPRINT     = {1854/LU-498502},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {probability tree; credal set; event tree; imprecise Markov chain; Markov chain; non-linear Perron-Frobenius Theorem; sensitivity analysis; stationarity; lower expectation; upper expectation; regularity; decision-processes; transition-probabilities; set-chains},
  NUMBER     = {4},
  PAGES      = {597–635},
  TITLE      = {Imprecise Markov chains and their limit behavior},
  VOLUME     = {23},
  XDATA      = {PES},
  YEAR       = {2009},
}

@XDATA{RESS,
  ISSN         = {0951-8320},
  JOURNALTITLE = {Reliability Engineering \& System Safety},
  PUBLISHER    = {Elsevier},
}

@ARTICLE{Hagan+Oakley-RESS04j,
  ABSTRACT   = {There are difficulties with probability as a representation of uncertainty. However, we argue that there is an important distinction between principle and practice. In principle, probability is uniquely appropriate for the representation and quantification of all forms of uncertainty; it is in this sense that we claim that ‘probability is perfect’. In practice, people find it difficult to express their knowledge and beliefs in probabilistic form, so that elicitation of probability distributions is a far from perfect process. We therefore argue that there is no need for alternative theories, but that any practical elicitation of expert knowledge must fully acknowledge imprecision in the resulting distribution. We outline a recently developed Bayesian technique that allows the imprecision in elicitation to be formulated explicitly, and apply it to some of the challenge problems.},
  AUTHOR     = {Anthony O'Hagan and Jeremy E. Oakley},
  DOI        = {10.1016/j.ress.2004.03.014},
  FILE       = {files/Hagan+Oakley-RESS04j.pdf},
  ISSUETITLE = {Alternative Representations of Epistemic Uncertainty},
  KEYWORDS   = {Aleatory probability; Bayesian inference; Computer codes; Elicitaton; Epistemic probability},
  NUMBER     = {1–3},
  PAGES      = {239–248},
  TITLE      = {Probability is perfect, but we can't elicit it perfectly},
  VOLUME     = {85},
  XDATA      = {RESS},
  YEAR       = {2004},
}

@XDATA{BEJ,
  JOURNALTITLE = {Bernoulli},
}

@ARTICLE{Cooman+QM-BEJ09j,
  ABSTRACT   = {We extend de Finetti's notion of exchangeability to finite and countable sequences of variables, when a subject's beliefs about them are modelled using coherent lower previsions rather than (linear) previsions. We derive representation theorems in both the finite and the countable case, in terms of sampling without and with replacement, respectively.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur and Enrique Miranda},
  DOI        = {10.3150/09-BEJ182},
  EPRINT     = {1854/LU-498518},
  EPRINTTYPE = {hdl},
  EPRINT     = {0909.1148},
  EPRINTTYPE = {arxiv},
  KEYWORDS   = {Representation Theorem; sampling without replacement; exchangeability; multinomial sampling; lower prevision; imprecise probability; probability; coherence; convergence in distribution; Bernstein polynomials},
  NUMBER     = {3},
  PAGES      = {721–735},
  TITLE      = {Exchangeable lower previsions},
  VOLUME     = {15},
  XDATA      = {BEJ},
  YEAR       = {2009},
}

@XDATA{Econometrica,
  JOURNALTITLE = {Econometrica},
  PUBLISHER    = {The Econometric Society},
}

@article{Crawford+Sobel-Econometrica82j,
  ABSTRACT   = {This paper develops a model of strategic communication, in which a better-informed Sender (S) sends a possibly noisy signal to a Receiver (R), who then takes an action that determines the welfare of both. We characterize the set of Bayesian Nash equilibria under standard assumptions, and show that equilibrium signaling always takes a strikingly simple form, in which S partitions the support of the (scalar) variable that represents his private information and introduces noise into his signal by reporting, in effect, only which element of the partition his observation actually lies in. We show under further assumptions that before S observes his private information, the equilibrium whose partition has the greatest number of elements is Pareto-superior to all other equilibria, and that if agents coordinate on this equilibrium, R's equilibrium expected utility rises when agents' preferences become more similar. Since R bases his choice of action on rational expectations, this establishes a sense in which equilibrium signaling is more informative when agents' preferences are more similar.},
  AUTHOR     = {Crawford, Vincent P. and Sobel, Joel},
  DATE       = {1982-11},
  DOI        = {10.2307/1913390},
  FILE       = {files/Crawford+Sobel-Econometrica82j.pdf},
  NUMBER     = {6},
  TITLE      = {Strategic Information Transmission},
  PAGES      = {1431–1451},
  EPRINT     = {1913390},
  EPRINTTYPE = {jstor},
  VOLUME     = {50},
  XDATA      = {Econometrica},
}

@XDATA{MS,
  JOURNALTITLE = {Management Science},
  PUBLISHER    = {INFORMS},
}

@ARTICLE{Spetzler+Stael-MS75j,
  ABSTRACT = {This paper presents the present philosophy and practice used in probability encoding by the Decision Analysis Group at Stanford Research Institute. Probability encoding, the process of extracting and quantifying individual judgment about uncertain quantities, is one of the major functions required in the performance of decision analysis. The paper discusses the setting of the encoding process, including the use of sensitivity analyses to identify crucial state variables for which extensive encoding procedures are appropriate. The importance of balancing modeling and encoding techniques is emphasized and examples of biases and unconscious modes of judgment are reviewed. A variety of encoding methods are presented and their applicability is discussed. The authors recommend and describe a structured interview process that utilizes a trained interviewer and a number of techniques designed to reduce biases and aid in the quantification of judgment.},
  AUTHOR = {Carl S. Spetzler and Staël von Holstein, Carl-Axel S.},
  DATE = {1975-11-01},
  DOI = {10.1287/mnsc.22.3.340},
  FILE = {files/Spetzler+Staël-MS75j.pdf},
  NUMBER = {3},
  PAGES = {340–358},
  TITLE = {Probability Encoding in Decision Analysis},
  VOLUME = {22},
}

@article{Lichtendahl+Winkler-MS07j,
  AUTHOR = {Lichtendahl, Jr., Kenneth C. and Robert L. Winkler},
  TITLE = {Probability elicitation, scoring rules, and competition among forecasters},
  VOLUME = {53},
  NUMBER = {11},
  PAGES = {1745–1755},
  YEAR = {2007},
  DOI = {10.1287/mnsc.1070.0729},
  FILE = {files/Lichtendahl+Winkler-MS07j.pdf},
  ABSTRACT = {Probability forecasters who are rewarded via a proper scoring rule may care not only about the score, but also about their performance relative to other forecasters. We model this type of preference and show that a competitive forecaster who wants to do better than another forecaster typically should report more extreme probabilities, exaggerating toward zero or one. We consider a competitive forecaster's best response to truthful reporting and also investigate equilibrium reporting functions in the case where another forecaster also cares about relative performance. We show how a decision maker can revise probabilities of an event after receiving reported probabilities from competitive forecasters and note that the strategy of exaggerating probabilities can make well-calibrated forecasters (and a decision maker who takes their reported probabilities at face value) appear to be overconfident. However, a decision maker who adjusts appropriately for the misrepresentation of probabilities by one or more forecasters can still be well calibrated. Finally, to try to overcome the forecasters' competitive instincts and induce cooperative behavior, we develop the notion of joint scoring rules based on business sharing and show that these scoring rules are strictly proper.},
  XDATA = {MS},
}

@ARTICLE{Iancu+Trichakis-MS14j,
  AUTHOR = {Iancu, Dan A. and Trichakis, Nikolaos},
  DOI = {10.1287/mnsc.2013.1753},
  FILE = {files/Iancu+Trichakis-MS14j.pdf},
  NUMBER = {1},
  PAGES = {130–147},
  TITLE = {Pareto Efficiency in Robust Optimization},
  VOLUME = {60},
  XDATA = {MS},
  YEAR = {2014},
}

@XDATA{MP,
  JOURNALTITLE = {Mathematical Programming},
  PUBLISHER    = {Springer},
  SHORTJOURNAL = {Math. Program.},
}

@article{Jackson+Lynch-MP87j,
  AUTHOR   = {Jackson, Peter L. and Lynch, David F.},
  DATE     = {1987},
  DOI      = {10.1007/BF02592950},
  FILE     = {files/Jackson+Lynch-MP87j.pdf},
  KEYWORDS = {Dantzig–Wolfe decomposition; large-scale optimization; linear programming; staircase linear programs; simplex method},
  NUMBER   = {2},
  PAGES    = {157–179},
  TITLE    = {Revised Dantzig–Wolfe decomposition for staircase-structured linear programs},
  VOLUME   = {39},
  XDATA    = {MP},
}

@XDATA{Synthese,
  ISSN         = {0039-7857},
  JOURNALTITLE = {Synthese},
  PUBLISHER    = {Springer},
}

@article{Walley+Fine-Synthese79j,
  AUTHOR = {Walley, Peter and Fine, Terrence L.},
  DOI    = {10.1007/BF00869449},
  FILE   = {files/Walley+Fine-Synthese79j.pdf},
  NUMBER = {3},
  PAGES  = {321-374},
  TITLE  = {Varieties of modal (classificatory) and comparative probability},
  VOLUME = {41},
  XDATA  = {Synthese},
  YEAR   = {1979},
}

@ARTICLE{Seidenfeld+SK-Synthese10j,
  AUTHOR   = {Teddy Seidenfeld and Mark J. Schervish and Joseph B. Kadane},
  DOI      = {10.1007/s11229-009-9470-7},
  FILE     = {files/Seidenfeld+SK-Synthese10j.pdf},
  KEYWORDS = {Choice functions; Coherence; Γ-Maximin; Maximality; Uncertainty; State-independent utility},
  PAGES    = {157–176},
  TITLE    = {Coherent choice functions under uncertainty},
  VOLUME   = {172},
  XDATA    = {Synthese},
  YEAR     = {2010},
}

@ARTICLE{Singer-Synthese14j,
  AUTHOR   = {Singer, Daniel Jeremy},
  DOI      = {10.1007/s11229-014-0429-y},
  FILE     = {files/Singer-Synthese14j.pdf},
  KEYWORDS = {Epistemology; Formal epistemology; Sleeping Beauty; Imprecise Bayesianism; Bayesianism},
  TITLE    = {Sleeping beauty should be imprecise},
  XDATA    = {Synthese},
  YEAR     = {2014},
}

@XDATA{ERK,
  ISSN         = {0165-0106},
  JOURNALTITLE = {Erkenntnis},
}

@article{Pedersen+Wheeler-ERK14j,
  FILE   = {Pedersen+Wheeler-ERK14j.pdf},
  YEAR   = {2014},
  VOLUME = {79},
  NUMBER = {6},
  DOI    = {10.1007/s10670-013-9531-7},
  TITLE  = {Demystifying Dilation},
  AUTHOR = {Pedersen, Arthur Paul and Wheeler, Gregory},
  PAGES  = {1305-1342},
  XDATA  = {ERK},
}

@XDATA{IJUFKS,
  JOURNALTITLE = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
}

@ARTICLE{Campos+HM-IJUFKS94j,
  ABSTRACT = {We study probability intervals as an interesting tool to represent uncertain information. A number of basic operations necessary to develop a calculus with probability intervals, such as combination, marginalization, conditioning and integration are studied in detail. Moreover, probability intervals are compared with other uncertainty theories, such as lower and upper probabilities, Choquet capacities of order two and belief and plausibility functions. The advantages of probability intervals with respect to these formalisms in computational efficiency are also highlighted.},
  AUTHOR   = {Luis M. de Campos and Juan F. Huete and Serafín Moral},
  DOI      = {10.1142/S0218488594000146},
  KEYWORDS = {Combination; Conditioning; Lower and Upper Probability; Marginalization; Probability Intervals; Uncertainty Management},
  FILE     = {files/Campos+HM-IJUFKS94j.pdf},
  NUMBER   = {2},
  PAGES    = {167–196},
  TITLE    = {Probability intervals: a tool for uncertain reasoning},
  URL      = {http://decsai.ugr.es/~lci/journal-papers-pdf/ijuf94.pdf},
  VOLUME   = {2},
  XDATA    = {IJUFKS},
  YEAR     = {1994},
}

@ARTICLE{Miranda+GG-IJUFKS02j,
  AUTHOR     = {Pedro Miranda and Michel Grabisch and Pedro Gil},
  DOI        = {10.1142/S0218488502001867},
  EPRINT     = {0804.2642},
  EPRINTTYPE = {arXiv},
  FILE       = {files/Miranda+GG-IJUFKS02j.pdf},
  NUMBER     = {Supplementary Issue 1},
  PAGES      = {105–123},
  TITLE      = {p-Symmetric fuzzy measures},
  VOLUME     = {10},
  XDATA      = {IJUFKS},
  YEAR       = {2002},
}

@ARTICLE{Pelessoni+Vicig-IJUFKS03j,
  ABSTRACT = {In this paper the theory of coherent imprecise previsions is applied to risk measurement. We introduce the notion of coherent risk measure defined on an arbitrary set of risks, showing that it can be considered a special case of coherent upper prevision. We also prove that our definition generalizes the notion of coherence for risk measures defined on a linear space of random numbers, given in literature. Consistency properties of Value-at-Risk (VaR), currently one of the most used risk measures, are investigated too, showing that it does not necessarily satisfy a weaker notion of consistency called 'avoiding sure loss'. We introduce sufficient conditions for VaR to avoid sure loss and to be coherent. Finally we discuss ways of modifying incoherent risk measures into coherent ones.},
  AUTHOR   = {Renato Pelessoni and Paolo Vicig},
  DOI      = {10.1142/S0218488503002156},
  KEYWORDS = {Imprecise prevision; Value-at-Risk; avoiding sure loss condition; coherent risk measure},
  FILE     = {files/Pelessoni+Vicig-IJUFKS03j.pdf},
  NUMBER   = {4},
  PAGES    = {393–412},
  TITLE    = {Imprecise previsions for risk measurement},
  VOLUME   = {11},
  XDATA    = {IJUFKS},
  YEAR     = {2003},
}

@XDATA{JMP,
  ISSN    = {0022-2496},
  JOURNAL = {Journal of Mathematical Psychology},
}

@ARTICLE{Weibull-JMP82j,
  ABSTRACT = {The paper examines Ramsey's proposition that preferences among uncertain prospects may be represented in terms of subjectively expected subjective values. While the von Neumann-Morgenstern approach presupposes probabilities and derives values, the present approach does the reverse: it presupposes values and derives probabilities. Necessary and sufficient conditions are presented for such representations for a fairly wide range of preference structures, including discrete as well as continuous spaces of states-of-nature. An operational procedure is suggested for constructing the subjective values and probabilities.},
  AUTHOR   = {Jörgen W. Weibull},
  DATE     = {1982-12},
  DOI      = {10.1016/0022-2496(82)90001-3},
  FILE     = {files/Weibull-JMP82j.pdf},
  NUMBER   = {3},
  PAGES    = {191–203},
  TITLE    = {A dual to the von Neumann-Morgenstern theorem},
  VOLUME   = {26},
  XDATA    = {JMP},
}

@ARTICLE{Miranda+Destercke-JMP15j,
  ABSTRACT = {When using convex probability sets (or, equivalently, lower previsions) as uncertainty models, identifying extreme points can help simplifying various computations or the use of some algorithms. In general, sets induced by specific models such as possibility distributions, linear vacuous mixtures or 2-monotone measures may have extreme points easier to compute than generic convex sets. In this paper, we study extreme points of another specific model: comparative probability orderings between the singletons of a finite space. We characterize these extreme points by means of a graphical representation of the comparative model, and use them to study the properties of the lower probability induced by this set. By doing so, we show that 2-monotone capacities are not informative enough to handle this type of comparisons without a loss of information. In addition, we connect comparative probabilities with other uncertainty models, such as imprecise probability masses.},
  AUTHOR   = {Enrique Miranda and Sébastien Destercke},
  DOI      = {10.1016/j.jmp.2014.11.004},
  FILE     = {files/Miranda+Destercke-JMP15j.pdf},
  KEYWORDS = {Comparative probabilities, Credal sets, 2-monotone capacities, Belief functions, Extreme points, Imprecise probability masses},
  PAGES    = {44–57},
  TITLE    = {Extreme points of the credal sets generated by comparative probabilities},
  VOLUME   = {64–65},
  YEAR     = {2015},
  XDATA    = {JMP},
}

@XDATA{Constraints,
  JOURNALTITLE = {Constraints},
  PUBLISHER    = {Springer},
}

@article{Morgado+HLPM-Constraints13j,
  AUTHOR   = {Morgado, Antonio and Heras, Federico and Liffiton, Mark and Planes, Jordi and Marques-Silva, Joao},
  DOI      = {10.1007/s10601-013-9146-2},
  FILE     = {files/Morgado+HLPM-Constraints13j.pdf},
  KEYWORDS = {MaxSAT; MaxSMT; Boolean optimization; Optimization problems},
  NUMBER   = {4},
  PAGES    = {478–534},
  TITLE    = {Iterative and core-guided MaxSAT solving: A survey and assessment},
  VOLUME   = {18},
  XDATA    = {Constraints},
  YEAR     = {2013},
}


@XDATA{TSMC,
  ISSN         = {0018-9472},
  JOURNALTITLE = {IEEE Transactions on Systems, Man and Cybernetics},
  PUBLISHER    = {IEEE},
  SHORTJOURNAL = {IEEE T. Syst. Man Cyb.},
}

@ARTICLE{Laskey-TSMC95j,
  ABSTRACT = {When eliciting a probability model from experts, knowledge engineers may compare the results of the model with expert judgment on test scenarios, then adjust model parameters to bring the behavior of the model more in line with the experts intuition. This paper presents a methodology for analytic computation of sensitivity values in Bayesian network models. Sensitivity values are partial derivatives of output probabilities with respect to parameters being varied in the sensitivity analysis. They measure the impact of small changes in a network parameter on a target probability value or distribution. Sensitivity values can be used to focus knowledge elicitation effort on those parameters having the most impact on outputs of concern. Analytic sensitivity values are computed for an example and compared to sensitivity analysis by direct variation of parameters},
  AUTHOR   = {K. B. Laskey},
  DOI      = {10.1109/21.384252},
  KEYWORDS = {Bayesian networks; knowledge elicitation; knowledge engineering; probability assessments; sensitivity analysis; symbolic reasoning; target probability value; uncertainty representation; Bayes methods; inference mechanisms; knowledge acquisition; probability; sensitivity analysis},
  MONTH    = {06},
  NUMBER   = {6},
  PAGES    = {901–909},
  TITLE    = {Sensitivity analysis for probability assessments in Bayesian networks},
  VOLUME   = {25},
  XDATA    = {TSMC},
  YEAR     = {1995},
}

@XDATA{JC,
  JOURNALTITLE = {Journal of Complexity},
}

@ARTICLE{Georgakopoulos+KP-JC88j,
  AUTHOR = {George Georgakopoulos and Dimitris Kavvadias and Christos H. Papadimitriou},
  FILE   = {files/Georgakopoulos+KP-JC88j.pdf},
  PAGES  = {1–11},
  TITLE  = {Probabilistic satisfiability},
  VOLUME = {4},
  XDATA  = {JC},
  YEAR   = {1988},
}

@XDATA{BAMS,
  JOURNALTITLE = {Bulletin of the American Mathematical Society},
  PUBLISHER    = {American Mathematical Society},
}

@REVIEW{Diaconis-BAMS09j,
  AUTHOR = {Persi Diaconis},
  DOI    = {10.1090/S0273-0979-09-01262-2},
  FILE   = {files/Diaconis-BAMS09j.pdf},
  PAGES  = {691–696},
  TITLE  = {Book review: “Probabilistic symmetries and invariance principles” by Olav Kallenberg},
  VOLUME = {46},
  YEAR   = {2009},
}


@XDATA{TKDA,
  JOURNALTITLE = {IEEE Transactions on Knowledge and Data Engineering},
  PUBLISHER    = {IEEE},
  SHORTJOURNAL = {IEEE T. Knowl. Data Eng.},
}

@ARTICLE{Druzdzel+Gaag-TKDA00j,
  AUTHOR = {Druzdzel, Marek J. and Linda C. van der Gaag},
  DOI    = {10.1109/TKDE.2000.868901},
  NUMBER = {4},
  PAGES  = {481–486},
  TITLE  = {Building probabilistic networks: Where do the numbers come from?},
  VOLUME = {12},
  XDATA  = {TKDA},
  YEAR   = {2000},
}

@XDATA{TVCG,
  ISSN         = {1077-2626},
  JOURNALTITLE = {IEEE Transactions on Visualization and Computer Graphics},
}

@ARTICLE{Bostock+OH-TVCG11j,
  ABSTRACT   = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.},
  AUTHOR     = {Bostock, M. and Ogievetsky, V. and Heer, J.},
  DATE       = {2011-12},
  DOI        = {10.1109/TVCG.2011.185},
  FILE       = {files/Bostock+OH-TVCG11j.pdf},
  KEYWORDS   = {Web sites; computer animation; data visualisation; document handling; user interfaces; Web visualization; animation; data-driven documents; document elements; dynamic transforms; native representation; representation-transparent approach; representational transparency; scene graph; standard document object model; toolkit-specific abstraction; Cascading style sheets; Data visualization; Debugging; Image color analysis; Information analysis; 2D graphics.; Information visualization; toolkits; user interfaces},
  NUMBER     = {12},
  PAGES      = {2301–2309},
  SHORTHAND  = {D3},
  TITLE      = {D³: Data-Driven Documents},
  URL        = {http://d3js.org/},
  VOLUME     = {17},
  XDATA      = {TVCG},
}

@XDATA{JSched,
  ISSN         = {1094-6136},
  JOURNALTITLE = {Journal of Scheduling},
  PUBLISHER    = {Springer},
  SHORTJOURNAL = {J. Sched.},
}

@ARTICLE{Akker+HK-JSched12j,
  AUTHOR   = {van den Akker, J. M. and Hoogeveen, J. A. and van Kempen, J. W.},
  DOI      = {10.1007/s10951-010-0191-z},
  KEYWORDS = {Column generation; Maximum lateness; Release dates; Precedence constraints; Time-indexed formulation},
  NUMBER   = {6},
  PAGES    = {801–810},
  TITLE    = {Using column generation to solve parallel machine scheduling problems with minmax objective functions},
  VOLUME   = {15},
  XDATA    = {JSched},
  YEAR     = {2012},
}

@XDATA{FS,
  ISSN         = {1233-1821},
  JOURNALTITLE = {Foundations of Science},
  PUBLISHER    = {Springer},
}

@ARTICLE{Freedman-FS95j,
  AUTHOR = {David Freedman},
  FILE   = {files/Freedman-FS95j.pdf},
  PAGES  = {19–39},
  TITLE  = {Some issues in the foundations of statistics},
  VOLUME = {1},
  XDATA  = {FS},
  YEAR   = {1995},
}


@XDATA{POS,
  JOURNALTITLE = {Philosophy of Science},
}

@ARTICLE{Seidenfeld-POS85j,
  ABSTRACT   = {Can there be good reasons for judging one set of probabilistic assertions more reliable than a second? There are many candidates for measuring "goodness" of probabilistic forecasts. Here, I focus on one such aspirant: calibration. Calibration requires an alignment of announced probabilities and observed relative frequency, e.g., 50 percent of forecasts made with the announced probability of .5 occur, 70 percent of forecasts made with probability .7 occur, etc. To summarize the conclusions: (i) Surveys designed to display calibration curves, from which a recalibration is to be calculated, are useless without due consideration for the interconnections between questions (forecasts) in the survey. (ii) Subject to feedback, calibration in the long run is otiose. It gives no ground for validating one coherent opinion over another as each coherent forecaster is (almost) sure of his own long-run calibration. (iii) Calibration in the short run is an inducement to hedge forecasts. A calibration score, in the short run, is improper. It gives the forecaster reason to feign violation of total evidence by enticing him to use the more predictable frequencies in a larger finite reference class than that directly relevant.},
  AUTHOR     = {Teddy Seidenfeld},
  FILE       = {papers/Seidenfeld-POS85j.pdf},
  NUMBER     = {2},
  PAGES      = {274–294},
  TITLE      = {Calibration, coherence, and scoring rules},
  EPRINT     = {187511},
  EPRINTTYPE = {jstor},
  VOLUME     = {52},
  XDATA      = {POS},
  YEAR       = {1985},
}


@XDATA{JASA,
  JOURNALTITLE = {Journal of the American Statistical Association},
  ISSN         = {0162-1459},
}

@ARTICLE{Savage-JASA71j,
  AUTHOR     = {Leonard J. Savage},
  EPRINT     = {2284229},
  EPRINTTYPE = {jstor},
  FILE       = {files/Savage-JASA71j.pdf},
  NUMBER     = {336},
  PAGES      = {783–801},
  TITLE      = {Elicitation of personal probabilities and expectations},
  VOLUME     = {66},
  XDATA      = {JASA},
  YEAR       = {1971},
}

@ARTICLE{Winkler-JASA71j,
  ABSTRACT   = {This article concerns a study in which personal probability assessments regarding the outcomes of football games were obtained. The results reported here, which include a detailed investigation of the assessments, an evaluation of the assessments in an inferential context and in a decision-theoretic context, and a discussion of the performance of a consensus, show that methods such as scoring rules and bets are useful in leading individuals to make careful probability assessments. Considerable variability existed among subjects, however, with predictions determined by mechanical schemes and by the organized betting market proving superior to those of many of the subjects.},
  AUTHOR     = {Winkler, Robert L.},
  DATE       = {1971-12},
  EPRINT     = {2284212},
  EPRINTTYPE = {jstor},
  FILE       = {files/Winkler-JASA71j.pdf},
  NUMBER     = {336},
  PAGES      = {675–685},
  TITLE      = {Probabilistic Prediction: Some Experimental Results},
  VOLUME     = {66},
  XDATA      = {JASA},
}

@ARTICLE{Dawid-JASA82j,
  ABSTRACT   = {Suppose that a forecaster sequentially assigns probabilities to events. He is well calibrated if, for example, of those events to which he assigns a probability 30 percent, the long-run proportion that actually occurs turns out to be 30 percent. We prove a theorem to the effect that a coherent Bayesian expects to be well calibrated, and consider its destructive implications for the theory of coherence.},
  AUTHOR     = {Dawid, A. P.},
  DATE       = {1982-09},
  DOI        = {10.1080/01621459.1982.10477856},
  EPRINT     = {2287720},
  EPRINTTYPE = {jstor},
  FILE       = {files/Dawid-JASA82j.pdf},
  NUMBER     = {379},
  PAGES      = {605–610},
  TITLE      = {The Well-Calibrated Bayesian},
  VOLUME     = {77},
  XDATA      = {JASA},
}

@article{Robins+Wasserman-JASA00j,
  AUTHOR  = {James Robins and Larry Wasserman},
  TITLE   = {Conditioning, Likelihood, and Coherence: A Review of Some Foundational Concepts},
  FILE    = {files/Robins+Wasserman-JASA00j.pdf},
  VOLUME  = {95},
  NUMBER  = {452},
  PAGES   = {1340-1346},
  YEAR    = {2000},
  DOI     = {10.1080/01621459.2000.10474344},
  XDATA   = {JASA},
}

@article{Garthwaite+KH-JASA05j,
  ABSTRACT = {Elicitation is a key task for subjectivist Bayesians. Although skeptics hold that elicitation cannot (or perhaps should not) be done, in practice it brings statisticians closer to their clients and subject-matter expert colleagues. This article reviews the state of the art, reflecting the experience of statisticians informed by the fruits of a long line of psychological research into how people represent uncertain information cognitively and how they respond to questions about that information. In a discussion of the elicitation process, the first issue to address is what it means for an elicitation to be successful; that is, what criteria should be used. Our answer is that a successful elicitation faithfully represents the opinion of the person being elicited. It is not necessarily “true” in some objectivistic sense, and cannot be judged in that way. We see that elicitation as simply part of the process of statistical modeling. Indeed, in a hierarchical model at which point the likelihood ends and the prior begins is ambiguous. Thus the same kinds of judgment that inform statistical modeling in general also inform elicitation of prior distributions. The psychological literature suggests that people are prone to certain heuristics and biases in how they respond to situations involving uncertainty. As a result, some of the ways of asking questions about uncertain quantities are preferable to others, and appear to be more reliable. However, data are lacking on exactly how well the various methods work, because it is unclear, other than by asking using an elicitation method, just what the person believes. Consequently, one is reduced to indirect means of assessing elicitation methods. The tool chest of methods is growing. Historically, the first methods involved choosing hyperparameters using conjugate prior families, at a time when these were the only families for which posterior distributions could be computed. Modern computational methods, such as Markov chain Monte Carlo, have freed elicitation from this constraint. As a result, now both parametric and nonparametric methods are available for low-dimensional problems. High-dimensional problems are probably best thought of as lacking another hierarchical level, which has the effect of reducing the as-yet-unelicited parameter space. Special considerations apply to the elicitation of group opinions. Informal methods, such as Delphi, encourage the participants to discuss the issue in the hope of reaching consensus. Formal methods, such as weighted averages or logarithmic opinion pools, each have mathematical characteristics that are uncomfortable. Finally, there is the question of what a group opinion even means, because it is not necessarily the opinion of any participant.},
  AUTHOR   = {Garthwaite, Paul H. and Kadane, Joseph B. and O'Hagan, Anthony},
  DOI      = {10.1198/016214505000000105},
  FILE     = {files/Garthwaite+KH-JASA05j.pdf},
  NUMBER   = {470},
  PAGES    = {680-701},
  TITLE    = {Statistical Methods for Eliciting Probability Distributions},
  VOLUME   = {100},
  XDATA    = {JASA},
  YEAR     = {2005},
}

@XDATA{KER,
  JOURNALTITLE = {The Knowledge Engineering Review},
}

@ARTICLE{Renooij-KER01j,
  AUTHOR = {Silja Renooij},
  DOI    = {10.1017/S0269888901000145},
  FILE   = {files/Renooij-KER01j.pdf},
  MONTH  = {09},
  NUMBER = {3},
  PAGES  = {255–269},
  TITLE  = {Probability elicitation for belief networks: Issues to consider},
  VOLUME = {16},
  XDATA  = {KER},
  YEAR   = {2001},
}

@XDATA{EAP,
  ISSN         = {1474-0028},
  JOURNALTITLE = {Economics and Philosophy},
}

@ARTICLE{Seidenfeld-EAP88j,
  AUTHOR = {Teddy Seidenfeld},
  DATE   = {1988-10},
  DOI    = {10.1017/S0266267100001085},
  FILE   = {files/Seidenfeld-EAP88j.pdf},
  ISSUE  = {2},
  PAGES  = {267–290},
  TITLE  = {Decision theory without “independence” or without “ordering”},
  VOLUME = {4},
  XDATA  = {EAP},
}

@XDATA{DEF,
  JOURNALTITLE = {Decisions in Economics and Finance},
  PUBLISHER    = {Springer-Verlag},
  ISSN         = {1593-8883},
}

@ARTICLE{Bewley-DEF02j,
  AUTHOR = {Bewley, Truman F.},
  DOI    = {10.1007/s102030200006},
  NUMBER = {2},
  FILE   = {files/Bewley-DEF02j.pdf},
  PAGES  = {79–110},
  TITLE  = {Knightian decision theory. Part I},
  VOLUME = {25},
  XDATA  = {DEF},
  YEAR   = {2002},
}

@XDATA{EL,
  JOURNALTITLE = {Economics Letters},
  ISSN         = {0165-1765},
}

@article{Wang-EL11j,
  ABSTRACT = {Non-incentivized belief elicitation has a negative effect on the belief accuracy of experienced observers predicting choices in 2×2 matrix games. This negative impact extends to the accuracy of group beliefs and revised beliefs after forecasters know each other's initial beliefs.},
  AUTHOR   = {Stephanie W. Wang},
  DOI      = {10.1016/j.econlet.2010.11.045},
  FILE     = {files/Wang-EL11j.pdf},
  NUMBER   = {1},
  TITLE    = {Incentive effects: The case of belief elicitation from individuals in groups},
  PAGES    = {30–33},
  KEYWORDS = {Belief elicitation; Incentives; Belief aggregation; Experiments},
  VOLUME   = {111},
  XDATA    = {EL},
  YEAR     = {2011},
}

@XDATA{JET,
  JOURNALTITLE = {Journal of Economic Theory},
  ISSN         = {0022-0531},
  PUBLISHER    = {Elsevier},
}

@ARTICLE{Gilboa+SS-JET13j,
  ABSTRACT = {We present a model of inductive inference that includes, as special cases, Bayesian reasoning, case-based reasoning, and rule-based reasoning. This unified framework allows us to examine how the various modes of inductive inference can be combined and how their relative weights change endogenously. For example, we establish conditions under which an agent who does not know the structure of the data generating process will decrease, over the course of her reasoning, the weight of credence put on Bayesian vs. non-Bayesian reasoning. We illustrate circumstances under which probabilistic models are used until an unexpected outcome occurs, whereupon the agent resorts to more basic reasoning techniques, such as case-based and rule-based reasoning, until enough data are gathered to formulate a new probabilistic model.},
  AUTHOR   = {Itzhak Gilboa and Larry Samuelson and David Schmeidler},
  DOI      = {10.1016/j.jet.2012.11.004},
  KEYWORDS = {Induction, Learning, Analogies, Theories, Case-based reasoning, Rule-based reasoning},
  NUMBER   = {4},
  PAGES    = {1399–1432},
  TITLE    = {Dynamics of Inductive Inference in a Unified Model},
  URL      = {https://hal-hec.archives-ouvertes.fr/hal-00712823},
  VOLUME   = {148},
  XDATA    = {JET},
  YEAR     = {2013},
}


@XDATA{GEB,
  JOURNALTITLE = {Games and Economic Behavior},
  ISSN         = {0899-8256},
  PUBLISHER    = {Elsevier},
}

@ARTICLE{Gayer+Gilboa-GEB14j,
  ABSTRACT = {Abstract We consider the dynamics of reasoning by general rules (theories) and by specific cases (analogies). When an agent faces an exogenous process, we show that, under mild conditions, if reality happens to be simple, the agent will converge to adopt a theory and discard analogical thinking. If, however, reality is complex, analogical reasoning is unlikely to disappear. By contrast, when the agent is a player in a large population coordination game, and the process is generated by all playersʼ predictions, convergence to a theory is much more likely. This may explain how a large population of players selects an equilibrium in such a game, and how social norms emerge. Mixed cases, involving noisy endogenous processes are likely to give rise to complex dynamics of reasoning, switching between theories and analogies.},
  AUTHOR   = {Gabrielle Gayer and Itzhak Gilboa},
  DOI      = {10.1016/j.geb.2013.11.003},
  KEYWORDS = {Case-based reasoning, Rule-based reasoning, Model selection, Social norms", Equilibrium selection},
  PAGES    = {267–283},
  TITLE    = {Analogies and theories: The role of simplicity and the emergence of norms},
  URL      = {https://hal-hec.archives-ouvertes.fr/hal-00712917},
  VOLUME   = {83},
  XDATA    = {GEB},
  YEAR     = {2014},
}


@XDATA{TD,
ISSN         = {0040-5833},
JOURNALTITLE = {Theory and Decision},
PUBLISHER    = {Springer},
}

@ARTICLE{Tillio+GS-TD13j,
  AUTHOR   = {Di Tillio, Alfredo and Gilboa, Itzhak and Samuelson, Larry},
  DOI      = {10.1007/s11238-011-9263-6},
  KEYWORDS = {Induction, Counterfactuals, Prediction},
  NUMBER   = {2},
  PAGES    = {167-182},
  TITLE    = {The predictive role of counterfactuals},
  URL      = {https://hal-hec.archives-ouvertes.fr/hal-00712888},
  VOLUME   = {74},
  XDATA    = {TD},
  YEAR     = {2013},
}


@XDATA{EMS,
  ISSN         = {1364-8152},
  JOURNALTITLE = {Environmental Modelling \& Software},
  PUBLISHER    = {Elsevier},
}

@article{Bastin+CJHPSNMW-ESM13j,
  ABSTRACT = {Web-based distributed modelling architectures are gaining increasing recognition as potentially useful tools to build holistic environmental models, combining individual components in complex workflows. However, existing web-based modelling frameworks currently offer no support for managing uncertainty. On the other hand, the rich array of modelling frameworks and simulation tools which support uncertainty propagation in complex and chained models typically lack the benefits of web based solutions such as ready publication, discoverability and easy access. In this article we describe the developments within the UncertWeb project which are designed to provide uncertainty support in the context of the proposed ‘Model Web’. We give an overview of uncertainty in modelling, review uncertainty management in existing modelling frameworks and consider the semantic and interoperability issues raised by integrated modelling. We describe the scope and architecture required to support uncertainty management as developed in UncertWeb. This includes tools which support elicitation, aggregation/disaggregation, visualisation and uncertainty/sensitivity analysis. We conclude by highlighting areas that require further research and development in UncertWeb, such as model calibration and inference within complex environmental models.},
  AUTHOR   = {Lucy Bastin and Dan Cornford and Richard Jones and Gerard B.M. Heuvelink and Edzer Pebesma and Christoph Stasch and Stefano Nativi and Paolo Mazzetti and Matthew Williams},
  DOI      = {10.1016/j.envsoft.2012.02.008},
  FILE     = {files/Bastin+CJHPSNMW-ESM13j.pdf},
  ISSUETITLE = {Thematic Issue on the Future of Integrated Modeling Science and Technology},
  KEYWORDS = {Uncertainty; Model web; UncertWeb; Web services; Uncertainty propagation; Visualisation; Interoperability},
  PAGES    = {116–134},
  TITLE    = {Managing uncertainty in integrated environmental modelling: The UncertWeb framework},
  URL      = {http://elicitator.uncertweb.org/},
  VOLUME   = {39},
  XDATA    = {EMS},
  YEAR     = {2013},
}

@article{Morris+OC-EMS14j,
  ABSTRACT = {Abstract We present a web-based probability distribution elicitation tool: The \{MATCH\} Uncertainty Elicitation Tool. The Tool is designed to help elicit probability distributions about uncertain model parameters from experts, in situations where suitable data is either unavailable or sparse. The Tool is free to use, and offers five different techniques for eliciting univariate probability distributions. A key feature of the Tool is that users can log in from different sites and view and interact with the same graphical displays, so that expert elicitation sessions can be conducted remotely (in conjunction with tele- or videoconferencing). This will make probability elicitation easier in situations where it is difficult to interview experts in person. Even when conducting elicitation remotely, interviewers will be able to follow good elicitation practice, advise the experts, and provide instantaneous feedback and assistance.},
  AUTHOR   = {David E. Morris and Jeremy E. Oakley and John A. Crowe},
  DOI      = {10.1016/j.envsoft.2013.10.010},
  FILE     = {files/Morris+OC-EMS14j.pdf},
  KEYWORDS = {Bayesian prior distribution; Expert judgement; Subjective probability; Web-based elicitation},
  PAGES    = {1–4},
  TITLE    = {A web-based tool for eliciting probability distributions from experts},
  URL      = {http://www.match.ac.uk/uncertainty/},
  VOLUME   = {52},
  XDATA    = {EMS},
  YEAR     = {2014},
}

@XDATA{TSVTA,
  JOURNALTITLE = {Труды Семинара по Векторному и Тензорному Анализу (Trudy Seminara po Vektornomu i Tenzornomu Analizu)},
  SHORTJOURNAL = {Tr. Semin. Vektorn. Tenzorn. Anal.},
}

@ARTICLE{Alexandrov+KK-TSVTA05j,
  ABSTRACT   = {This is an extended version of a talk on October 4, 2004 at the research seminar “Differential geometry and applications” (headed by Academician A. T. Fomenko) at Moscow State University. The paper contains an overview of available (but far from well-known) results about the Blaschke addition of convex bodies, some new theorems on the monotonicity of the volume of convex bodies (in particular, convex polyhedra with parallel faces) as well as description of a software for visualization of polyhedra with prescribed outward normals and face areas.},
  AUTHOR     = {Victor Alexandrov and Natalia Kopteva and Semen S. Kutateladze},
  EPRINT     = {math/0502345},
  EPRINTTYPE = {arxiv},
  PAGES      = {8–30},
  TITLE      = {Blaschke addition and convex polyhedra},
  VOLUME     = {26},
  YEAR       = {2005},
  XDATA      = {TSVTA},
}

@COLLECTION{Augustin+CCT-ITIP14b,
  TITLE     = {Introduction to Imprecise Probabilities},
  DATE      = {2014-05},
  DOI       = {10.1002/9781118763117},
  EDITOR    = {Thomas Augustin and Frank P. A. Coolen and Gert de Cooman and Matthias C. M. Troffaes},
  ISBN      = {978-0-470-97381-3},
  PUBLISHER = {Wiley},
  SERIES    = {Wiley Series in Probability and Statistics},
}

@INCOLLECTION{Quaeghebeur-ITIP14c,
  AUTHOR   = {Erik Quaeghebeur},
  CHAPTER  = {1},
  CROSSREF = {Augustin+CCT-ITIP14b},
  DOI      = {10.1002/9781118763117.ch1},
  TITLE    = {Desirability},
  PAGES    = {1–27},
}

@INCOLLECTION{Miranda+Cooman-ITIP14c,
  AUTHOR   = {Enrique Miranda and Gert de Cooman},
  CHAPTER  = {2},
  CROSSREF = {Augustin+CCT-ITIP14b},
  DOI      = {10.1002/9781118763117.ch2},
  TITLE    = {Lower previsions},
  PAGES    = {28–55},
}

@INCOLLECTION{Antonucci+CZ-ITIP14c,
  AUTHOR   = {Alessandro Antonucci and Cassio P. de Campos and Marco Zaffalon},
  CHAPTER  = {9},
  CROSSREF = {Augustin+CCT-ITIP14b},
  DOI      = {10.1002/9781118763117.ch9},
  TITLE    = {Probabilistic Graphical Models},
  PAGES    = {207–229},
}

@BOOK{Kohlas+Moral-AUDR01b,
  DATE      = {2001},
  DOI       = {10.1007/978-94-017-1737-3},
  EDITOR    = {Jürg Kohlas and Serafín Moral},
  PUBLISHER = {Springer},
  TITLE     = {Algorithms for uncertainty and defeasible reasoning},
  SERIES    = {Handbook of Defeasible Reasoning and Uncertainty Management Systems},
  VOL       = {5},
}

@INCOLLECTION{Kohlas+Shenoy-AUDR01c,
  AUTHOR   = {Jürg Kohlas and Prakash P. Shenoy},
  CROSSREF = {Kohlas+Moral-AUDR01b},
  DOI      = {10.1007/978-94-017-1737-3_2},
  FILE     = {files/Kohlas+Shenoy-AUDR01c.pdf},
  TITLE    = {Computation in valuation algebras},
  PAGES    = {5-39},
}

@INCOLLECTION{Cano+Moral-AUDR01c,
  AUTHOR   = {Andrés Cano and Serafín Moral},
  CROSSREF = {Kohlas+Moral-AUDR01b},
  DOI      = {10.1007/978-94-017-1737-3_9},
  FILE     = {files/Cano+Moral-HDRUMS01c.pdf},
  PAGES    = {369–420},
  TITLE    = {Algorithms for imprecise probabilities},
}

@COLLECTION{Baswell-AMR10b,
  EDITOR    = {Albert R. Baswell},
  SERIES    = {Advances in Mathematics Research},
  VOLUME    = {11},
  PUBLISHER = {Nova Science Publishers},
  ISBN      = {978-1-60876-970-4},
  YEAR      = {2010},
}

@INCOLLECTION{Piatti+AZ-AMR10c,
  AUTHOR   = {Piatti, Alberto and Antonucci, Alessandro and Zaffalon, Marco},
  CROSSREF = {Baswell-AMR10b},
  FILE     = {files/Piatti+AZ-AMR10c.pdf},
  PAGES    = {227–279},
  TITLE    = {Building knowledge-based systems by credal networks: a tutorial},
}

@XDATA{UAI95,
  EVENTDATE  = {1995},
  EVENTTITLE = {UAI '95},
}

@PROCEEDINGS{Besnard+Hanks-UAI95b,
  DATE      = {1995},
  EDITOR    = {Philippe Besnard and Steve Hanks},
  LOCATION  = {San Francisco, California},
  PUBLISHER = {Morgan Kaufmann},
  TITLE     = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI95},
}

@INPROCEEDINGS{Druzdzel+Gaag-UAI95p,
  AUTHOR   = {Marek J. Druzdzel and Linda C. van der Gaag},
  CROSSREF = {Besnard+Hanks-UAI95b},
  FILE     = {files/Druzdzel+Gaag-UAI95p.pdf},
  PAGES    = {141–148},
  TITLE    = {Elicitation of probabilities for belief networks: Combining qualitative and quantitative information},
}

@XDATA{UAI96,
  EVENTDATE  = {1996-08-01/1996-08-04},
  EVENTTITLE = {UAI '96},
  VENUE      = {Reed College, Portland, Oregon, USA},
}

@PROCEEDINGS{Horvitz+Jensen-UAI96b,
  DATE      = {1996},
  EDITOR    = {Eric Horvitz and Finn Verner Jensen},
  LOCATION  = {San Francisco, California},
  PUBLISHER = {Morgan Kaufmann},
  TITLE     = {Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI96},
}

@INPROCEEDINGS{Chrisman-UAI96p,
  AUTHOR     = {Lonnie Chrisman},
  CROSSREF   = {Horvitz+Jensen-UAI96b},
  EPRINT     = {1302.3569},
  EPRINTTYPE = {arxiv},
  FILE       = {files/Chrisman-UAI96p.pdf},
  PAGES      = {178–185},
  TITLE      = {Propagation of 2-monotone lower probabilities on an undirected graph},
}

@XDATA{UAI99,
  EVENTDATE  = {1999},
  EVENTTITLE = {UAI '99},
}

@PROCEEDINGS{-UAI99b,
  DATE      = {1999},
  LOCATION  = {San Francisco, California},
  PUBLISHER = {Morgan Kaufmann},
  TITLE     = {Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI99},
}

@INPROCEEDINGS{Gaag+RWAT-UAI99p,
  ABSTRACT  = {In building Bayesian belief networks, the elicitation of all probabilities required can be a major obstacle. We learned the extent of this often-cited observation in the construction of the probabilistic part of a complex influence diagram in the field of cancer treatment. Based upon our negative experiences with existing methods, we designed a new method for probability elicitation from domain experts. The method combines various ideas, among which are the ideas of transcribing probabilities and of using a scale with both numerical and verbal anchors for marking assessments. In the construction of the probabilistic part of our influence diagram, the method proved to allow for the elicitation of many probabilities in little time.},
  AUTHOR    = {Linda C. van der Gaag and Silja Renooij and Cilia L. M. Witteman and Berthe M. P. Aleman and Babs G. Taal},
  CROSSREF   = {-UAI99b},
  KEYWORDS  = {belief networks; expert elicitation},
  PAGES     = {647–654},
  PUBLISHER = {Morgan Kaufmann},
  TITLE     = {How to elicit many probabilities},
}


@XDATA{UAI02,
  EVENTDATE  = {2002-08-01/2002-08-04},
  EVENTTITLE = {UAI '02},
  VENUE      = {University of Alberta, Edmonton, Alberta, Canada},
}

@PROCEEDINGS{Darwiche+Friedman-UAI02b,
  DATE      = {2002},
  EDITOR    = {Adnan Darwiche and Nir Friedman},
  TITLE     = {Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence},
  PUBLISHER = {Morgan Kaufmann},
  XDATA     = {UAI02},
}

@INPROCEEDINGS{Renooij+Gaag-UAI02p,
  AUTHOR   = {Silja Renooij and Linda C. van der Gaag},
  CROSSREF = {Darwiche+Friedman-UAI02b},
  FILE     = {files/Renooij+Gaag-UAI02p.pdf},
  PAGES    = {422–429},
  TITLE    = {From qualitative to quantitative probabilistic networks},
}

@XDATA{UAI04,
  EVENTDATE  = {2004-07-07/2004-07-11},
  EVENTTITLE = {UAI '04},
  VENUE      = {Banff, Canada},
}

@PROCEEDINGS{Chickering+Halpern-UAI04b,
  DATE      = {2004},
  EDITOR    = {David Maxwell Chickering and Joseph Y. Halpern},
  LOCATION  = {Arlington, Virginia},
  PUBLISHER = {AUAI Press},
  TITLE     = {Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI04},
}

@INPROCEEDINGS{Gaag+BF-UAI04p,
  AUTHOR    = {Linda C. van der Gaag and Hans L. Bodlaender and Ad Feelders},
  CROSSREF  = {Chickering+Halpern-UAI04b},
  FILE      = {files/Gaag+BF-UAI04p.pdf},
  PAGES     = {569–576},
  TITLE     = {Monotonicity in Bayesian networks},
}

@INPROCEEDINGS{Renooij-Gaag-UAI04,
  AUTHOR    = {Silja Renooij and Linda C. van der Gaag},
  CROSSREF  = {Chickering+Halpern-UAI04b},
  PAGES     = {479–486},
  TITLE     = {Evidence-invariant sensitivity bounds},
}

@XDATA{UAI05,
  EVENTDATE  = {2005},
  EVENTTITLE = {UAI '05},
}

@PROCEEDINGS{-UAI05b,
  DATE      = {2005},
  ISBN      = {0-9749039-1-4},
  PUBLISHER = {AUAI Press},
  TITLE     = {Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI05},
}

@INPROCEEDINGS{Campos+Cozman-UAI05p,
  AUTHOR     = {Cassio Polpo de Campos and Fabio Gagliardi Cozman},
  CROSSREF   = {-UAI05b},
  EPRINT     = {1207.1367},
  EPRINTTYPE = {arxiv},
  FILE       = {files/Campos+Cozman-UAI05p.pdf},
  PAGES      = {153–160},
  TITLE      = {Belief updating and learning in semi-qualitative probabilistic networks},
}

@XDATA{UAI08,
  EVENTDATE  = {2008-07-09/2008-07-12},
  EVENTTITLE = {UAI 2008},
  VENUE      = {Helsinki, Finland},
}

@PROCEEDINGS{McAllester+Myllymäki-UAI08b,
  DATE   = {2008},
  EDITOR = {D. McAllester and P. Myllymäki},
  TITLE  = {Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence},
  XDATA  = {UAI08},
}

@INPROCEEDINGS{Cooman+HQ-UAI08p,
  ABSTRACT   = {When the initial and transition probabilities of a finite Markov chain in discrete time are not well known, we should perform a sensitivity analysis. This is done by considering as basic uncertainty models the so-called credal sets that these probabilities are known or believed to belong to, and by allowing the probabilities to vary over such sets. This leads to the definition of an imprecise Markov chain. We show that the time evolution of such a system can be studied very efficiently using so-called lower and upper expectations. We also study how the inferred credal set about the state at time n evolves as n goes to infinity: under quite unrestrictive conditions, it converges to a uniquely invariant credal set, regardless of the credal set given for the initial state. This leads to a non-trivial generalisation of the classical Perron–Frobenius Theorem to imprecise Markov chains.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  CROSSREF   = {McAllester+Myllymäki-UAI08b},
  EPRINT     = {1854/LU-427340},
  EPRINTTYPE = {hdl},
  PAGES      = {129–136},
  TITLE      = {Sensitivity analysis for finite Markov chains in discrete time},
}

@XDATA{UAI10,
  EVENTDATE  = {2010-07-08/2010-07-11},
  EVENTTITLE = {UAI 2010},
  VENUE      = {Catalina Island, California},
}

@PROCEEDINGS{Spirtes+Grünwald-UAI10b,
  DATE      = {2010},
  EDITOR    = {Peter Spirtes and Peter Grünwald},
  PUBLISHER = {AUAI Press},
  TITLE     = {Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI10},
}

@INPROCEEDINGS{Quaeghebeur-UAI10p,
  ABSTRACT   = {The standard coherence criterion for lower previsions is expressed using an infinite number of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such lower prevision is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Spirtes+Grünwald-UAI10b},
  EPRINT     = {1854/LU-984156},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherence; lower previsions; polytopes; constraints; vertices; extreme points; characterization; computation},
  PAGES      = {466–473},
  TITLE      = {Characterizing the set of coherent lower previsions with a finite number of constraints or vertices},
}

@XDATA{IJCAI11,
  EVENTTITLE = {IJCAI 2011},
}

@PROCEEDINGS{-IJCAI11b,
  DATE  = {2011},
  TITLE = {Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence},
  XDATA = {IJCAI11},
}

@INPROCEEDINGS{Finger+Bona-IJCAI11p,
  AUTHOR   = {Marcelo Finger and Glauber De Bona},
  CROSSREF = {-IJCAI11b},
  FILE     = {Finger+Bona-IJCAI11p.pdf},
  PAGES    = {528–533},
  TITLE    = {Probabilistic satisfiability: logic-based algorithms and phase transition},
}

@XDATA{AAAI13,
  EVENTDATE  = {2013-07-14/2013-07-18},
  EVENTTITLE = {AAAI-13},
  VENUE      = {Bellevue, Washington},
}

@PROCEEDINGS{-AAAI13b,
  DATE      = {2013},
  TITLE     = {Proceedings of the Twenty-Seventh AAAI Conference on Artificial Intelligence},
  PUBLISHER = {AAAI Press},
  XDATA     = {AAAI13},
}

@INPROCEEDINGS{Campos+Cozman-AAAI13p,
  AUTHOR   = {Cassio Polpo de Campos and Fabio Gagliardi Cozman},
  CROSSREF = {-AAAI13b},
  PAGES    = {217–223},
  TITLE    = {Complexity of inferences in polytree-shaped semi-qualitative probabilistic networks},
}

@XDATA{ECAI10,
  EVENTDATE  = {2010-08-16/2010-08-16},
  EVENTTITLE = {ECAI 2010},
  VENUE = {Lisbon, Portugal},
}

@PROCEEDINGS{Coelho+SW-ECAI10b,
  ISBN      = {978-1-60750-605-8},
  EDITOR    = {Helder Coelho and Rudi Studer and Michael Wooldridge},
  LOCATION  = {Amsterdam, the Netherlands},
  PUBLISHER = {IOS Press},
  SERIES    = {Frontiers in Artificial Intelligence and Applications},
  TITLE     = {Proceedings of the 19th European Conference on Artificial Intelligence},
  VOLUME    = {215},
  XDATA     = {ECAI10},
  YEAR      = {2010},
}

@INPROCEEDINGS{Kwisthout+BG-ECAI10p,
  AUTHOR   = {Johan H. P. Kwisthout and Hans L. Bodlaender and Linda C. van der Gaag},
  CROSSREF = {Coelho+SW-ECAI10b},
  PAGES    = {237–242},
  TITLE    = {The necessity of bounded treewidth for efficient inference in Bayesian networks},
}

@XDATA{ISIPTA03,
  EVENTDATE    = {2003-07-14/2003-07-17},
  EVENTTITLE   = {ISIPTA '03},
  ORGANIZATION = {SIPTA},
  VENUE        = {Lugano, Switzerland},
}

@PROCEEDINGS{Bernard+SZ-ISIPTA03b,
  DATE      = {2003},
  EDITOR    = {Jean-Marc Bernard and Teddy Seidenfeld and Marco Zaffalon},
  ISBN      = {9781894145176},
  LOCATION  = {Waterloo, Ontario, Canada},
  PUBLISHER = {Carleton Scientific},
  SERIES    = {Proceedings in Informatics},
  TITLE     = {Proceedings of the Third International Symposium on Imprecise Probabilities and Their Applications},
  VOLUME    = {18},
  XDATA     = {ISIPTA03},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-ISIPTA03p,
  ABSTRACT   = {We discuss two approaches for choosing a strategy in a two-player game. We suppose that the game is played a large number of rounds, which allows the players to use observations of past play to guide them in choosing a strategy. Central in these approaches is the way the opponent's next strategy is assessed; both a precise and an imprecise Dirichlet model are used. The observations of the opponent's past strategies can then be used to update the model and obtain new assessments. To some extent, the imprecise probability approach allows us to avoid making arbitrary initial assessments. To be able to choose a strategy, the assessment of the opponent's strategy is combined with rules for selecting an optimal response to it: a so-called best response or a maximin strategy. Together with the updating procedure, this allows us to choose strategies for all the rounds of the game. The resulting playing sequence can then be analysed to investigate if the strategy choices can converge to equilibria.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {Bernard+SZ-ISIPTA03b},
  EPRINT     = {1854/LU-213482},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {imprecise Dirichlet model; game theory; fictitious play; learning; equilibria},
  PAGES      = {452–466},
  TITLE      = {Game-theoretic learning using the imprecise Dirichlet model},
}

@XDATA{ISIPTA05,
  EVENTDATE    = {2005-07-20/2005-07-23},
  EVENTTITLE   = {ISIPTA '05},
  ORGANIZATION = {SIPTA},
  VENUE        = {Pittsburgh, Pennsylvania},
}

@PROCEEDINGS{Cozman+NS-ISIPTA05b,
  DATE   = {2005},
  EDITOR = {Fabio Gagliardi Cozman and Robert Nau and Teddy Seidenfeld},
  TITLE  = {Proceedings of the Fourth International Symposium on Imprecise Probabilities and Their Applications},
  XDATA  = {ISIPTA05},
}

@INPROCEEDINGS{Cooman+TM-ISIPTA05p,
  AUTHOR   = {Gert de Cooman and Matthias C. M. Troffaes and Enrique Miranda},
  CROSSREF = {Cozman+NS-ISIPTA05b},
  PAGES    = {145–154},
  TITLE    = {n-Monotone lower previsions and lower integrals},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-ISIPTA05p,
  ABSTRACT   = {When considering sampling models described by a distribution from an exponential family, it is possible to create two types of imprecise probability models. One is based on the corresponding conjugate distribution and the other on the corresponding predictive distribution. In this paper, we show how these types of models can be constructed for any (regular, linear, canonical) exponential family, such as the centered normal distribution. To illustrate the possible use of such models, we take a look at credal classification. We show that they are very natural and potentially promising candidates for describing the attributes of a credal classifier, also in the case of continuous attributes.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {Cozman+NS-ISIPTA05b},
  EPRINT     = {1854/LU-320871},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Exponential family; Inference; Imprecise probability models; Conjugate analysis; Naive credal classifier},
  PAGES      = {287–296},
  TITLE      = {Imprecise probability models for inference in exponential families},
}

@INPROCEEDINGS{Wallner-ISIPTA05p,
  AUTHOR   = {Anton Wallner},
  CROSSREF = {Cozman+NS-ISIPTA05b},
  PAGES    = {388–395},
  TITLE    = {Maximal number of vertices of polytopes defined by F-probabilities},
}

@XDATA{ISIPTA07,
  EVENTDATE    = {2007-07-16/2007-07-19},
  EVENTTITLE   = {ISIPTA '07},
  ORGANIZATION = {SIPTA},
  VENUE        = {Prague, Czech Republic},
}

@PROCEEDINGS{Cooman+VZ-ISIPTA07b,
  DATE   = {2007},
  EDITOR = {Gert de Cooman and Jiřina Vejnarová and Marco Zaffalon},
  TITLE  = {Proceedings of the Fifth International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA07},
}

@INPROCEEDINGS{Cooman+MQ-ISIPTA07p,
  ABSTRACT   = {We consider immediate predictive inference, where a subject, using a number of observations of a finite number of exchangeable random variables, is asked to coherently model his beliefs about the next observation, in terms of a predictive lower prevision. We study when such predictive lower previsions are representation insensitive, meaning that they are essentially independent of the choice of the (finite) set of possible values for the random variables. Such representation insensitive predictive models have very interesting properties, and among such models, the ones produced by the Imprecise Dirichlet-Multinomial Model are quite special in a number of ways.},
  AUTHOR     = {Gert de Cooman and Enrique Miranda and Erik Quaeghebeur},
  CROSSREF   = {Cooman+VZ-ISIPTA07b},
  EPRINT     = {1854/LU-371965},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherence; exchangeability; immediate prediction; predictive inference; imprecise Dirichlet-Multinomial model; lower prevision; coherence; representation insensitivity; exchangeability; immediate prediction; representation invariance; Johnson's sufficientness postulate},
  TITLE      = {Immediate prediction under exchangeability and representation insensitivity},
}

@XDATA{ISIPTA09,
  EVENTDATE    = {2009-07-14/2009-07-18},
  EVENTTITLE   = {ISIPTA '09},
  ORGANIZATION = {SIPTA},
  VENUE        = {Durham, United Kingdom},
}

@PROCEEDINGS{Augustin+CMT-ISIPTA09b,
  DATE   = {2009},
  EDITOR = {Thomas Augustin and Frank P. A. Coolen and Serafín Moral and Matthias C. M. Troffaes},
  TITLE  = {Proceedings of the Sixth International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA09},
}

@INPROCEEDINGS{Cooman+Quaeghebeur-ISIPTA09p,
  ABSTRACT   = {Sets of desirable gambles constitute a quite general type of uncertainty model with an interesting geometrical interpretation. We study exchangeability assessments for such models, and prove a counterpart of de Finetti's finite representation theorem. We show that this representation theorem has a very nice geometrical interpretation. We also lay bare the relationships between the representations of updated exchangeable models, and discuss conservative inference (natural extension) under exchangeability.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {Augustin+CMT-ISIPTA09b},
  EPRINT     = {1854/LU-718913},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherence; exchangeability; sets of desirable gambles; weak desirability; representation; desirability; natural extension; real desirability; updating},
  PAGES      = {159–168},
  TITLE      = {Exchangeability for sets of desirable gambles},
}

@INPROCEEDINGS{Shariatmadar+QC-ISIPTA09a,
  AUTHOR     = {Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {ISIPTA '09: Program \& Abstracts},
  EPRINT     = {1854/LU-718910},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {vacuous prevision; possibility distribution; maximinity; constrained optimization; p-box; linear prevision; maximality},
  PAGES      = {34–34},
  TITLE      = {A constrained optimization problem under uncertainty},
  YEAR       = {2009},
  XDATA      = {ISIPTA09},
}

@XDATA{ISIPTA11,
  EVENTDATE    = {2011-07-25/2011-07-28},
  EVENTTITLE   = {ISIPTA '11},
  ORGANIZATION = {SIPTA},
  VENUE        = {Innsbruck, Austria},
}

@PROCEEDINGS{Coolen+CFO-ISIPTA11b,
  DATE      = {2011},
  EDITOR    = {Frank P. A. Coolen and Gert de Cooman and Thomas Fetz and Michael Oberguggenberger},
  PUBLISHER = {SIPTA},
  TITLE     = {Proceedings of the Seventh International Symposium on Imprecise Probability: Theories and Applications},
  XDATA     = {ISIPTA11},
}

@INPROCEEDINGS{Bock+Cooman-ISIPTA11p,
  ABSTRACT = {We present an efficient exact algorithm for estimating state sequences from outputs (or observations) in imprecise hidden Markov models (iHMM), where both the uncertainty linking one state to the next, and that linking a state to its output, are represented using coherent lower previsions. The notion of independence we associate with the credal network representing the iHMM is that of epistemic irrelevance. We consider as best estimates for state sequences the (Walley–Sen) maximal sequences for the posterior joint state model (conditioned on the observed output sequence), associated with a gain function that is the indicator of the state sequence. This corresponds to (and generalises) finding the state sequence with the highest posterior probability in HMMs with precise transition and output probabilities (pHMMs). We argue that the computational complexity is at worst quadratic in the length of the Markov chain, cubic in the number of states, and essentially linear in the number of maximal state sequences. For binary iHMMs, we investigate experimentally how the number of maximal state sequences depends on the model parameters.},
  AUTHOR   = {De Bock, Jasper and Gert de Cooman},
  CROSSREF = {Coolen+CFO-ISIPTA11b},
  PAGES    = {159–168},
  TITLE    = {State sequence prediction in imprecise hidden Markov models},
}

@PROCEEDINGS{-ISIPTA11b,
  DATE  = {2011},
  TITLE = {Program and Abstracts},
  XDATA = {ISIPTA11},
}

@INPROCEEDINGS{Quaeghebeur+CH-ISIPTA11a,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Filip Hermans},
  CROSSREF   = {-ISIPTA11b},
  EPRINT     = {1854/LU-1863955},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {acceptability; desirability; favorability; indifference; preference},
  PAGES      = {29},
  TITLE      = {Generalizing nonstrict and strict preference desirability},
}

@INPROCEEDINGS{Camp+CBQH-ISIPTA11a,
  AUTHOR     = {Van Camp, Arthur and Gert de Cooman and De Bock, Jasper and Erik Quaeghebeur and Filip Hermans},
  CROSSREF   = {-ISIPTA11b},
  EPRINT     = {1854/LU-1863971},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {hidden Markov models; learning; imprecise Dirichlet model; expected counts},
  PAGES      = {34},
  TITLE      = {Learning imprecise hidden Markov models},
}

@INPROCEEDINGS{Shariatmadar+QC-ISIPTA11a,
  AUTHOR     = {Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {-ISIPTA11b},
  EPRINT     = {1854/LU-1225787},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {maximality; linear programming; maximinity; possibility distribution; vacuous prevision},
  PAGES      = {31},
  TITLE      = {Linear programming under vacuous and possibilistic uncertainty},
}

@XDATA{ISIPTA13,
  EVENTDATE    = {2013-07-02/2013-07-05},
  EVENTTITLE   = {ISIPTA '13},
  ORGANIZATION = {SIPTA},
  VENUE        = {Compiègne, France},
}

@PROCEEDINGS{Cozman+DDS-ISIPTA13b,
  DATE   = {2013},
  EDITOR = {Fabio Cozman and Thierry Denœux and Sébastien Destercke and Teddy Seidenfeld},
  TITLE  = {Proceedings of the Eight International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA13},
}

@INPROCEEDINGS{Bock+Cooman-ISIPTA13p,
  AUTHOR     = {De Bock, Jasper and Gert de Cooman},
  CROSSREF   = {Cozman+DDS-ISIPTA13b},
  PAGES      = {99–108},
  TITLE      = {Credal networks under epistemic irrelevance using sets of desirable gambles},
}

@INPROCEEDINGS{Quaeghebeur-ISIPTA13p,
  ABSTRACT   = {Lower previsions defined on a finite set of gambles can be looked at as points in a finite-dimensional real vector space. Within that vector space, the sets of sure loss avoiding and coherent lower previsions form convex polyhedra. We present procedures for obtaining characterizations of these polyhedra in terms of a minimal, finite number of linear constraints. As compared to the previously known procedure, these procedures are more efficient and much more straightforward. Next, we take a look at a procedure for correcting incoherent lower previsions based on pointwise dominance. This procedure can be formulated as a multi-objective linear program, and the availability of the finite characterizations provide an avenue for making these programs computationally feasible.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Cozman+DDS-ISIPTA13b},
  KEYWORDS   = {avoiding sure loss; coherence; linear constraint; polytope; enumeration; projection; multi-objective linear programming; incoherence; dominance},
  PAGES      = {275–284},
  TITLE      = {Characterizing coherence, correcting incoherence},
}

@XDATA{ISIPTA15,
  EVENTDATE    = {2015-07-20/2015-07-24},
  EVENTTITLE   = {ISIPTA '15},
  ORGANIZATION = {SIPTA},
  VENUE        = {Pescara, Italy},
}

@PROCEEDINGS{Augustin+DMQ-ISIPTA15b,
  DATE   = {2015},
  EDITOR = {Thomas Augustin and Serena Doria and Enrique Miranda and Erik Quaeghebeur},
  TITLE  = {Proceedings of the Ninth International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA15},
}

@INPROCEEDINGS{Camp+CMQ-ISIPTA15p,
  AUTHOR     = {Van Camp, Arthur and Gert de Cooman and Enrique Miranda and Erik Quaeghebeur},
  CROSSREF   = {Augustin+DMQ-ISIPTA15b},
  PAGES      = {305–314},
  TITLE      = {Modelling indifference with choice functions},
}

@INPROCEEDINGS{Quaeghebeur-ISIPTA15a,
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Augustin+DMQ-ISIPTA15b},
  PAGES      = {347},
  TITLE      = {Partial partial preference order orders},
}

@INPROCEEDINGS{Quaeghebeur+WBPS-ISIPTA15a,
  AUTHOR     = {Erik Quaeghebeur and Chris Wesseling and Emma Beauxis-Aussalet and Teresa Piovesan and Tom Sterkenburg},
  CROSSREF   = {Augustin+DMQ-ISIPTA15b},
  PAGES      = {348},
  TITLE      = {The CWI World Cup Competition: Eliciting Sets of Acceptable Gambles},
}

@XDATA{IPSP14,
  EVENTDATE    = {2014-06-27/2014-06-28},
  EVENTTITLE   = {IPSP '14},
  ORGANIZATION = {SIPTA},
  VENUE        = {München, Germany},
}

@INPROCEEDINGS{Camp+CQ-IPSP14a,
  ABSTRACT  = {We study Seidenfeld, Schervish, and Kadane’s notion of choice functions, and want to make them accessible to people who are familiar with sets of desirable gambles. We relate both theories explicitly using their derived strict partial orderings. We give an expression for the most conservative extension of a set of desirable gambles to a choice function. Because it is important for inference purposes, we also make a link with belief structures.},
  AUTHOR    = {Van Camp, Arthur and Gert de Cooman and Erik Quaeghebeur},
  BOOKTITLE = {Imprecise Probabilities in Statistics and Philosophy, Abstracts},
  CROSSREF  = {IPSP14},
  FILE      = {files/Camp+CQ-IPSP14a.pdf},
  PAGETOTAL = {6},
  TITLE     = {Connecting choice functions and sets of desirable gambles},
}

@XDATA{ECSQARU09,
  EVENTDATE  = {2009},
  EVENTTITLE = {ECSQARU 2009},
}

@PROCEEDINGS{Sossai+Chemello-ECSQARU09b,
  TITLE     = {Symbolic and Quantitative Approaches to Reasoning with Uncertainty},
  EDITOR    = {Claudio Sossai and Gaetano Chemello},
  ISBN      = {978-3-642-02905-9},
  PUBLISHER = {Springer},
  SERIES    = {Lecture Notes in Computer Science},
  VOLUME    = {5590},
  XDATA     = {ECSQARU09},
  YEAR      = {2009},
}

@INPROCEEDINGS{Gaag+RSH-ECSQUARU09p,
  AUTHOR   = {Linda C. van der Gaag and Silja Renooij and Wilma Steeneveld and Henk Hogeveen},
  CROSSREF = {Sossai+Chemello-ECSQARU09b},
  DOI      = {10.1007/978-3-642-02906-6_45},
  FILE     = {files/Gaag+RSH-ECSQUARU09p.pdf},
  PAGES    = {518–529},
  TITLE    = {When in doubt ... be indecisive},
}

@XDATA{ECSQARU13,
  EVENTDATE  = {2013-07-08/2013-07-10},
  EVENTTITLE = {ECSQARU 2013},
  VENUE      = {Utrecht, Netherlands},
}

@PROCEEDINGS{Gaag-ECSQARU13b,
  TITLE     = {Symbolic and Quantitative Approaches to Reasoning with Uncertainty},
  EDITOR    = {Linda C. van der Gaag},
  ISBN      = {978-3-642-39090-6},
  PUBLISHER = {Springer},
  SERIES    = {Lecture Notes in Artificial Intelligence},
  VOLUME    = {7958},
  XDATA     = {ECSQARU13},
  YEAR      = {2013},
}

@INPROCEEDINGS{Antonucci+CHZ-ECSQUARU13p,
  AUTHOR   = { Alessandro Antonucci and Cassio P. de Campos and David Huber and Marco Zaffalon},
  CROSSREF = {Gaag-ECSQARU13b},
  DOI      = {10.1007/978-3-642-39091-3_2},
  FILE     = {files/Antonucci+CHZ-ECSQUARU13p.pdf},
  PAGES    = {13–25},
  TITLE    = {Approximating credal network inferences by linear programming},
}

@INPROCEEDINGS{Cozman+Ianni-ECSQUARU13p,
  AUTHOR   = {Fabio Gagliardi Cozman and Lucas Fargoni di Ianni},
  CROSSREF = {Gaag-ECSQARU13b},
  DOI      = {10.1007/978-3-642-39091-3_13},
  FILE     = {files/Cozman+Ianni-ECSQUARU09p},
  PAGES    = {145–156},
  TITLE    = {Probabilistic Satisfiability and Coherence Checking through Integer Programming},
}

@XDATA{SMPS06,
  EVENTDATE  = {2006-09-05/2006-09-07},
  EVENTTITLE = {SMPS 2006},
  VENUE      = {Bristol, England},
}

@PROCEEDINGS{Lawry+MBLGGH-SMPS06b,
  EDITOR    = {Jonathan Lawry and Enrique Miranda and A. Bugarin and Shoumei Li and María Ángeles Gil and Przemysław Grzegorzewski and Olgierd Hryniewicz},
  ISBN      = {978-3540347767},
  ISSN      = {1615-3871},
  PUBLISHER = {Springer},
  TITLE     = {Soft Methods for Integrated Uncertainty Modelling},
  SERIES    = {Advances in Soft Computing},
  VOLUME    = {6},
  XDATA     = {SMPS06},
  YEAR      = {2006},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-SMPS06p,
  ABSTRACT   = {We consider lower probabilities on finite possibility spaces as models for the uncertainty about the state. These generalizations of classical probabilities can have some interesting properties; for example: k-monotonicity, avoiding sure loss, coherence, permutation invariance. The sets formed by all the lower probabilities satisfying zero or more of these properties are convex. We show how the extreme points and rays of these sets – the extreme lower probabilities – can be calculated and we give an illustration of our results.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {Lawry+MBLGGH-SMPS06b},
  DOI        = {10.1007/3-540-34777-1_26},
  EPRINT     = {1854/LU-406341},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {extreme points; Lower probabilities; imprecise probabilities},
  PAGES      = {211–221},
  TITLE      = {Extreme lower probabilities},
}

@XDATA{SMPS08,
  EVENTDATE  = {2008-09-08/2008-09-10},
  EVENTTITLE = {SMPS 2008},
  VENUE      = {Toulouse, France},
}

@PROCEEDINGS{Dubois+LPGGH-SMPS08b,
  DATE      = {2008},
  EDITOR    = {Didier Dubois and M. A. Lubiano and H. Prade and María Ángeles Gil and Przemysław Grzegorzewski and Olgierd Hryniewicz},
  PUBLISHER = {Springer},
  SERIES    = {Advances in Soft Computing},
  TITLE     = {Soft methods for handling variability and imprecision},
  VOLUME    = {48},
  XDATA     = {SMPS08},
}

@INPROCEEDINGS{Quaeghebeur-SMPS08p,
  ABSTRACT   = {We give a definition for lower and upper covariance in Walley's theory of imprecise probabilities (or coherent lower previsions) that is direct, i.e., does not refer to credal sets. It generalizes Walley's definition for lower and upper variance. Just like Walley's definition of lower and upper variance, our definition for lower and upper covariance is compatible with the credal set approach; i.e., we also provide a covariance envelope theorem. Our approach mirrors the one taken by Walley: we first reformulate the calculation of a covariance as an optimization problem and then generalize this optimization problem to lower and upper previsions. We also briefly discuss the still unclear meaning of lower and upper (co)variances and mention some ideas about generalizations to other central moments.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Dubois+LPGGH-SMPS08b},
  DOI        = {10.1007/978-3-540-85027-4_39},
  EPRINT     = {1854/LU-445579},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {central moment; covariance; envelope theorem; variance; theory of imprecise probabilities},
  PAGES      = {323–330},
  TITLE      = {Lower and upper covariance},
}

@XDATA{SMPS12,
  EVENTDATE  = {2012-10-04/2012-10-06},
  EVENTTITLE = {SMPS 2012},
  VENUE      = {Konstanz, Germany},
}

@PROCEEDINGS{Kruse+BMGGH-SMPS12b,
  DATE      = {2013},
  EDITOR    = {Rudolf Kruse and Michael R. Berthold and Christian Moewes and María Ángeles Gil and Przemysław Grzegorzewski and Olgierd Hryniewicz},
  PUBLISHER = {Springer},
  SERIES    = {Advances in Soft Computing},
  TITLE     = {Synergies of Soft Computing and Statistics for Intelligent Data Analysis},
  VOLUME    = {190},
  XDATA     = {SMPS12},
}

@INPROCEEDINGS{Quaeghebeur-SMPS12p,
  ABSTRACT   = {Uncertainty models such as sets of desirable gambles and (conditional) lower previsions can be represented as convex cones. Checking the consistency of and drawing inferences from such models requires solving feasibility and optimization problems. We consider finitely generated such models. For closed cones, we can use linear programming; for conditional lower prevision-based cones, there is an efficient algorithm using an iteration of linear programs. We present an efficient algorithm for general cones that also uses an iteration of linear programs.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Kruse+BMGGH-SMPS12b},
  DOI        = {10.1007/978-3-642-33042-1_6},
  EPRINT     = {1854/LU-3007274},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Consistency; convex cones; feasibility; inference; linear programming},
  PAGES      = {45–54},
  TITLE      = {The CONEstrip algorithm},
}

@XDATA{NLMUA2011,
  EVENTDATE  = {2011-09-07/2011-09-09},
  EVENTTITLE = {NLMUA 2011},
  VENUE      = {Beijing, China},
}

@PROCEEDINGS{Li+WOKMG-NLMUA11b,
  EDITOR    = {Shoumei Li and Xia Wang and Yoshiaki Okazaki and Jun Kawabe and Toshiaki Murofushi and Li Guan},
  PUBLISHER = {Springer},
  SERIES    = {Advances in Intelligent and Soft Computing},
  TITLE     = {Nonlinear Mathematics for Uncertainty and its Applications},
  VOLUME    = {100},
  YEAR      = {2011},
  XDATA     = {NLMUA2011},
}

@INPROCEEDINGS{Quaeghebeur-NLMUA11p,
  ABSTRACT   = {Drawing inferences from general lower probabilities on finite possibility spaces usually involves solving linear programming problems. For some applications this may be too computationally demanding. Some special classes of lower probabilities allow for using computationally less demanding techniques. One such class is formed by the completely monotone lower probabilities, for which inferences can be drawn efficiently once their Mö bius transform has been calculated. One option is therefore to draw approximate inferences by using a completely monotone approximation to a general lower probability; this must be an outer approximation to avoid drawing inferences that are not implied by the approximated lower probability. In this paper, we discuss existing and new algorithms for performing this approximation, discuss their relative strengths and weaknesses, and illustrate how each one works and performs.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Li+WOKMG-NLMUA11b},
  DOI        = {10.1007/978-3-642-22833-9_20},
  EPRINT     = {1854/LU-1864309},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {outer approximation; lower probabilities; complete monotonicity; belief functions; Möbius transform},
  PAGES      = {169–178},
  TITLE      = {Completely monotone outer approximations of lower probabilities on finite possibility spaces},
}

@XDATA{IPMU96,
  EVENTDATE  = {1996-07-01/1996-07-05},
  EVENTTITLE = {IPMU '96},
  VENUE      = {Granada, Spain},
}

@PROCEEDINGS{-IPMU96b,
  DATE  = {1996},
  TITLE = {Proceedings of the Sixth International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems: IPMU 96},
  XDATA = {IPMU96},
}

@INPROCEEDINGS{Vicig-IPMU96p,
  AUTHOR   = {Paolo Vicig},
  CROSSREF = {-IPMU96b},
  FILE     = {files/Vicig-IPMU96p.pdf},
  PAGES    = {61–66},
  TITLE    = {An algorithm for imprecise conditional probability assessments in expert systems},
  VOLUME   = {1},
}

@INPROCEEDINGS{Moral+Wilson-IPMU96p,
  ANNOTATION = {ook op papier},
  CROSSREF   = {-IPMU96b},
  AUTHOR     = {Serafín Moral and Nic Wilson},
  PAGES      = {1337–1344},
  TITLE      = {Importance sampling algorithms for the calculation of Dempster-Shafer belief},
  VOLUME     = {3},
}

@XDATA{IPMU02,
  EVENTDATE  = {2002},
  EVENTTITLE = {IPMU 2002},
}

@PROCEEDINGS{-IPMU02b,
  DATE  = {2002},
  TITLE = {Proceedings of the Ninth International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems},
  XDATA = {IPMU02},
}

@INPROCEEDINGS{Miranda+CC-IPMU02p,
  ABSTRACT   = {We discuss how lower previsions induced by multi-valued mappings fit into the framework of the behavioural theory of imprecise probabilities, and show how the notions of coherence and natural extension from that theory can be used to prove and generalise existing results in an elegant and straightforward manner. This provides a clear example for their explanatory and unifying power.},
  ANNOTATION = {uitgebreide versie, ook op papier},
  CROSSREF   = {-IPMU02b},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Inés Couso},
  KEYWORDS   = {coherence; conditioning; evidence theory},
  TITLE      = {Lower previsions induced by multi-valued mappings},
}

@XDATA{IPMU06,
  EVENTDATE  = {2006-07-02/2006-07-02},
  EVENTTITLE = {IPMU 2006},
  VENUE      = {Paris, France},
}

@PROCEEDINGS{-IPMU06b,
  DATE       = {2006},
  PUBLISHER  = {Editions E.D.K.},
  TITLEADDON = {Proceedings of the Eleventh International Conference on Information Processing and Management of Uncertainty in Knowledge-based Systems},
  TITLE      = {Information Processing and Management of Uncertainty in Knowledge-based Systems},
  XDATA      = {IPMU06},
}

@INPROCEEDINGS{Miranda+CQ-IPMU06p,
  ABSTRACT   = {We study the moment problem for finitely additive probabilities and show that the information provided by the moments is equivalent to the one given by the associated lower and upper distribution functions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {-IPMU06b},
  EPRINT     = {1854/LU-344503},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherent lower previsions; moment problem; lower and upper distribution functions},
  PAGES      = {89–96},
  TITLE      = {The moment problem for finitely additive probabilities},
  VOLUME     = {1},
}

@COLLECTION{Bouchon+YMR-UIIS08b,
  DATE      = {2008},
  EDITOR    = {Bernadette Bouchon-Meunier and Ronald R. Yager and C. Marsala and M. Rifqi},
  ISBN      = {978-981-279-234-1},
  PUBLISHER = {World Scientific},
  TITLE     = {Uncertainty and Intelligent Information Systems},
  URL       = {http://www.worldscibooks.com/compsci/6747.html},
}

@INCOLLECTION{Miranda+CQ-UIIS08c,
  ABSTRACT   = {We study the moment problem for finitely additive probabilities and show that the information provided by the moments is equivalent to the one given by the associated lower and upper distribution functions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {Bouchon+YMR-UIIS08b},
  CHAPTER    = {3},
  EPRINT     = {1854/LU-430153},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherent lower previsions; moment problem; lower and upper distribution functions},
  PAGES      = {33–45},
  TITLE      = {The moment problem for finitely additive probabilities},
}

@XDATA{IPMU10,
  EVENTDATE  = {2010-06-28/2010-07-02},
  EVENTTITLE = {IPMU 2010},
  VENUE      = {Dortmund, Germany},
}

@PROCEEDINGS{Hüllermeier+KH-IPMU10b,
  DATE      = {2010},
  EDITOR    = {Eyke Hüllermeier and Rudolf Kruse and Frank Hoffmann},
  PUBLISHER = {Springer},
  SERIES    = {Communications in Computer and Information Science},
  VOLUME    = {80},
  XDATA     = {IPMU10},
}

@INPROCEEDINGS{Cooman+Quaeghebeur-IPMU10p,
  ABSTRACT   = {Sets of desirable gambles constitute a quite general type of uncertainty model with an interesting geometrical interpretation. We study infinite exchangeability assessments for them, and give a counterpart of de Finetti's infinite representation theorem. We show how the infinite representation in terms of frequency vectors is tied up with multivariate Bernstein (basis) polynomials. We also lay bare the relationships between the representations of updated exchangeable models, and discuss conservative inference (natural extension) under exchangeability.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {Hüllermeier+KH-IPMU10b},
  DOI        = {10.1007/978-3-642-14055-6_7},
  EPRINT     = {1854/LU-984155},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {sets of desirable gambles; weak desirability; natural extension; coherence; desirability; exchangeability; representation; updating},
  PAGES      = {60–69},
  TITLE      = {Infinite exchangeability for sets of desirable gambles},
}

@XDATA{IPMU12,
  EVENTDATE  = {2012-07-09/2012-07-13},
  EVENTTITLE = {IPMU 2012},
  VENUE      = {Catania, Italy},
}

@PROCEEDINGS{Greco+BCFMY-IPMU12b,
  DATE      = {2012},
  EDITOR    = {Salvatore Greco and Bernadette Bouchon-Meunier and Giulianella Coletti and Mario Fedrizzi and Benedetto Matarazzo and Ronald R. Yager},
  ISBN      = {978-3-642-31718-7},
  ISSN      = {1865-0929},
  PUBLISHER = {Springer},
  SERIES    = {Communications in Computer and Information Science},
  TITLE     = {Advances in Computational Intelligence},
  VOLUME    = {299},
  XDATA     = {IPMU12},
}

@INPROCEEDINGS{Gaag+RSEL-IPMU12p,
  AUTHOR   = {Linda C. van der Gaag and Silja Renooij and Hermi J. M. Schijf and Armin R. W. Elbers and Willie L. A. Loeffen},
  CROSSREF = {Greco+BCFMY-IPMU12b},
  DOI      = {10.1007/978-3-642-31718-7_16},
  FILE     = {file/Gaag+RSEL-IPMU12p.pdf},
  PAGES    = {151–160},
  TITLE    = {Experiences with eliciting probabilities from multiple experts},
}

@INPROCEEDINGS{Couso+Dubois-IPMU12p,
  AUTHOR   = {Couso, Inés and Dubois, Didier},
  CROSSREF = {Greco+BCFMY-IPMU12b},
  DOI      = {10.1007/978-3-642-31718-7_41},
  PAGES    = {388-399},
  TITLE    = {An imprecise probability approach to joint extensions of stochastic and interval orderings},
}

@INPROCEEDINGS{Quaeghebeur+HSC-IPMU12p,
  ABSTRACT   = {We consider linear programming problems with uncertain constraint coefficients described by intervals or, more generally, possibility distributions. The uncertainty is given a behavioral interpretation using coherent lower previsions from the theory of imprecise probabilities. We give a meaning to the linear programming problems by reformulating them as decision problems under such imprecise-probabilistic uncertainty. We provide expressions for and illustrations of the maximin and maximal solutions of these decision problems and present computational approaches for dealing with them.},
  AUTHOR     = {Erik Quaeghebeur and Nathan Huntley and Keivan Shariatmadar and Gert de Cooman},
  CROSSREF   = {Greco+BCFMY-IPMU12b},
  DOI        = {10.1007/978-3-642-31718-7_45},
  EPRINT     = {1854/LU-2090091},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {linear program; interval uncertainty; vacuous lower prevision; possibility distribution; coherent lower prevision; imprecise probabilities; decision making; maximinity; maximality},
  PAGES      = {430–439},
  TITLE      = {Maximin and maximal solutions for linear programming problems with possibilistic uncertainty},
}

@XDATA{IPMU14,
  EVENTDATE  = {2014-07-15/2014-07-19},
  EVENTTITLE = {IPMU 2014},
  VENUE      = {Montpellier, France},
}

@PROCEEDINGS{Laurent+SBY-IPMU14b,
  DATE      = {2014},
  EDITOR    = {Anne Laurent and Olivier Strauss and Bernadette Bouchon-Meunier and Ronald R. Yager},
  ISBN      = {978-3-319-08851-8},
  ISSN      = {1865-0929},
  PUBLISHER = {Springer},
  SERIES    = {Communications in Computer and Information Science},
  TITLE     = {Information Processing and Management of Uncertainty in Knowledge-Based Systems},
  VOLUME    = {444},
  XDATA     = {IPMU14},
}

@INPROCEEDINGS{Quaeghebeur-IPMU14p,
  ABSTRACT   = {We present a variant of the CONEstrip algorithm for checking whether the origin lies in a finitely generated convex cone that can be open, closed, or neither. This variant is designed to deal efficiently with problems where the rays defining the cone are specified as linear combinations of propositional sentences. The variant differs from the original algorithm in that we apply row generation techniques. The generator problem is WPMaxSAT, an optimization variant of SAT; both can be solved with specialized solvers or integer linear programming techniques. We additionally show how optimization problems over the cone can be solved by using our propositional CONEstrip algorithm as a preprocessor. The algorithm is designed to support consistency and inference computations within the theory of sets of desirable gambles. We also make a link to similar computations in probabilistic logic, conditional probability assessments, and imprecise probability theory.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Laurent+SBY-IPMU14b},
  DOI        = {10.1007/978-3-319-08852-5_48},
  KEYWORDS   = {sets of desirable gambles; linear programming; row generation; satisfiability; SAT; PSAT; WPMaxSAT; consistency; coherence; inference; natural extension},
  PAGES      = {466–475},
  TITLE      = {A Propositional CONEstrip Algorithm},
}

@XDATA{FLINS10,
  EVENTDATE  = {2010-08-02/2010-08-04},
  EVENTTITLE = {FLINS 2010},
  VENUE      = {Chengdu, China},
}

@PROCEEDINGS{Ruan+LXCK-FLINS10b,
  DATE       = {2010},
  EDITOR     = {Da Ruan and Yianrui Li and Yang Xu and Guoqing Chen and Etienne E. Kerre},
  LOCATION   = {Singapore},
  PUBLISHER  = {World Scientific},
  SERIES     = {Proceedings Series on Computer Engineering and Information Science},
  TITLE      = {Computational intelligence: foundations and applications},
  XDATA      = {FLINS10},
}

@INPROCEEDINGS{Quaeghebeur+SC-FLINS10p,
  ABSTRACT   = {We investigate a constrained optimization problem for which there is uncertainty about a constraint parameter. Our aim is to reformulate it as a (constrained) optimization problem without uncertainty. This is done by recasting the original problem as a decision problem under uncertainty. We give results for a number of different types of uncertainty models—linear and vacuous previsions, and possibility distributions—and for two different optimality criteria for decision problems under uncertainty—maximinity and maximality.},
  AUTHOR     = {Erik Quaeghebeur and Keivan Shariatmadar and Gert de Cooman},
  CROSSREF   = {Ruan+LXCK-FLINS10b},
  DOI        = {10.1142/9789814324700_0120},
  EPRINT     = {1854/LU-973379},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {possibility distribution; linear prevision; maximinity; maximality; vacuous prevision; constrained optimization},
  PAGES      = {791–796},
  TITLE      = {A constrained optimization problem under uncertainty},
}

@XDATA{FLINS12,
  EVENTDATE  = {2012-08-26/2012-08-29},
  EVENTTITLE = {FLINS 2012},
  VENUE      = {Istanbul, Turkey},
}

@PROCEEDINGS{Kahraman+KB-FLINS12b,
  DATE       = {2012},
  EDITOR     = {Cengiz Kahraman and Etienne E. Kerre and Faik Tunc Bozbura},
  PUBLISHER  = {World Scientific},
  SERIES     = {Proceedings Series on Computer Engineering and Information Science},
  TITLE      = {Uncertainty Modeling in Knowledge Engineering and Decision Making},
  VOLUME     = {7},
  XDATA      = {FLINS12},
}

@INPROCEEDINGS{Huntley+QSQCK-FLINS12p,
  ABSTRACT   = {We present a software implementation of the methods for solving linear programming problems under uncertainty from previous work. Uncertainties about constraint parameters can be expressed as intervals or trapezoidal possibility distributions. The software computes the solutions for the optimality criteria maximin and maximality. For maximality with possibility distributions, only an approximate solution is obtained.},
  AUTHOR     = {Nathan Huntley and Rolando Quiñones and Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman and Etienne E. Kerre},
  CROSSREF   = {Kahraman+KB-FLINS12b},
  DOI        = {10.1142/9789814417747_0075},
  EPRINT     = {1854/LU-3028486},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {linear programming; uncertainty; maximin; maximality; implementation},
  PAGES      = {465–470},
  TITLE      = {Implementation of maximin and maximal solutions for linear programming problems under uncertainty},
}

@INPROCEEDINGS{Cooman+QM-ISI07p,
  ABSTRACT     = {This paper deals with belief models, and in particular lower previsions, for both (finite) collections and (infinite) sequences of exchangeable random variables taking a finite number of values. When such collections or sequences are assumed to be exchangeable, this more or less means that their specific order is irrelevant. We show that exchangeable lower previsions can be written as a combination of (i) a coherent prevision expressing that permutations of realisations of such collections or sequences are considered equally likely, and (ii) a coherent lower prevision for the `frequency' of occurrence of the different values the random variables can take. This is the essence of representation in de Finetti's sense: we generalise his results to coherent lower previsions, both for finite collections and infinite sequences. We also solve a more practical problem: how to extend a number of lower prevision assessments to an exchangeable lower prevision that is as conservative as possible.},
  AUTHOR       = {Gert de Cooman and Erik Quaeghebeur and Enrique Miranda},
  BOOKTITLE    = {Bulletin of the International Statistical Institute 56th Session – Proceedings},
  EPRINT       = {1854/LU-377955},
  EPRINTTYPE   = {hdl},
  NUMBER       = {1556},
  ORGANIZATION = {International Statistical Institute},
  TITLE        = {Representing and assessing exchangeable lower previsions},
  VENUE        = {Lisboa, Portugal},
  YEAR         = {2007},
}

@INPROCEEDINGS{Shariatmadar+ACBQK-USD10p,
  ABSTRACT   = {We consider the problem of modelling the load on a bridge pillar when hit by a vehicle. This load depends on a number of uncertain variables, such as the mass of the vehicle and its speed on impact. The objective of our study is to analyse their effect on the load. More specifically, we are interested in finding the minimum distance of the pillar to the side of the road passing under the bridge such that a given constraint on the load is satisfied in 99\% of impact cases, i.e., such that the probability of satisfying the constraint is 0.99. In addition, we look for solutions to the following optimisation problem: find the distance that minimises a given cost function while still satisfying a given constraint on the load. This optimisation problem under uncertain constraints is not a well-posed problem, so we turn it into a decision problem under uncertainty. For both problems, we consider two typical cases. In the first, so-called precise-probability case, all uncertain variables involved are modelled using probability distributions, and in the second, so-called imprecise-probability case, the uncertainty for at least some of the variables (in casu the mass) is modelled by an interval of possible values, which is a special imprecise-probabilistic model. In the first case, we compute the joint distribution using simple Monte Carlo simulation, and in the second case, we combine Monte Carlo simulation with newly developed techniques in the field of imprecise probabilities. For the optimisation problem with uncertain constraints, this leads to two distinct approaches with different optimality criteria, namely maximality and maximinity, which we discuss and compare.},
  AUTHOR     = {Keivan Shariatmadar and Raluca Andrei and Gert de Cooman and Pieter Baekeland and Erik Quaeghebeur and Etienne E. Kerre},
  BOOKTITLE  = {Proceedings of ISMA2010: international conference on noise and vibration engineering including USD2010},
  EDITOR     = {P. Sas and B. Bergen},
  EPRINT     = {1854/LU-97337},
  EPRINTTYPE = {hdl},
  ISBN       = {9789073802872},
  KEYWORDS   = {vehicle impact; constrained optimisation; decision making; maximinity; linear-vacuous prevision; uncertainty; bridge collision; maximality; Vehicle–pillar collision; linear prevision},
  PAGES      = {5057–5065},
  PUBLISHER  = {KU Leuven. Department of Mechanical Engineering},
  TITLE      = {Optimisation under uncertainty applied to a bridge collision problem},
  VENUE      = {Leuven, Belgium},
  YEAR       = {2010},
}

@PROCEEDINGS{Przełęcki+SW-FMMES76b,
  EVENTTITLE = {Conference for Formal Methods in the Methodology of Empirical Sciences},
  EVENTDATE  = {1974-06-17/1974-06-21},
  VENUE      = {Warsaw, Poland},
  TITLE      = {Formal Methods in the Methodology of Empirical Sciences},
  EDITOR     = {Przełęcki, Marian and Szaniawski, Klemens and Wójcicki, Ryszard and Malinowski, Grzegorz},
  PUBLISHER  = {D. Reidel Publishing Company and Ossolineum Publishing company},
  SERIES     = {Synthese Library},
  VOLUME     = {103},
  YEAR       = {1976},
}

@INPROCEEDINGS{Williams-FMMES74p,
  AUTHOR    = {Peter M. Williams},
  CROSSREF  = {Przełęcki+SW-FMMES76b},
  DOI       = {10.1007/978-94-010-1135-8_16},
  FILE      = {files/Williams-FMMES74p.pdf},
  PAGES     = {229–246},
  TITLE     = {Indeterminate probabilities},
}

@INPROCEEDINGS{Druzdzel+Henrion-AAAI93p,
  AUTHOR    = {Marek J. Druzdzel and M. Henrion},
  BOOKTITLE = {Proceedings of the Eleventh National Conference on Artificial Intelligence},
  LOCATION  = {Menlo Park, California},
  PAGES     = {548–553},
  PUBLISHER = {AAAI Press},
  TITLE     = {Efficient reasoning in qualitative probabilistic networks},
  YEAR      = {1993},
}

@INPROCEEDINGS{Kwisthout+BG-SOFSEM11p,
  AUTHOR    = {Johan H. P. Kwisthout and Hans L. Bodlaender and Linda C. van der Gaag},
  BOOKTITLE = {SOFSEM 2011: Theory and Practice of Computer Science},
  DOI       = {10.1007/978-3-642-18381-2_30},
  EDITOR    = {Ivana Černá and Tibor Gyimóthy and Juraj Hromkovič and Keith Jefferey and Rastislav Králović and Marko Vukolić and Stefan Wolf},
  ISBN      = {978-3-642-18380-5},
  FILE      = {files/Kwisthout+BG-SOFSEM11p.pdf},
  PAGES     = {356–367},
  PUBLISHER = {Springer},
  SERIES    = {Lecture Notes in Computer Science},
  TITLE     = {The complexity of finding kth most probable explanations in probabilistic networks},
  VOLUME    = {6543},
  YEAR      = {2011},
}

@INPROCEEDINGS{Schrage+IG-Haskell05p,
  AUTHOR     = {Martijn M. Schrage and Arjan van IJzendoorn and Linda C. van der Gaag},
  BOOKTITLE  = {Proceedings of the 2005 ACM SIGPLAN Workshop on Haskell},
  DOI        = {10.1145/1088348.1088351},
  EVENTDATE  = {2005-09},
  EVENTTITLE = {Haskell '05},
  ISBN       = {1-59593-071-X},
  PAGES      = {17–26},
  PUBLISHER  = {ACM Press},
  TITLE      = {Haskell ready to Dazzle the real world},
  URL        = {http://www.cs.uu.nl/wiki/Dazzle},
  VENUE      = {Tallinn, Estonia},
  YEAR       = {2005},
}

@INPROCEEDINGS{Gaag+RSEL-BNAIC10p,
  AUTHOR     = {Linda C. van der Gaag and Silja Renooij and Hermi J. M. Schijf and Armin R. W. Elbers and Willie L. A. Loeffen},
  BOOKTITLE  = {Proceedings of the 22nd Benelux Conference on Artificial Intelligence},
  EVENTTITLE = {BNAIC 2010},
  FILE       = {files/Gaag+RSEL-BNAIC10p.pdf},
  TITLE      = {Probability assessments from multiple experts: qualitative information is more robust},
  VENUE      = {Luxembourg},
  YEAR       = {2010},
}

@INPROCEEDINGS{Quaeghebeur-DynComp03a,
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Proceedings of the 7th workshop on dynamics and computation: Iterated games and cooperation},
  EDITOR     = {Vincent Blondel and Patrick Deleenheer and Rudolphe Sepulchre},
  EPRINT     = {1854/LU-212736},
  EPRINTTYPE = {hdl},
  PAGES      = {28–29},
  TITLE      = {Fictitious play: two viewpoints and two versions},
  VENUE      = {Leuven, Belgium},
  YEAR       = {2003},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-BeNeLux04a,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {Book of Abstracts 23rd Benelux Meeting on Systems and Control},
  EDITOR     = {Bram de Jager and Vincent Verdult},
  EPRINT     = {1854/LU-213489},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2004-03-17/2004-03-19},
  PAGES      = {113},
  TITLE      = {Command line completion: an illustration of learning and decision making using the imprecise Dirichlet model},
  VENUE      = {Helvoirt, the Netherlands},
  YEAR       = {2004},
}

@INPROCEEDINGS{Quaeghebeur-GeoMIP11a,
  ABSTRACT   = {The criteria that characterize many interesting classes of lower previsions, such as coherent or k-monotone lower probabilities, can in finite spaces often be seen as a set of linear constraints on the set of lower previsions in the class, which therefore is a convex polyhedron. It can be equivalently characterized by its set of vertices. For all interesting classes that I studied, the set of vertices or necessary and sufficient constraints is finite. In the presentation I aim to make these representations a bit more concrete to people, so that their possible uses – both in applications and theory – can be discussed in a tangible way.},
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Geometry of Imprecise Probability and related Statistical Methods, Workshop abstracts},
  EPRINT     = {1854/LU-1974606},
  EPRINTTYPE = {hdl},
  TITLE      = {Finitary characterizations of sets of lower previsions},
  VENUE      = {Durham, UK},
  YEAR       = {2011},
}

@INPROCEEDINGS{Quaeghebeur+CH-RatDec12a,
  ABSTRACT   = {Uncertainty and preference is often modeled using linear previsions and linear orders. Some more expressive models use sets of probabilities, lower previsions, or partial orders (see, e.g., the work of Seidenfeld et al. and Walley). In the discussion of these more expressive models, or even to justify them, alternative representations in terms of sets of so-called acceptable, favorable, or desirable gambles appear (cf. the work of Williams, Seidenfeld et al., and Walley). Such ‘sets of gambles’-based models are attractive because of their geometric nature. We generalize these ‘sets of gambles’-based models by considering a pair of sets, one with accepted gambles and one with rejected gambles. We develop a framework based on a small number of axioms—No Confusion, Deductive Closure, No Limbo, and Indifference to Status Quo—and provide an interesting characterization of the resulting models. Furthermore, we define a pair of equivalent gamble relations that generalize the partial orders mentioned earlier; the corresponding characterization result is also given.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Filip Hermans},
  BOOKTITLE  = {Frontiers of Rationality and Decision, Abstracts},
  EPRINT     = {1854/LU-2977779},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2012-08-29/2012-08-31},
  KEYWORDS   = {statements; preference; accept; reject; acceptability; indifference; favorability; desirability; prevision},
  PAGETOTAL  = {2},
  TITLE      = {Modeling uncertainty using accept \& reject statements},
  VENUE      = {Groningen, the Netherlands},
  YEAR       = {2012},
}

@INPROCEEDINGS{Quaeghebeur-FUR14a,
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Foundations of Utility and Risk, Abstracts},
  EVENTDATE  = {2014-06-30/2014-08-02},
  FILE       = {files/Quaeghebeur-FUR14a.pdf},
  PAGETOTAL  = {1},
  TITLE      = {Modelling risk \& uncertainty using accept \& reject statements.},
  VENUE      = {Rotterdam, the Netherlands},
  YEAR       = {2014},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-PhDSymp03a,
  ABSTRACT   = {A method of command line completion based on probabilistic models is described. The method supplements the existing deterministic ones. The probabilistic models are developed within the context of imprecise probabilities. An imprecise Dirichlet model is used to represent the assessments about all possible completions and to allow for learning by observing the commands typed previously. Due to the use of imprecise probabilities a partial (instead of a linear) ordering of the possible completion actions will be constructed during decision making. Markov models can additionally be incorporated to take recurring sequences of commands into account.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {Proceedings of the Fourth UGent-FTW PhD Symposium},
  EPRINT     = {1854/LU-289414},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {decision making; learning; command line completion; imprecise Dirichlet model; Markov model},
  PAGETOTAL  = {2},
  PUBLISHER  = {Ghent University Faculty of Engineering},
  TITLE      = {Command line completion: an illustration of learning and decision making using the imprecise Dirichlet model},
  VENUE      = {Ghent, Belgium},
  YEAR       = {2003},
}

@INPROCEEDINGS{Quaeghebeur+CD-PhDSymp05a,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Dirk Aeyels},
  BOOKTITLE  = {Proceedings of the Sixth UGent-FirW PhD Symposium},
  EPRINT     = {1854/LU-325534},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2005-11-30},
  TITLE      = {Building classifiers that cope with small training sets},
  VENUE      = {Ghent, Belgium},
  YEAR       = {2005},
}

@INPROCEEDINGS{Quaeghebeur-IAP02a,
  ABSTRACT   = {The objective of our research is first of all the development of a method for learning the transition probabilities in (possibly hidden) Markov models using imprecise probabilities, and next the application of this method to some real-life problems. The learning model used will be the imprecise Dirichlet model, an extension of the precise Dirichlet model to the theory of imprecise probabilities. Possible applications are gene-sequence alignment and pre-fetching of web pages.},
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attraction Pole IAP V/22 Study Day, Posters},
  EPRINT     = {1854/LU-1974568},
  EPRINTTYPE = {hdl},
  TITLE      = {Learning in Markov models using the imprecise Dirichlet model},
  VENUE      = {Louvain-la-Neuve, Belgium},
  YEAR       = {2002},
}

@INPROCEEDINGS{Cooman+HQ-IAP07a,
  ABSTRACT   = {An imprecise Markov chain is defined by a closed convex set of transition matrices instead of a unique one for a classical precise Markov chain. These imprecise Markov chains allow us to model situations where we do not have enough information to specify a unique transition matrix, or to approximate the behaviour of non‐stationary Markov chains. We show that there are efficient, dynamic programming‐ like ways to work and reason with these imprecise Markov chains; e.g. to calculate the resulting distribution over the states at any time instant. We prove that this distribution converges in time, similarly to the precise case and under very mild conditions. We thus effectively prove a Perron-Frobenius theorem for a special class of non‐linear systems.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attaction Pole IAP VI/4-DYSCO, Abstracts},
  EPRINT     = {1854/LU-1974573},
  EPRINTTYPE = {hdl},
  PAGES      = {14–14},
  TITLE      = {Limit behaviour for imprecise Markov Chains},
  VENUE      = {Brussels, Belgium},
  YEAR       = {2007},
}

@INPROCEEDINGS{Cooman+HQ-DYSCO07a,
  ABSTRACT   = {Event trees are a graphical model of a set of possible situations and the possible paths going through them, from the initial situation to the terminal situations. With each situation, there is associated a local uncertainty model that represents beliefs about the next situation. The uncertainty models can be classical, precise probabilities; they can also be of a more general, imprecise probabilistic type, in which case they can be seen as sets of classical probabilities (yielding probability intervals). To work with such event trees, we must combine these local uncertainty models. We show this can be done efficiently by back-propagation through the tree, both for precise and imprecise probabilistic models, and we illustrate this using an imprecise probabilistic counterpart of the classical Markov chain. This allows us to perform a robustness analysis for Markov chains very efficiently.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attraction Pole IAP VI/4 Kickoff meeting, Posters},
  EPRINT     = {1854/LU-1974570},
  EPRINTTYPE = {hdl},
  TITLE      = {Propagating imprecise probabilities through event trees},
  VENUE      = {Louvain-la-Neuve, Belgium},
  YEAR       = {2007},
}

@INPROCEEDINGS{Cooman+HQ-DYSCO09a,
  ABSTRACT   = {We replace strong independence in credal networks with the weaker notion of epistemic irrelevance. Focusing on directed trees, we show how to combine the local credal sets in the networks into an overall joint model, and use this to construct and justify an exact message-passing algorithm that computes updated beliefs for a variable in the network. The algorithm, which is essentially linear in the number of nodes, is formulated entirely in terms of coherent lower previsions. We supply examples of the algorithm's operation, and report an application to on-line character recognition that illustrates the advantages of the model for prediction.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attraction Pole IAP VI/4 DYSCO Study Day, Posters},
  EPRINT     = {1854/LU-1974578},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2009-05-28},
  TITLE      = {Belief propagation in imprecise Markov trees},
  VENUE      = {Mons, Belgium},
  YEAR       = {2009},
}

@INPROCEEDINGS{Shariatmadar+QC-DYSCO10a,
  AUTHOR     = {Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {Interuniversity Attaction Pole IAP VI/4-DYSCO, Book of abstracts},
  EPRINT     = {1854/LU-1060040},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {expectation; constrained optimisation; maximality; vacuous; decision theory; maximinity},
  PAGES      = {14–14},
  TITLE      = {Dealing with uncertain constraints in optimisation using decision theory},
  VENUE      = {Ghent, Belgium},
  YEAR       = {2010},
}

@INPROCEEDINGS{Quaeghebeur-DYSCO10a,
  ABSTRACT   = {The standard coherence criterion for lower previsions is expressed using an infinite number of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such lower prevision is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results.},
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attaction Pole IAP VI/4-DYSCO, Book of abstracts},
  EPRINT     = {1854/LU-1974580},
  EPRINTTYPE = {hdl},
  PAGES      = {19–19},
  TITLE      = {Characterizing the set of coherent lower previsions with a finite number of constraints or vertices},
  VENUE      = {Court-St-Etienne, Belgium},
  YEAR       = {2010},
}

@PROCEEDINGS{Klee-SMP63b,
  DATE       = {1963},
  EDITOR     = {Klee, Jr., Victor L.},
  PUBLISHER  = {American Mathematical Society},
  SERIES     = {Proceedings of Symposia in Pure Mathematics},
  TITLE      = {Convexity},
  TITLEADDON = {Proceedings of the Seventh Symposium in Pure Mathematics of the American Mathematical Society},
  URL        = {http://books.google.com/books?id=MuEFJR7Ek4EC},
}

@PROCEEDINGS{-CIM28b,
  DATE      = {1928},
  LOCATION  = {Bologna},
  PUBLISHER = {N. Zanichelli},
  TITLE     = {Atti del congresso internationale dei matematici},
}

@INPROCEEDINGS{Finetti-CIM28p,
  AUTHOR    = {Bruno de Finetti},
  CROSSREF  = {-CIM28b},
  PAGES     = {179–190},
  TITLE     = {Funzione caratteristica di un fenomeno aleatorio},
  VOLUME    = {VI},
}

@PROCEEDINGS{Nagel+ST-LMPS62b,
  DATE       = {1962},
  EDITOR     = {Ernest Nagel and Patrick Suppes and Alfred Tarski},
  EVENTDATE  = {1960},
  EVENTTITLE = {International Congress on Logic, Methodology and Philosophy of Science},
  PUBLISHER  = {Stanford University Press},
  TITLE      = {Logic, Methodology and Philosophy of Science},
}

@INPROCEEDINGS{Good-LMPS62p,
  AUTHOR   = {Irving John Good},
  CROSSREF = {Nagel+ST-LMPS62b},
  PAGES    = {319–329},
  TITLE    = {Subjective Probability as the Measure of a non-Measurable Set},
}


@PROCEEDINGS{-ICLMPS75b,
  TITLE     = {Fifth International Congress of Logic, Methodology and Philosophy of Science},
  DATE      = {1975},
}

@INPROCEEDINGS{Williams-ICLMPS75p,
  AUTHOR    = {Peter M. Williams},
  CROSSREF  = {-ICLMPS75b},
  PAGES     = {29–33},
  TITLE     = {Coherence, strict coherence and zero probabilities},
  VOLUME    = {VI},
}

@INPROCEEDINGS{Bayarri+DK-SDTRT88p,
  AUTHOR     = {M. J. Bayarri and M. H. DeGroot and J. B. Kadane},
  BOOKTITLE  = {Statistical Decision Theory and Related Topics IV},
  EDITOR     = {S. S. Gupta and J. O. Berger},
  EVENTDATE  = {1986-06-15/1986-06-20},
  EVENTTITLE = {Fourth Purdue Symposium on Statistical Decision Theory and Related Topics},
  FILE       = {files/Bayarri+DK-SDTRT88p.pdf},
  PAGES      = {3–16},
  PUBLISHER  = {Springer},
  TITLE      = {What is the likelihood function?},
  VENUE      = {Purdue University},
  VOLUME     = {1},
  YEAR       = {1988},
}

@INPROCEEDINGS{Manquinho+MP-SAT09p,
  AUTHOR    = {Manquinho, Vasco and Marques-Silva, Joao and Planes, Jordi},
  BOOKTITLE = {Theory and Applications of Satisfiability Testing - SAT 2009},
  DOI       = {10.1007/978-3-642-02777-2_45},
  EDITOR    = {Kullmann, Oliver},
  FILE      = {files/Manquinho+MP-SAT09p.pdf},
  ISBN      = {978-3-642-02776-5},
  PUBLISHER = {Springer},
  PAGES     = {495–508},
  SERIES    = {Lecture Notes in Computer Science},
  TITLE     = {Algorithms for weighted Boolean optimization},
  YEAR      = {2009},
  VOLUME    = {5584},
}

@INPROCEEDINGS{Campos+Cozman-STAIRS04p,
  AUTHOR    = {de Campos, Cassio Polpo and Cozman, Fabio Gagliardi},
  BOOKTITLE = {Proceedings of the Second European Starting AI Researcher Symposium},
  FILE      = {files/Campos+Cozman-STAIRS04p.pdf},
  PAGES     = {50–61},
  TITLE     = {Inference in credal networks using multilinear programming},
  YEAR      = {2004}
}

@INPROCEEDINGS{Diaconis-BS88p,
  AUTHOR     = {Persi Diaconis},
  BOOKTITLE  = {Bayesian Statistics 3},
  EDITOR     = {José M. Bernardo and M. H. DeGroot and Dennis V. Lindley and Adrian F. M. Smith},
  EVENTTITLE = {Third Valencia International Meeting},
  EVENTDATE  = {1987-06-01/1987-06-05},
  FILE       = {files/Diaconis-BS88p.pdf},
  TITLE      = {Recent progress on de Finetti's notion of exchangeability},
  PAGES      = {111–125},
  PUBLISHER  = {Oxford University Press},
  LOCATION   = {Oxford},
  VENUE      = {Valencia, Spain},
  YEAR       = {1988},
}


@BOOK{Morgan+Henrion-GDUQRPA90b,
  AUTHOR = {Millett Granger Morgan and Max Henrion},
  PUBLISHER = {Cambridge University Press},
  TITLE = {Uncertainty},
  SUBTITLE = {A guide to dealing with uncertainty in quantitative risk and policy analysis},
  YEAR = {1990},
}

@BOOK{Cooke-EI91b,
  AUTHOR = {Roger M. Cooke},
  PUBLISHER = {Oxford University Press},
  TITLE = {Experts in Uncertainty},
  SUBTITLE = {Opinion and Subjective Probability in Science},
  YEAR = {1991},
}

@BOOK{Finetti-TDP70b,
  AUTHOR    = {Bruno de Finetti},
  NOTE      = {English translation: \parencite{Finetti-TOP75b}},
  PUBLISHER = {Giulio Einaudi},
  TITLE     = {Teoria Delle Probabilità},
  YEAR      = {1970},
}

@BOOK{Finetti-TOP75b,
  AUTHOR    = {Bruno de Finetti},
  DATE      = {1974/1975},
  NOTE      = {Two volumes; translation of \parencite{Finetti-TDP70b}},
  PUBLISHER = {John Wiley \& Sons},
  TITLE     = {Theory of Probability},
}

@BOOK{Shafer-MTE76b,
  AUTHOR    = {Glenn Shafer},
  PUBLISHER = {Princeton University Press},
  TITLE     = {A mathematical theory of evidence},
  YEAR      = {1976},
}

@BOOK{Walley-SRIP91b,
  AUTHOR    = {Peter Walley},
  FILE      = {files/Walley-SRIP91b.pdf},
  LOCATION  = {London},
  PUBLISHER = {Chapman \& Hall},
  SERIES    = {Monographs on Statistics and Applied Probability},
  TITLE     = {Statistical reasoning with imprecise probabilities},
  VOLUME    = {42},
  YEAR      = {1991},
}

@BOOK{Grünwald-MDLP07b,
  AUTHOR    = {Peter Grünwald},
  FILE      = {files/Grünwald-MDLP07b.pdf},
  LOCATION  = {Cambridge, Massachusetts and London, England},
  PUBLISHER = {MIT Press},
  SERIES    = {Adaptive computation and machine learning},
  TITLE     = {The minimum description length principle},
  YEAR      = {2007},
}

@BOOK{Hagan+BDEGJOR-UJ06b,
  AUTHOR    = {Anthony O'Hagan and Caitlin E. Buck and Alireza Daneshkhah and J. Richard Eiser and Paul H. Garthwaite and David J. Jenkinson and Jeremy E. Oakley and Tim Rakow},
  DATE      = {2006-07},
  ISBN      = {978-0-470-02999-2},
  PUBLISHER = {Wiley},
  SERIES    = {Statistics in Practice},
  TITLE     = {Uncertain Judgements: Eliciting Experts' Probabilities},
  URL       = {http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0470029994.html},
}

@COLLECTION{Harmelen+LP-HKR08b,
  EDITOR    = {F. van Harmelen and V. Lifschitz and B. Porter},
  PUBLISHER = {Elsevier},
  TITLE     = {Handbook of Knowledge Representation},
  YEAR      = {2008},
}

@INCOLLECTION{Gomes+KSS-HKR08c,
  AUTHOR   = {Carla P. Gomes and Henry Kautz and Ashish Sabharwal and Bart Selman},
  CHAPTER  = {2},
  CROSSREF = {Harmelen+LP-HKR08b},
  FILE     = {files/Gomes+KSS-HKR08c.pdf},
  PAGES    = {89–134},
  TITLE    = {Satisfiability solvers},
}

@INCOLLECTION{Seidenfeld-SK-ARITP90c,
  AUTHOR    = {Teddy Seidenfeld and Mark J. Schervish and Joseph B. Kadane},
  BOOKTITLE = {Acting and Reflecting: The Interdisciplinary Turn in Philosophy},
  EDITOR    = {Wilfried Sieg},
  FILE      = {files/Seidenfeld-SK-ARITP90c.pdf},
  LOCATION  = {Dordrecht},
  PAGES     = {143–170},
  PUBLISHER = {Kluwer Academic Publishers},
  SERIES    = {Synthese Library},
  TITLE     = {Decisions without ordering},
  VOLUME    = {211},
  YEAR      = {1990},
}

@BOOK{Pourret+NM-BNPGA08b,
  EDITOR    = {Olivier Pourret and Patrick Naïm and Bruce Marcot},
  ISBN      = {978-0-470-06030-8},
  PUBLISHER = {Wiley},
  TITLE     = {Bayesian networks: a practical guide to applications},
  YEAR      = {2008},
}

@COLLECTION{Biere+HMW-HS09b,
  EDITOR    = {Armin Biere and Marijn Heule and Hans van Maaren and Toby Walsh},
  ISBN      = {978-1-58603-929-5},
  PUBLISHER = {IOS Press},
  SERIES    = {Frontiers in Artificial Intelligence and Applications},
  TITLE     = {Handbook of Satisfiability},
  VOLUME    = {185},
  YEAR      = {2009},
}

@INCOLLECTION{Prestwich-HS09c,
  AUTHOR   = {Steven Prestwich},
  CROSSREF = {Biere+HMW-HS09b},
  PAGES    = {75–98},
  TITLE    = {CNF Encodings},
  CHAPTER  = {2},
}

@BOOK{Koller+Friedman-PGM09b,
  AUTHOR    = {Daphne Koller and Nir Friedman},
  ISBN      = {978-0-262-01319-2},
  PUBLISHER = {MIT Press},
  SERIES    = {Adaptive Computation and Machine Learning},
  TITLE     = {Probabilistic graphical models},
  YEAR      = {2009},
}

@INCOLLECTION{Gaag+RC-APGM07c,
  AUTHOR    = {Linda C. van der Gaag and Silja Renooij and Veerle M. H. Coupé},
  BOOKTITLE = {Advances in Probabilistic Graphical Models},
  DOI       = {10.1007/978-3-540-68996-6_5},
  EDITOR    = {Lucas, Peter and Gámez, José A. and Salmerón, Antonio},
  FILE      = {files/Gaag+RC-APGM07c.pdf},
  PAGES     = {103–124},
  PUBLISHER = {Springer},
  SERIES    = {Studies in Fuzziness and Soft Computing},
  TITLE     = {Sensitivity analysis of probabilistic networks},
  VOLUME    = {214},
  YEAR      = {2007},
}

@INCOLLECTION{Bansal+Raman-AC99c,
  AUTHOR    = {Bansal, Nikhil and Raman, Venkatesh},
  BOOKTITLE = {Algorithms and Computation},
  DOI       = {10.1007/3-540-46632-0_26},
  ISBN      = {978-3-540-66916-6},
  PUBLISHER = {Springer},
  PAGES     = {247–258},
  SERIES    = {Lecture Notes in Computer Science},
  TITLE     = {Upper Bounds for MaxSat: Further Improved},
  VOLUME    = {1741},
  YEAR      = {1999},
}

@INCOLLECTION{Weibull-ORET84c,
  ABSTRACT  = {In operations research and microeconomic modelling it is usual to assume that a decision-maker’s preferences ≼ over prospects x∈X over time, space, or uncertain states-of-nature may be represented by an integral ∫x(ω)dμ(ω) over the underlying set of times, locations, or states-of-nature. In a temporal setting such an integral may be interpreted as the present value of prospect x with respect to a temporal discount function. In a spatial setting, it may be interpreted as accessibility to location pattern x with respect to a spatial discount function. In a choice among uncertain prospects, finally, the integral may be interpreted as the expected value of prospect x with respect to a probability measure.},
  AUTHOR    = {Weibull, Jörgen W.},
  YEAR      = {1984},
  ISBN      = {978-3-642-69911-5},
  FILE      = {files/Weibull-ORET84c.pdf},
  BOOKTITLE = {Operations Research and Economic Theory},
  EDITOR    = {Hauptmann, H. and Krelle, W. and Mosler, K.C.},
  DOI       = {10.1007/978-3-642-69909-2_22},
  TITLE     = {Continuous linear representations of preference orderings in vector spaces},
  PUBLISHER = {Springer},
  PAGES     = {291–305},
}

@REPORT{Williams-UoS75r,
  AUTHOR      = {Peter M. Williams},
  DATE        = {1975-02},
  INSTITUTION = {School of Mathematical and Physical Sciences, University of Sussex},
  FILE        = {files/Williams-UoS75r.pdf},
  NOTE        = {Published as \parencite{Williams-IJAR07j}},
  TITLE       = {Notes on conditional previsions},
  TYPE        = {techreport},
}

@REPORT{Williams-UoS90r,
  AUTHOR      = {Peter M. Williams},
  DATE        = {1990-02-05},
  INSTITUTION = {School of Cognitive and Computing Sciences, University of Sussex},
  FILE        = {files/Williams-UoS90r.pdf},
  TITLE       = {Averaging and Eliciting Expert Opinion},
  TYPE        = {techreport},
}

@REPORT{Walley+Bernard-CAF99r,
  ANNOTATION  = {geannoteerde kopie},
  AUTHOR      = {Peter Walley and Jean-Marc Bernard},
  INSTITUTION = {Université de Paris 8},
  NUMBER      = {CAF-9901},
  TITLE       = {Imprecise probabilistic prediction for categorical data},
  TYPE        = {techreport},
  YEAR        = {1999},
}

@REPORT{Quaeghebeur-WLMMEUI04r,
  AUTHOR     = {Erik Quaeghebeur},
  EPRINT     = {1854/LU-1976594},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Markov model; imprecise Dirichlet model; weak law},
  SERIES     = {Working paper},
  TITLE      = {Weak law for Markov model estimation using the IDM},
  TYPE       = {techreport},
  YEAR       = {2004},
}

@UNPUBLISHED{Quaeghebeur-DPM09n,
  AUTHOR = {Erik Quaeghebeur},
  DATE   = {2009-03-25},
  NOTE   = {Note},
  TITLE  = {The determinant of a parameterized matrix},
}

@REPORT{Jenkinson-BEEP05r,
  AUTHOR      = {David Jenkinson},
  DATE        = {2005-04-22},
  FILE        = {files/Jenkinson-BEEP05r.pdf},
  INSTITUTION = {University of Sheffield},
  SERIES      = {BEEP working paper},
  TITLE       = {The elicitation of probabilities - A review of the statistical literature},
  TYPE        = {techreport},
}

@ONLINE{Fukuda-polyfaq,
  AUTHOR = {Komei Fukuda},
  DATE   = {2004-06-18},
  TITLE  = {Frequently asked questions in polyhedral computation},
  URL    = {http://www.ifor.math.ethz.ch/~fukuda/polyfaq},
}

@ONLINE{Wikipedia-656148466,
  DATE         = {2015-04-12},
  ORGANIZATION = {Wikipedia},
  SHORTHAND    = {Goode homolosine projection},
  TITLE        = {Goode homolosine projection},
  URL          = {http://en.wikipedia.org/w/index.php?oldid=656148466},
}

@UNPUBLISHED{Seidenfeld-Note13u,
  AUTHOR = {Teddy Seidenfeld},
  DATE   = {2013-01-08},
  FILE   = {files/Seidenfeld-Note13u.pdf},
  TITLE  = {Note on the value of “independent” evidence},
}

@MISC{Django,
  PUBLISHER = {Django Software Foundation},
  SHORTHAND = {Django},
  TITLE     = {Django},
  TYPE      = {software},
  URL       = {https://djangoproject.com},
}

@MISC{ECMAscript,
  PUBLISHER = {Ecma International},
  SHORTHAND = {ECMAscript},
  TITLE     = {ECMAscript},
  TYPE      = {Programming language},
  URL       = {http://www.ecma-international.org/ecma-262/5.1/},
}

@MISC{SVG,
  PUBLISHER  = {W3C},
  SHORTHAND  = {SVG},
  SHORTTITLE = {SVG},
  TITLE      = {Scalable Vector Graphics},
  TYPE       = {Programming language},
  URL        = {http://www.w3.org/TR/SVG/},
}

@MISC{NumericJS,
  AUTHOR     = {Sébastien Loisel},
  SHORTHAND  = {NumericJS},
  SHORTTITLE = {NumericJS},
  TITLE      = {Numeric Javascript},
  TYPE       = {software},
  URL        = {http://numericjs.com/},
  YEAR       = {2012},
}

@MISC{GLPK,
  AUTHOR    = {Andrew Makhorin},
  PUBLISHER = {Free Software Foundation},
  SHORTHAND = {GLPK},
  TITLE     = {GNU Linear Programming Kit},
  TYPE      = {software},
  URL       = {https://www.gnu.org/software/glpk/},
  YEAR      = {2014},
}

@MANUAL{Bisschop-AIMMS12m,
  AUTHOR     = {Johannes Bisschop},
  DATE       = {2012-03-08},
  FILE       = {files/Bisschop-AIMMS12m.pdf},
  TITLE      = {Aimms},
  TITLEADDON = {Optimization modeling},
}
