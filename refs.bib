@THESIS{Quaeghebeur-MA01b,
  ABSTRACT    = {We bestuderen een leermethode voor eindige spelen in de strategische vorm. Hierbij maken de spelers gebruik van een geschiedenis van reeds gespeelde sessies om inschattingen te maken over de waarschijnlijke strategiekeuze van een tegenspeler. Op die waarschijnlijk geachte strategiekeuze baseren de spelers zich om een eigen strategie te kiezen. We bestuderen hiervoor eerst de wetenschapsdiscipline genaamd speltheorie. We gaan hier in op kenmerkende elementen van spelen en bekijken mogelijke voorstellingswijzen. We gaan dieper in op de voorstelling van een spel in de strategische vorm. Een strategie, een geheel aan regels die de keuze van acties binnen een spel volledig bepalen, en de opbrengstfunctie, die de uitslag van een spel voor de speler vastlegt, worden gedefinieerd. We bekijken hoe we de strategieën van een spel kunnen onderverdelen en welke strategieën optimaal zijn voor een speler. Zo komen we tot volgende concepten: beste antwoord, wat de verzameling van strategieën is die de opbrengst van de speler maximaliseert voor een gegeven strategie van zijn tegenspeler; evenwicht, wat een strategiecombinatie is waar geen enkele speler er voordeel bij heeft om van strategie te veranderen; dominantie, wat een methode is om strategieën te identificeren die het best niet gespeeld worden en maximin-strategie, wat een voorzichtige strategiekeuze is. In tweede instantie bespreken we imprecieze waarschijnlijkheden, wat een onzekerheidsmodel is waar niet alleen rekening kan worden gehouden met onzekerheid, maar ook met onbepaaldheid. We gaan in op de gevolgen van rationaliteitvereisten voor dit model en zijn rekenregels. Er wordt tevens een interpretatie op basis van gokgedrag gegeven aan de grootheden die we gebruiken om waarschijnlijkheden uit te drukken. Voortbouwend op het voorgaande wordt onderzocht hoe we een beslissing kunnen maken tussen keuzes voor verschillende mogelijke strategieën. Dit leidt tot de definitie van maximale strategieën, die goede keuzes zijn voor een speler. Deze beslissingen worden gebaseerd op het Dirichletmodel, dat inschattingen weergeeft over de strategiekeuze van een tegenspeler. We leggen ook uit hoe dit model bijgesteld kan worden door verrekening van de informatie bekomen uit reeds gespeelde sessies. Door het voorgaande te combineren kunnen we de beoogde leermethode formuleren. We maken hier een onderscheid tussen een precieze methode, waarbij er geen rekening wordt gehouden met eventuele onbepaaldheid en twee imprecieze methodes, waarbij dit wel gebeurt. Uiteindelijk bekijken we de dynamica van de leermethode, namelijk de evolutie van de inschattingen van spelers en de door hen gespeelde strategieën. We onderzoeken voornamelijk onder welke voorwaarden er enkel convergentie naar een evenwicht zal optreden.},
  ADDENDUM    = {Supervisor: Gert de Cooman},
  AUTHOR      = {Erik Quaeghebeur},
  EDITOR      = {Gert de Cooman},
  EPRINT      = {1854/LU-469938},
  EPRINTTYPE  = {hdl},
  FILE        = {files/Quaeghebeur-MA01.pdf},
  INSTITUTION = {Ghent University},
  KEYWORDS    = {evenwicht; fictief spelen; imprecieze waarschijnlijkheden; leren; speltheorie},
  TITLE       = {Speltheoretisch leren met imprecieze waarschijnlijkheden: dynamische aspecten},
  TITLEADDON  = {(Game-theo\-retic learning using imprecise probabilities: dynamical aspects)},
  TYPE        = {mathesis},
  YEAR        = {2001},
}

@THESIS{Quaeghebeur-MA02b,
  ABSTRACT    = {This text treats of the problem of predicting the flow of a river using past flow measurements, rainfall measurements and rainfall predictions. The objective is to generalize a forecasting method already used to predict daily consumption of electricity. The developed method will be compared to Hydromax, an existing riverflow forecasting model. The developed method simultaneously generates a series of consecutive flow predictions called a flow curve. This is done by combining separate forecasts for the mean, standard deviation and the normalized profile of the flow curve. Therefore, three separate forecasting models will be used, one for each of the aforementioned flow curve components. To understand the difficulties involved in riverflow forecasting we first take a look at the relevant hydrological concepts and the data used in constructing and testing the forecasting method. We will principally be interested in the prediction of floods, as these phenomena can have dire socioeconomic consequences if they take place without a timely warning. Some of the forecasting models will be based on mathematical techniques derived from the field of artificial neural networks. As an introduction we will shortly elaborate on this field before presenting a more profound study of the two derived techniques we will use. These are the so-called `self-organizing maps' and `radial basis function networks'. An essential part of the forecasting method are linear and nonlinear regression models. We shall take a look at these parameterized prediction models, the associated prediction errors and the parameter estimation involved in constructing them. Thus being well prepared, we will have at this stage a close look at the Hydromax model and explain the forecasting method we have developed. They will be compared in terms of the data needed and the hydrological knowledge involved. Finally, we will show how the developed method is used in practice. The obtained results will be compared with those obtained by Hydromax, and remarks will be made about possible improvements. We will conclude with showing that the developed method holds promise, but is not yet suitable for practical applications. Suggestions for further research are also included.},
  ADDENDUM    = {Supervisor: Vincent Wertz},
  AUTHOR      = {Erik Quaeghebeur},
  FILE        = {files/Quaeghebeur-MA02b.pdf},
  INSTITUTION = {Catholic University of Louvain},
  TITLE       = {Analyse et prédiction de débit de rivières par des méthodes non linéaires},
  TITLEADDON  = {(Analysis and prediction of river flow using non-linear methods)},
  TYPE        = {mathesis},
  YEAR        = {2002},
}

@THESIS{Quaeghebeur-PhD09b,
  ABSTRACT    = {This thesis's main subject is deriving, proposing, and studying predictive and parametric inference models that are based on the theory of coherent lower previsions. One important side subject also appears: obtaining and discussing extreme lower probabilities. In the chapter ‘Modeling uncertainty’, I give an introductory overview of the theory of coherent lower previsions ─ also called the theory of imprecise probabilities ─ and its underlying ideas. This theory allows us to give a more expressive ─ and a more cautious ─ description of uncertainty. This overview is original in the sense that ─ more than other introductions ─ it is based on the intuitive theory of coherent sets of desirable gambles. I show in the chapter ‘Extreme lower probabilities’ how to obtain the most extreme forms of uncertainty that can be modeled using lower probabilities. Every other state of uncertainty describable by lower probabilities can be formulated in terms of these extreme ones. The importance of the results in this area obtained and extensively discussed by me is currently mostly theoretical. The chapter ‘Inference models’ treats learning from samples from a finite, categorical space. My most basic assumption about the sampling process is that it is exchangeable, for which I give a novel definition in terms of desirable gambles. My investigation of the consequences of this assumption leads us to some important representation theorems: uncertainty about (in)finite sample sequences can be modeled entirely in terms of category counts (frequencies). I build on this to give an elucidating derivation from first principles for two popular inference models for categorical data ─ the predictive imprecise Dirichlet-multinomial model and the parametric imprecise Dirichlet model; I apply these models to game theory and learning Markov chains. In the last chapter, ‘Inference models for exponential families’, I enlarge the scope to exponential family sampling models; examples are normal sampling and Poisson sampling. I first thoroughly investigate exponential families and the related conjugate parametric and predictive previsions used in classical Bayesian inference models based on conjugate updating. These previsions serve as a basis for the new imprecise-probabilistic inference models I propose. Compared to the classical Bayesian approach, mine allows to be much more cautious when trying to express what we know about the sampling model; this caution is reflected in behavior (conclusions drawn, predictions made, decisions made) based on these models. Lastly, I show how the proposed inference models can be used for classification with the naive credal classifier.},
  AUTHOR      = {Erik Quaeghebeur},
  ADDENDUM    = {Supervisor: Gert de Cooman},
  EPRINT      = {1854/LU-495650},
  EPRINTTYPE  = {hdl},
  INSTITUTION = {Ghent University},
  ISBN        = {9789085782490},
  KEYWORDS    = {exponential family; imprecise Dirichlet model; inference; desirable gambles; extreme points; coherence; exchangeability; imprecise probability; sample; updating; lower prevision; representation insensitivity; learning},
  FILE        = {files/Quaeghebeur-PhD09b.pdf},
  PUBLISHER   = {Ghent University Faculty of Engineering},
  TITLE       = {Learning from samples using coherent lower previsions},
  TYPE        = {phdthesis},
  YEAR        = {2009},
}

@THESIS{Quaeghebeur-PhD10b,
  AUTHOR      = {Liesbet Quaeghebeur},
  INSTITUTION = {Universiteit Antwerpen},
  FILE        = {files/Quaeghebeur-PhD10b.pdf},
  TITLE       = {A Philosophy of Everyday, Face-to-face Conversation},
  TYPE        = {phdthesis},
  YEAR        = {2010},
}

@XDATA{JRSSB,
  JOURNALTITLE = {Journal of the Royal Statistical Society. Series B (Methodological)},
  PUBLISHER    = {Wiley for the Royal Statistical Society},
  SHORTJOURNAL = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
}

@ARTICLE{Lauritzen+Spiegelhalter-JRSSB88j,
  ABSTRACT   = {A causal network is used in a number of areas as a depiction of patterns of `influence' among sets of variables. In expert systems it is common to perform `inference' by means of local computations on such large but sparse networks. In general, non-probabilistic methods are used to handle uncertainty when propagating the effects of evidence, and it has appeared that exact probabilistic methods are not computationally feasible. Motivated by an application in electromyography, we counter this claim by exploiting a range of local representations for the joint probability distribution, combined with topological changes to the original network termed `marrying' and `filling-in'. The resulting structure allows efficient algorithms for transfer between representations, providing rapid absorption and propagation of evidence. The scheme is first illustrated on a small, fictitious but challenging example, and the underlying theory and computational aspects are then discussed.},
  AUTHOR     = {Lauritzen, S. L. and Spiegelhalter, D. J.},
  EPRINT     = {2345762},
  EPRINTTYPE = {jstor},
  FILE       = {files/Lauritzen+Spiegelhalter-JRSSB88j.pdf},
  NUMBER     = {2},
  PAGES      = {157--224},
  TITLE      = {Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems},
  VOLUME     = {50},
  XDATA      = {JRSSB},
  YEAR       = {1988},
}

@XDATA{IJAR,
  JOURNALTITLE = {International Journal of Approximate Reasoning},
  ISSN         = {0888-613X},
  PUBLISHER    = {Elsevier},
  SHORTJOURNAL = {Int. J. Approx. Reason.},
}

@ARTICLE{Cozman-IJAR05j,
  ABSTRACT = {This paper presents an overview of graphical models that can handle imprecision in probability values. The paper first reviews basic concepts and presents a brief historical account of the field. The main characteristics of the credal network model are then discussed, as this model has received considerable attention in the literature.},
  AUTHOR   = {Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2004.10.003},
  KEYWORDS = {Credal network; Graphical models; Sets of probability distributions; imprecise probability},
  FILE     = {files/Cozman-IJAR05j.pdf},
  NUMBER   = {2-3},
  PAGES    = {167–184},
  TITLE    = {Graphical models for imprecise probabilities},
  VOLUME   = {39},
  YEAR     = {2005},
  XDATA    = {IJAR},
}

@ARTICLE{Campos+Cozman-IJAR07j,
  ABSTRACT = {This paper investigates the computation of lower/upper expectations that must cohere with a collection of probabilistic assessments and a collection of judgements of epistemic independence. New algorithms, based on multilinear programming, are presented, both for independence among events and among random variables. Separation properties of graphical models are also investigated.},
  AUTHOR   = {Cassio Polpo de Campos and Fabio Gagliardi Cozman},
  DOI      = {10.1016/j.ijar.2006.07.013},
  KEYWORDS = {concepts of independence; epistemic independence; imprecise probabilities; multilinear programming; sets of probability measures},
  FILE     = {files/Campos+Cozman-IJAR07j.pdf},
  NUMBER   = {3},
  PAGES    = {244–260},
  TITLE    = {Computing lower and upper expectations under epistemic independence},
  VOLUME   = {44},
  XDATA    = {IJAR},
  YEAR     = {2007},
}

@ARTICLE{Miranda-IJAR08j,
  ABSTRACT = {This paper presents a summary of Peter Walley's theory of coherent lower previsions. We introduce three representations of coherent assessments: coherent lower and upper previsions, closed and convex sets of linear previsions, and sets of desirable gambles. We show also how the notion of coherence can be used to update our beliefs with new information, and a number of possibilities to model the notion of independence with coherent lower previsions. Next, we comment on the connection with other approaches in the literature: de Finetti's and Williams' earlier work, Kuznetsov's and Weischelberger's work on interval-valued probabilities, Dempster-Shafer theory of evidence and Shafer and Vovk's game-theoretic approach. Finally, we present a brief survey of some applications and summarize the main strengths and challenges of the theory.},
  AUTHOR   = {Enrique Miranda},
  DOI      = {10.1016/j.ijar.2007.12.001},
  KEYWORDS = {Avoiding sure loss; Coherence; Conditional lower previsions; Desirability; Imprecision; Independence; Subjective probability},
  FILE     = {files/Miranda-IJAR08j.pdf},
  NUMBER   = {2},
  PAGES    = {628–658},
  TITLE    = {A survey of the theory of coherent lower previsions},
  VOLUME   = {48},
  XDATA    = {IJAR},
  YEAR     = {2008},
}

@ARTICLE{Cooman+MQ-IJAR08j,
  ABSTRACT   = {We consider immediate predictive inference, where a subject, using a number of observations of a finite number of exchangeable random variables, is asked to coherently model his beliefs about the next observation, in terms of a predictive lower prevision. We study when such predictive lower previsions are representation insensitive, meaning that they are essentially independent of the choice of the (finite) set of possible values for the random variables. We establish that such representation insensitive predictive models have very interesting properties, and show that among such models, the ones produced by the Imprecise Dirichlet-Multinomial Model are quite special in a number of ways. In the Conclusion, we discuss the open question as to how unique the predictive lower previsions of the Imprecise Dirichlet-Multinomial Model are in being representation insensitive.},
  AUTHOR     = {Gert de Cooman and Enrique Miranda and Erik Quaeghebeur},
  DOI        = {10.1016/j.ijar.2008.03.010},
  EPRINT     = {1854/LU-497890},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Coherence; Exchangeability; Immediate prediction; Imprecise Dirichlet-Multinomial Model; Imprecise probabilities; Johnson’s sufficientness postulate; Lower prevision; Predictive inference; Representation insensitivity; Representation invariance principle; Rule of Succession},
  FILE       = {files/Cooman+MQ-IJAR08j.pdf},
  NUMBER     = {2},
  PAGES      = {204–216},
  TITLE      = {Representation insensitivity in immediate prediction under exchangeability},
  VOLUME     = {50},
  XDATA      = {IJAR},
  YEAR       = {2009},
}

@ARTICLE{Miranda+CQ-IJAR08j,
  ABSTRACT   = {We study the information that a distribution function provides about the finitely additive probability measure inducing it. We show that in general there is an infinite number of finitely additive probabilities associated with the same distribution function. Secondly, we investigate the relationship between a distribution function and its given sequence of moments. We provide formulae for the sets of distribution functions, and finitely additive probabilities, associated with some moment sequence, and determine under which conditions the moments determine the distribution function uniquely. We show that all these problems can be addressed efficiently using the theory of coherent lower previsions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  DATE       = {2008-04},
  DOI        = {10.1016/j.ijar.2007.07.007},
  EPRINT     = {1854/LU-397873},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {lower distribution function; coherent lower prevision; lower Riemann–Stieltjes integral; complete monotonicity; moment sequence},
  FILE       = {files/Miranda+CQ-IJAR08j.pdf},
  NUMBER     = {1},
  PAGES      = {132–155},
  TITLE      = {Finitely additive extensions of distribution functions and moment sequences: The coherent lower prevision approach},
  VOLUME     = {48},
  XDATA      = {IJAR},
}

@ARTICLE{Quaeghebeur+Cooman-IJAR09j,
  ABSTRACT   = {We propose a new learning model for finite strategic-form two-player games based on fictitious play and Walley's imprecise Dirichlet model [P. Walley, Inferences from multinomial data: learning about a bag of marbles, J. Roy. Statist. Soc. B 58 (1996) 3–57]. This model allows the initial beliefs of the players about their opponent’s strategy choice to be near-vacuous or imprecise instead of being precisely defined. A similar generalization can be made as the one proposed by Fudenberg and Kreps [D. Fudenberg, D.M. Kreps, Learning mixed equilibria, Games Econ. Behav. 5 (1993) 320–367] for fictitious play, where assumptions about immediate behavior are replaced with assumptions about asymptotic behavior. We also obtain similar convergence results for this generalization: if there is convergence, it will be to an equilibrium.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  DOI        = {10.1016/j.ijar.2008.03.012},
  EPRINT     = {1854/LU-495971},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Fictitious play; Imprecise probability models; Imprecise Dirichlet model; Decision making; Two-player games; Learning},
  NUMBER     = {2},
  PAGES      = {243–256},
  TITLE      = {Learning in games using the imprecise Dirichlet-model},
  VOLUME     = {50},
  XDATA      = {IJAR},
  YEAR       = {2009},
}

@ARTICLE{Antonucci+BPZ-IJAR09j,
  ABSTRACT = {Credal networks are imprecise probabilistic graphical models generalizing Bayesian networks to convex sets of probability mass functions. This makes credal networks particularly suited to model expert knowledge under very general conditions, including states of qualitative and incomplete knowledge. In this paper, we present a credal network for risk evaluation in case of intrusion of civil aircrafts into a restricted flight area. The different factors relevant for this evaluation, together with an independence structure over them, are initially identified. These factors are observed by sensors, whose reliabilities can be affected by variable external factors, and even by the behaviour of the intruder. A model of these observation processes, and the necessary fusion scheme for the information returned by the sensors measuring the same factor, are both completely embedded into the structure of the credal network. A pool of experts, facilitated in their task by specific techniques to convert qualitative judgements into imprecise probabilistic assessments, has made possible the quantification of the network. We show the capabilities of the proposed model by means of some preliminary tests referred to simulated scenarios. Overall, we can regard this application as a useful tool to support military experts in their decision, but also as a quite general imprecise-probability paradigm for information fusion.},
  AUTHOR   = {Alessandro Antonucci and Ralph Brühlmann and Alberto Piatti and Marco Zaffalon},
  DATE     = {2009-04},
  DOI      = {10.1016/j.ijar.2009.01.005},
  KEYWORDS = {Credal networks; Information fusion; Sensor management; Tracking systems},
  FILE     = {files/Antonucci+BPZ-IJAR09j.pdf},
  NUMBER   = {4},
  PAGES    = {666–679},
  TITLE    = {Credal networks for military identification problems},
  VOLUME   = {50},
  XDATA    = {IJAR},
}

@ARTICLE{Cooman+HAZ-IJAR10j,
  ABSTRACT = {We focus on credal nets, which are graphical models that generalise Bayesian nets to imprecise probability. We replace the notion of strong independence commonly used in credal nets with the weaker notion of epistemic irrelevance, which is arguably more suited for a behavioural theory of probability. Focusing on directed trees, we show how to combine the given local uncertainty models in the nodes of the graph into a global model, and we use this to construct and justify an exact message-passing algorithm that computes updated beliefs for a variable in the tree. The algorithm, which is linear in the number of nodes, is formulated entirely in terms of coherent lower previsions, and is shown to satisfy a number of rationality requirements. We supply examples of the algorithm's operation, and report an application to on-line character recognition that illustrates the advantages of our approach for prediction. We comment on the perspectives, opened by the availability, for the first time, of a truly efficient algorithm based on epistemic irrelevance.},
  AUTHOR   = {Gert de Cooman and Filip Hermans and Alessandro Antonucci and Marco Zaffalon},
  DATE     = {2010-11},
  DOI      = {10.1016/j.ijar.2010.08.011},
  KEYWORDS = {Coherence; Credal net; Epistemic irrelevance; Hidden Markov model; Separation; Strong independence},
  FILE     = {files/Cooman+HAZ-IJAR10j.pdf},
  NUMBER   = {9},
  PAGES    = {1029–1052},
  TITLE    = {Epistemic irrelevance in credal nets: the case of imprecise Markov trees},
  VOLUME   = {51},
  XDATA    = {IJAR},
}

@ARTICLE{Renooij-IJAR12j,
  ABSTRACT   = {Sensitivity analysis in hidden Markov models (HMMs) is usually performed by means of a perturbation analysis where a small change is applied to the model parameters, upon which the output of interest is re-computed. Recently it was shown that a simple mathematical function describes the relation between HMM parameters and an output probability of interest; this result was established by representing the HMM as a (dynamic) Bayesian network. To determine this sensitivity function, it was suggested to employ existing Bayesian network algorithms. Up till now, however, no special purpose algorithms for establishing sensitivity functions for HMMs existed. In this paper we discuss the drawbacks of computing HMM sensitivity functions, building only upon existing algorithms. We then present a new and efficient algorithm, which is specially tailored for determining sensitivity functions in HMMs.},
  AUTHOR     = {Silja Renooij},
  DATE       = {2012-12},
  DOI        = {10.1016/j.ijar.2012.06.003},
  ISSUETITLE = {Fifth European Workshop on Probabilistic Graphical Models (PGM-2010)},
  KEYWORDS   = {Sensitivity analysis; Bayesian networks; Hidden Markov models; Sensitivity function},
  NUMBER     = {9},
  PAGES      = {1397–1414},
  TITLE      = {Efficient sensitivity analysis in hidden markov models},
  VOLUME     = {53},
  XDATA      = {IJAR},
}

@ARTICLE{Cooman+Quaeghebeur-IJAR12j,
  ABSTRACT   = {Sets of desirable gambles constitute a quite general type of uncertainty model with an interesting geometrical interpretation. We give a general discussion of such models and their rationality criteria. We study exchangeability assessments for them, and prove counterparts of de Finetti's finite and infinite representation theorems. We show that the finite representation in terms of count vectors has a very nice geometrical interpretation, and that the representation in terms of frequency vectors is tied up with multivariate Bernstein (basis) polynomials. We also lay bare the relationships between the representations of updated exchangeable models, and discuss conservative inference (natural extension) under exchangeability and the extension of exchangeable sequences.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur},
  DOI        = {10.1016/j.ijar.2010.12.002},
  EPRINT     = {1854/LU-1106209},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Extending an exchangeable sequence; prevision; Updating; Natural extension; Representation; Exchangeability; Sets of desirable gambles},
  FILE       = {files/Cooman+Quaeghebeur-IJAR12j.pdf},
  NUMBER     = {3},
  PAGES      = {363–395},
  TITLE      = {Exchangeability and sets of desirable gambles},
  VOLUME     = {53},
  YEAR       = {2012},
  XDATA      = {IJAR},
}

@ARTICLE{Quaeghebeur+CH-submitted,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Filip Hermans},
  EPRINT     = {1208.4462},
  EPRINTTYPE = {arxiv},
  SORTYEAR   = {2013},
  TITLE      = {Accept \& Reject Statement-Based Uncertainty Models},
  YEAR       = {submitted},
}

@XDATA{AIJ,
  ISSN         = {0004-3702},
  JOURNALTITLE = {Artificial Intelligence},
  PUBLISHER    = {Elsevier},
}

@ARTICLE{Cozman-AIJ00j,
  ABSTRACT = {This paper presents a complete theory of credal networks, structures that associate convex sets of probability measures with directed acyclic graphs. Credal networks are graphical models for precise/imprecise beliefs. The main contribution of this work is a theory of credal networks that displays as much flexibility and representational power as the theory of standard Bayesian networks. Results in this paper show how to express judgements of irrelevance and independence, and how to compute inferences in credal networks. A credal network admits several extensions–several sets of probability measures comply with the constraints represented by a network. Two types of extensions are investigated. The properties of strong extensions are clarified through a new generalization of d-separation, and exact and approximate inference methods are described for strong extensions. Novel results are presented for natural extensions, and linear fractional programming methods are described for natural extensions. The paper also investigates credal networks that are defined globally through perturbations of a single network.},
  AUTHOR   = {Fabio Gagliardi Cozman},
  DOI      = {10.1016/S0004-3702(00)00029-1},
  KEYWORDS = {Bayesian networks; Convex sets of probability measures; Graphical d-separation relations; Graphical models of inference; Independence relations; Lower and upper expectations; Robust Bayesian analysis},
  FILE     = {files/Cozman-AIJ00j.pdf},
  NUMBER   = {2},
  PAGES    = {199–233},
  TITLE    = {Credal networks},
  VOLUME   = {120},
  XDATA    = {AIJ},
  YEAR     = {2000},
}

@ARTICLE{Cooman+MZ-AIJ11j,
  ABSTRACT = {There is no unique extension of the standard notion of probabilistic independence to the case where probabilities are indeterminate or imprecisely specified. Epistemic independence is an extension that formalises the intuitive idea of mutual irrelevance between different sources of information. This gives epistemic independence very wide scope as well as appeal: this interpretation of independence is often taken as natural also in precise-probabilistic contexts. Nevertheless, epistemic independence has received little attention so far. This paper develops the foundations of this notion for variables assuming values in finite spaces. We define (epistemically) independent products of marginals (or possibly conditionals) and show that there always is a unique least-committal such independent product, which we call the independent natural extension. We supply an explicit formula for it, and study some of its properties, such as associativity, marginalisation and external additivity, which are basic tools to work with the independent natural extension. Additionally, we consider a number of ways in which the standard factorisation formula for independence can be generalised to an imprecise-probabilistic context. We show, under some mild conditions, that when the focus is on least-committal models, using the independent natural extension is equivalent to imposing a so-called strong factorisation property. This is an important outcome for applications as it gives a simple tool to make sure that inferences are consistent with epistemic independence judgements. We discuss the potential of our results for applications in Artificial Intelligence by recalling recent work by some of us, where the independent natural extension was applied to graphical models. It has allowed, for the first time, the development of an exact linear-time algorithm for the imprecise probability updating of credal trees.},
  AUTHOR   = {Gert de Cooman and Enrique Miranda and Marco Zaffalon},
  DOI      = {10.1016/j.artint.2011.06.001},
  KEYWORDS = {Epistemic irrelevance; Epistemic independence; Independent natural extension; Strong product; Factorisation; Coherent lower previsions},
  FILE     = {files/Cooman+MZ-AIJ11j.pdf},
  NUMBER   = {12–13},
  PAGES    = {1911–1950},
  TITLE    = {Independent natural extension},
  VOLUME   = {175},
  XDATA    = {AIJ},
  YEAR     = {2011},
}

@XDATA{JAIR,
  JOURNALTITLE = {Journal of Artificial Intelligence Research},
  SHORTJOURNAL = {J. Artificial Intelligence Res.},
}

@ARTICLE{Cooman+Miranda-JAIR12j,
  ABSTRACT = {The results in this paper add useful tools to the theory of sets of desirable gambles, a growing toolbox for reasoning with partial probability assessments. We investigate how to combine a number of marginal coherent sets of desirable gambles into a joint set using the properties of epistemic irrelevance and independence. We provide formulas for the smallest such joint, called their independent natural extension, and study its main properties. The independent natural extension of maximal coherent sets of desirable gambles allows us to define the strong product of sets of desirable gambles. Finally, we explore an easy way to generalise these results to also apply for the conditional versions of epistemic irrelevance and independence. Having such a set of tools that are easily implemented in computer programs is clearly beneficial to fields, like AI, with a clear interest in coherent reasoning under uncertainty using general and robust uncertainty models that require no full specification.},
  AUTHOR   = {Gert de Cooman and Enrique Miranda},
  DOI      = {10.1613/jair.3770},
  FILE     = {files/Cooman+Miranda-JAIR12j.pdf},
  PAGES    = {601–640},
  TITLE    = {Irrelevant and independent natural extension for sets of desirable gambles},
  VOLUME   = {45},
  XDATA    = {JAIR},
  YEAR     = {2012},
}

@XDATA{AMAI,
  JOURNALTITLE = {Annals of Mathematics and Artificial Intelligence},
  SHORTJOURNAL = {Ann. Math. Artif. Intell.},
}

@ARTICLE{Cozman+Walley-AMAI05j,
  ABSTRACT   = {This paper investigates Walley's concepts of epistemic irrelevance and epistemic independence for imprecise probability models. We study the mathematical properties of irrelevance and independence, and their relation to the graphoid axioms. Examples are given to show that epistemic irrelevance can violate the symmetry, contraction and intersection axioms, that epistemic independence can violate contraction and intersection, and that this accords with informal notions of irrelevance and independence.},
  ANNOTATION = {ook op papier},
  AUTHOR     = {Fabio Gagliardi Cozman and Peter Walley},
  DOI        = {10.1007/s10472-005-9004-z},
  FILE       = {files/Cozman+Walley-AMAI05j.pdf},
  NUMBER     = {1},
  PAGES      = {173–195},
  TITLE      = {Graphoid properties of epistemic irrelevance and independence},
  VOLUME     = {45},
  XDATA      = {AMAI},
  YEAR       = {2005},
}

@XDATA{FSS,
  JOURNALTITLE = {Fuzzy Sets and Systems},
  ISSN         = {0165-0114},
  PUBLISHER    = {Elsevier},
  SHORTJOURNAL = {Fuzzy Sets and Systems},
}

@ARTICLE{Quaeghebeur+Cooman-FSS08j,
  ABSTRACT   = {We consider lower probabilities on finite possibility spaces as models for the uncertainty about the state. These generalizations of classical probabilities can have some interesting properties; for example: k-monotonicity, avoiding sure loss, coherence, permutation invariance. The sets formed by all the lower probabilities satisfying zero or more of these properties are convex. We show how the extreme points and rays of these sets – the extreme lower probabilities – can be calculated and we give an illustration of our results.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  DATE       = {2008-09},
  DOI        = {10.1016/j.fss.2007.11.020},
  EPRINT     = {1854/LU-429244},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {combinatorial problems; extreme points; imprecise probabilities; lower probabilities; non-additive measures},
  FILE       = {files/Quaeghebeur+Cooman-FSS08j.pdf},
  NUMBER     = {16},
  PAGES      = {2163–2175},
  TITLE      = {Extreme lower probabilities},
  VOLUME     = {159},
  XDATA      = {FSS},
}

@ARTICLE{Quaeghebeur+SC-FSS12j,
  ABSTRACT   = {We investigate a constrained optimization problem with uncertainty about constraint parameters. Our aim is to reformulate it as a (constrained) optimization problem without uncertainty. This is done by recasting the original problem as a decision problem under uncertainty. We give results for a number of different types of uncertainty models—linear and vacuous previsions, and possibility distributions—and for two common but different optimality criteria for such decision problems—maximinity and maximality. We compare our approach with other approaches that have appeared in the literature.},
  AUTHOR     = {Erik Quaeghebeur and Keivan Shariatmadar and Gert de Cooman},
  DOI        = {10.1016/j.fss.2012.02.004},
  EPRINT     = {1854/LU-2030199},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Constrained optimization; Maximinity; Maximality; Coherent lower prevision; Linear prevision; Vacuous prevision; Possibility distribution},
  PAGES      = {74–88},
  TITLE      = {Constrained optimization problems under uncertainty with coherent lower previsions},
  VOLUME     = {206},
  YEAR       = {2012},
  XDATA      = {FSS},
}

@XDATA{JTP,
  JOURNALTITLE = {Journal of Theoretical Probability},
  SHORTJOURNAL = {J. Theoret. Probab.},
}

@ARTICLE{Miranda+CQ-JTP07j,
  ABSTRACT   = {We investigate to what extent finitely additive probability measures on the unit interval are determined by their moment sequence. We do this by studying the lower envelope of all finitely additive probability measures with a given moment sequence. Our investigation leads to several elegant expressions for this lower envelope, and it allows us to conclude that the information provided by the moments is equivalent to the one given by the associated lower and upper distribution functions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  DATE       = {2007-09-01},
  DOI        = {10.1007/s10959-007-0055-4},
  EPRINT     = {1854/LU-376551},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Hausdorff moment problem; coherent lower prevision; complete monotonicity; lower distribution function},
  FILE       = {files/Miranda+CQ-JTP07j.pdf},
  NUMBER     = {3},
  PAGES      = {663–693},
  TITLE      = {The Hausdorff Moment Problem under Finite Additivity},
  VOLUME     = {20},
  XDATA      = {JTP},
}

@XDATA{PES,
  JOURNALTITLE = {Probability in the Engineering and Informational Sciences},
  SHORTJOURNAL = {Probab. Engrg. Inform. Sci.},
}

@ARTICLE{Cooman+HQ-PES09j,
  ABSTRACT   = {When the initial and transition probabilities of a finite Markov chain in discrete time are not well known, we should perform a sensitivity analysis. This can be done by considering as basic uncertainty models the so-called credal sets that these probabilities are known or believed to belong to, and by allowing the probabilities to vary over such sets. This leads to the definition of an imprecise Markov chain. We show that the time evolution of such a system can be studied very efficiently using so-called lower and upper expectations, which are equivalent mathematical representations of credal sets. We also study how the inferred credal set about the state at time n evolves as n goes to infinity: under quite unrestrictive conditions, it converges to a uniquely invariant credal set, regardless of the credal set given for the initial state. This leads to a non-trivial generalisation of the classical Perron-Frobenius Theorem to imprecise Markov chains.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  DOI        = {10.1017/S0269964809990039},
  EPRINT     = {1854/LU-498502},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {probability tree; credal set; event tree; imprecise Markov chain; Markov chain; non-linear Perron-Frobenius Theorem; sensitivity analysis; stationarity; lower expectation; upper expectation; regularity; decision-processes; transition-probabilities; set-chains},
  NUMBER     = {4},
  PAGES      = {597–635},
  TITLE      = {Imprecise Markov chains and their limit behavior},
  VOLUME     = {23},
  XDATA      = {PES},
  YEAR       = {2009},
}

@XDATA{BEJ,
  JOURNALTITLE = {Bernoulli},
}

@ARTICLE{Cooman+QM-BEJ09j,
  ABSTRACT   = {We extend de Finetti's notion of exchangeability to finite and countable sequences of variables, when a subject's beliefs about them are modelled using coherent lower previsions rather than (linear) previsions. We derive representation theorems in both the finite and the countable case, in terms of sampling without and with replacement, respectively.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur and Enrique Miranda},
  DOI        = {10.3150/09-BEJ182},
  EPRINT     = {1854/LU-498518},
  EPRINTTYPE = {hdl},
  EPRINT     = {0909.1148},
  EPRINTTYPE = {arxiv},
  KEYWORDS   = {Representation Theorem; sampling without replacement; exchangeability; multinomial sampling; lower prevision; imprecise probability; probability; coherence; convergence in distribution; Bernstein polynomials},
  NUMBER     = {3},
  PAGES      = {721–735},
  TITLE      = {Exchangeable lower previsions},
  VOLUME     = {15},
  XDATA      = {BEJ},
  YEAR       = {2009},
}

@XDATA{MP,
  JOURNALTITLE = {Mathematical Programming},
  PUBLISHER    = {Springer},
  SHORTJOURNAL = {Math. Program.},
}

@article{Jackson+Lynch-MP87j,
  AUTHOR   = {Jackson, Peter L. and Lynch, David F.},
  DATE     = {1987},
  DOI      = {10.1007/BF02592950},
  FILE     = {files/Jackson+Lynch-MP87j.pdf},
  KEYWORDS = {Dantzig–Wolfe decomposition; large-scale optimization; linear programming; staircase linear programs; simplex method},
  NUMBER   = {2},
  PAGES    = {157–179},
  TITLE    = {Revised Dantzig–Wolfe decomposition for staircase-structured linear programs},
  VOLUME   = {39},
  XDATA    = {MP},
}

@XDATA{TSVTA,
  JOURNALTITLE = {Труды Семинара по Векторному и Тензорному Анализу (Trudy Seminara po Vektornomu i Tenzornomu Analizu)},
  SHORTJOURNAL = {Tr. Semin. Vektorn. Tenzorn. Anal.},
}

@ARTICLE{Alexandrov+KK-TSVTA05j,
  ABSTRACT   = {This is an extended version of a talk on October 4, 2004 at the research seminar “Differential geometry and applications” (headed by Academician A. T. Fomenko) at Moscow State University. The paper contains an overview of available (but far from well-known) results about the Blaschke addition of convex bodies, some new theorems on the monotonicity of the volume of convex bodies (in particular, convex polyhedra with parallel faces) as well as description of a software for visualization of polyhedra with prescribed outward normals and face areas.},
  AUTHOR     = {Victor Alexandrov and Natalia Kopteva and Semen S. Kutateladze},
  EPRINT     = {math/0502345},
  EPRINTTYPE = {arxiv},
  PAGES      = {8–30},
  TITLE      = {Blaschke addition and convex polyhedra},
  VOLUME     = {26},
  YEAR       = {2005},
  XDATA      = {TSVTA},
}

@COLLECTION{Coolen+ACT-ITIP13b,
  TITLE     = {Introduction to Imprecise Probabilities},
  YEAR      = {expected},
  EDITOR    = {Frank P. A. Coolen and Thomas Augustin and Gert de Cooman and Matthias C. M. Troffaes},
  PUBLISHER = {Wiley},
  SORTYEAR  = {2013},
}

@INCOLLECTION{Quaeghebeur-ITIP13c,
  AUTHOR   = {Erik Quaeghebeur},
  CROSSREF = {Coolen+ACT-ITIP13b},
  TITLE    = {Desirability},
}

@BOOK{Kohlas+Moral-AUDR01b,
  DATE      = {2001},
  DOI       = {10.1007/978-94-017-1737-3},
  EDITOR    = {Jürg Kohlas and Serafín Moral},
  PUBLISHER = {Springer},
  TITLE     = {Algorithms for Uncertainty and Defeasible Reasoning},
  SERIES    = {Handbook of Defeasible Reasoning and Uncertainty Management Systems},
  VOL       = {5},
}

@incollection{Kohlas+Shenoy-AUDR01c,
  AUTHOR   = {Jürg Kohlas and Prakash P. Shenoy},
  CROSSREF = {Kohlas+Moral-AUDR01b},
  DOI      = {10.1007/978-94-017-1737-3_2},
  FILE     = {files/Kohlas+Shenoy-AUDR01c.pdf},
  TITLE    = {Computation in Valuation Algebras},
  PAGES    = {5-39},
}

@INCOLLECTION{Cano+Moral-AUDR01c,
  AUTHOR   = {Andrés Cano and Serafín Moral},
  CROSSREF = {Kohlas+Moral-AUDR01b},
  DOI      = {10.1007/978-94-017-1737-3_9},
  FILE     = {files/Cano+Moral-HDRUMS01c.pdf},
  PAGES    = {369–420},
  TITLE    = {Algorithms for imprecise probabilities},
}

@XDATA{UAI95,
  EVENTDATE  = {1995},
  EVENTTITLE = {UAI '95},
}

@PROCEEDINGS{Besnard+Hanks-UAI95b,
  DATE      = {1995},
  TITLE     = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence},
  EDITOR    = {Philippe Besnard and Steve Hanks},
  PUBLISHER = {Morgan Kaufmann},
  XDATA     = {UAI95},
}

@XDATA{UAI96,
  EVENTDATE  = {1996-08-01/1996-08-04},
  EVENTTITLE = {UAI '96},
  VENUE      = {Reed College, Portland, Oregon, USA},
}

@PROCEEDINGS{Horvitz+Jensen-UAI96b,
  DATE      = {1996},
  EDITOR    = {Eric Horvitz and Finn Verner Jensen},
  PUBLISHER = {Morgan Kaufmann},
  TITLE     = {Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI96},
}

@INPROCEEDINGS{Chrisman-UAI96p,
  AUTHOR     = {Lonnie Chrisman},
  CROSSREF   = {Horvitz+Jensen-UAI96b},
  EPRINT     = {1302.3569},
  EPRINTTYPE = {arxiv},
  FILE       = {files/Chrisman-UAI96p.pdf},
  PAGES      = {178–185},
  TITLE      = {Propagation of 2-monotone lower probabilities on an undirected graph},
}

@XDATA{UAI02,
  EVENTDATE  = {2002-08-01/2002-08-04},
  EVENTTITLE = {UAI '02},
  VENUE      = {University of Alberta, Edmonton, Alberta, Canada},
}

@PROCEEDINGS{Darwiche+Friedman-UAI02b,
  DATE      = {2002},
  EDITOR    = {Adnan Darwiche and Nir Friedman},
  TITLE     = {Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence},
  PUBLISHER = {Morgan Kaufmann},
  XDATA     = {UAI02},
}

@INPROCEEDINGS{Renooij+Gaag-UAI02p,
  AUTHOR    = {Silja Renooij and Linda C. van der Gaag},
  CROSSREF  = {Darwiche+Friedman-UAI02b},
  LOCALFILE = {files/Renooij+Gaag-UAI02p.pdf},
  PAGES     = {422–429},
  TITLE     = {From qualitative to quantitative probabilistic networks},
}

@XDATA{UAI04,
  EVENTDATE  = {2004-07-07/2004-07-11},
  EVENTTITLE = {UAI '04},
  VENUE      = {Banff, Canada},
}

@PROCEEDINGS{Chickering+Halpern-UAI04b,
  DATE      = {2004},
  EDITOR    = {David Maxwell Chickering and Joseph Y. Halpern},
  PUBLISHER = {AUAI Press},
  TITLE     = {Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI04},
}

@INPROCEEDINGS{Renooij-Gaag-UAI04,
  AUTHOR    = {Silja Renooij and Linda C. van der Gaag},
  CROSSREF  = {Chickering+Halpern-UAI04b},
  PAGES     = {479–486},
  TITLE     = {Evidence-invariant sensitivity bounds},
}

@XDATA{UAI05,
  EVENTDATE  = {2005},
  EVENTTITLE = {UAI '05},
}

@PROCEEDINGS{-UAI05b,
  DATE      = {2005},
  ISBN      = {0-9749039-1-4},
  PUBLISHER = {AUAI Press},
  TITLE     = {Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI05},
}

@INPROCEEDINGS{Campos+Cozman-UAI05p,
  AUTHOR     = {Cassio Polpo de Campos and Fabio Gagliardi Cozman},
  CROSSREF   = {-UAI05b},
  EPRINT     = {1207.1367},
  EPRINTTYPE = {arxiv},
  LOCALFILE  = {files/Campos+Cozman-UAI05p.pdf},
  PAGES      = {153–160},
  TITLE      = {Belief Updating and Learning in Semi-Qualitative Probabilistic Networks.},
}

@XDATA{UAI08,
  EVENTDATE  = {2008-07-09/2008-07-12},
  EVENTTITLE = {UAI 2008},
  VENUE      = {Helsinki, Finland},
}

@PROCEEDINGS{McAllester+Myllymäki-UAI08b,
  DATE   = {2008},
  EDITOR = {D. McAllester and P. Myllymäki},
  TITLE  = {Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence},
  XDATA  = {UAI08},
}

@INPROCEEDINGS{Cooman+HQ-UAI08p,
  ABSTRACT   = {When the initial and transition probabilities of a finite Markov chain in discrete time are not well known, we should perform a sensitivity analysis. This is done by considering as basic uncertainty models the so-called credal sets that these probabilities are known or believed to belong to, and by allowing the probabilities to vary over such sets. This leads to the definition of an imprecise Markov chain. We show that the time evolution of such a system can be studied very efficiently using so-called lower and upper expectations. We also study how the inferred credal set about the state at time n evolves as n goes to infinity: under quite unrestrictive conditions, it converges to a uniquely invariant credal set, regardless of the credal set given for the initial state. This leads to a non-trivial generalisation of the classical Perron–Frobenius Theorem to imprecise Markov chains.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  CROSSREF   = {McAllester+Myllymäki-UAI08b},
  EPRINT     = {1854/LU-427340},
  EPRINTTYPE = {hdl},
  PAGES      = {129–136},
  TITLE      = {Sensitivity analysis for finite Markov chains in discrete time},
}

@XDATA{UAI10,
  EVENTDATE  = {2010-07-08/2010-07-11},
  EVENTTITLE = {UAI 2010},
  VENUE      = {Catalina Island, California},
}

@PROCEEDINGS{Spirtes+Grünwald-UAI10b,
  DATE      = {2010},
  EDITOR    = {Peter Spirtes and Peter Grünwald},
  PUBLISHER = {AUAI Press},
  TITLE     = {Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence},
  XDATA     = {UAI10},
}

@INPROCEEDINGS{Quaeghebeur-UAI10p,
  ABSTRACT   = {The standard coherence criterion for lower previsions is expressed using an infinite number of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such lower prevision is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Spirtes+Grünwald-UAI10b},
  EPRINT     = {1854/LU-984156},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherence; lower previsions; polytopes; constraints; vertices; extreme points; characterization; computation},
  PAGES      = {466–473},
  TITLE      = {Characterizing the set of coherent lower previsions with a finite number of constraints or vertices},
}

@XDATA{ISIPTA03,
  EVENTDATE    = {2003-07-14/2003-07-17},
  EVENTTITLE   = {ISIPTA '03},
  ORGANIZATION = {SIPTA},
  VENUE        = {Lugano, Switzerland},
}

@PROCEEDINGS{Bernard+SZ-ISIPTA03b,
  DATE      = {2003},
  EDITOR    = {Jean-Marc Bernard and Teddy Seidenfeld and Marco Zaffalon},
  ISBN      = {9781894145176},
  LOCATION  = {Waterloo, Ontario, Canada},
  PUBLISHER = {Carleton Scientific},
  SERIES    = {Proceedings in Informatics},
  TITLE     = {Proceedings of the Third International Symposium on Imprecise Probabilities and Their Applications},
  VOLUME    = {18},
  XDATA     = {ISIPTA03},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-ISIPTA03p,
  ABSTRACT   = {We discuss two approaches for choosing a strategy in a two-player game. We suppose that the game is played a large number of rounds, which allows the players to use observations of past play to guide them in choosing a strategy. Central in these approaches is the way the opponent's next strategy is assessed; both a precise and an imprecise Dirichlet model are used. The observations of the opponent's past strategies can then be used to update the model and obtain new assessments. To some extent, the imprecise probability approach allows us to avoid making arbitrary initial assessments. To be able to choose a strategy, the assessment of the opponent's strategy is combined with rules for selecting an optimal response to it: a so-called best response or a maximin strategy. Together with the updating procedure, this allows us to choose strategies for all the rounds of the game. The resulting playing sequence can then be analysed to investigate if the strategy choices can converge to equilibria.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {Bernard+SZ-ISIPTA03b},
  EPRINT     = {1854/LU-213482},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {imprecise Dirichlet model; game theory; fictitious play; learning; equilibria},
  PAGES      = {452–466},
  TITLE      = {Game-Theoretic Learning Using the Imprecise Dirichlet Model},
}

@XDATA{ISIPTA05,
  EVENTDATE    = {2005-07-20/2005-07-23},
  EVENTTITLE   = {ISIPTA '05},
  ORGANIZATION = {SIPTA},
  VENUE        = {Pittsburgh, Pennsylvania},
}

@PROCEEDINGS{Cozman+NS-ISIPTA05b,
  DATE   = {2005},
  EDITOR = {Fabio Gagliardi Cozman and Robert Nau and Teddy Seidenfeld},
  TITLE  = {Proceedings of the Fourth International Symposium on Imprecise Probabilities and Their Applications},
  XDATA  = {ISIPTA05},
}

@INPROCEEDINGS{Cooman+TM-ISIPTA05p,
  AUTHOR   = {Gert de Cooman and Matthias C. M. Troffaes and Enrique Miranda},
  CROSSREF = {Cozman+NS-ISIPTA05b},
  PAGES    = {145–154},
  TITLE    = {n-Monotone lower previsions and lower integrals},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-ISIPTA05p,
  ABSTRACT   = {When considering sampling models described by a distribution from an exponential family, it is possible to create two types of imprecise probability models. One is based on the corresponding conjugate distribution and the other on the corresponding predictive distribution. In this paper, we show how these types of models can be constructed for any (regular, linear, canonical) exponential family, such as the centered normal distribution. To illustrate the possible use of such models, we take a look at credal classification. We show that they are very natural and potentially promising candidates for describing the attributes of a credal classifier, also in the case of continuous attributes.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {Cozman+NS-ISIPTA05b},
  EPRINT     = {1854/LU-320871},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Exponential family; Inference; Imprecise probability models; Conjugate analysis; Naive credal classifier},
  PAGES      = {287–296},
  TITLE      = {Imprecise probability models for inference in exponential families},
}

@INPROCEEDINGS{Wallner-ISIPTA05p,
  AUTHOR   = {Anton Wallner},
  CROSSREF = {Cozman+NS-ISIPTA05b},
  PAGES    = {388–395},
  TITLE    = {Maximal number of vertices of polytopes defined by F-probabilities},
}

@XDATA{ISIPTA07,
  EVENTDATE    = {2007-07-16/2007-07-19},
  EVENTTITLE   = {ISIPTA '07},
  ORGANIZATION = {SIPTA},
  VENUE        = {Prague, Czech Republic},
}

@PROCEEDINGS{Cooman+VZ-ISIPTA07b,
  DATE   = {2007},
  EDITOR = {Gert de Cooman and Jiřina Vejnarová and Marco Zaffalon},
  TITLE  = {Proceedings of the Fifth International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA07},
}

@INPROCEEDINGS{Cooman+MQ-ISIPTA07p,
  ABSTRACT   = {We consider immediate predictive inference, where a subject, using a number of observations of a finite number of exchangeable random variables, is asked to coherently model his beliefs about the next observation, in terms of a predictive lower prevision. We study when such predictive lower previsions are representation insensitive, meaning that they are essentially independent of the choice of the (finite) set of possible values for the random variables. Such representation insensitive predictive models have very interesting properties, and among such models, the ones produced by the Imprecise Dirichlet-Multinomial Model are quite special in a number of ways.},
  AUTHOR     = {Gert de Cooman and Enrique Miranda and Erik Quaeghebeur},
  CROSSREF   = {Cooman+VZ-ISIPTA07b},
  EPRINT     = {1854/LU-371965},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherence; exchangeability; immediate prediction; predictive inference; imprecise Dirichlet-Multinomial model; lower prevision; coherence; representation insensitivity; exchangeability; immediate prediction; representation invariance; Johnson's sufficientness postulate},
  TITLE      = {Immediate prediction under exchangeability and representation insensitivity},
}

@XDATA{ISIPTA09,
  EVENTDATE    = {2009-07-14/2009-07-18},
  EVENTTITLE   = {ISIPTA '09},
  ORGANIZATION = {SIPTA},
  VENUE        = {Durham, United Kingdom},
}

@PROCEEDINGS{Augustin+CMT-ISIPTA09b,
  DATE   = {2009},
  EDITOR = {Thomas Augustin and Frank P. A. Coolen and Serafín Moral and Matthias C. M. Troffaes},
  TITLE  = {Proceedings of the Sixth International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA09},
}

@INPROCEEDINGS{Cooman+Quaeghebeur-ISIPTA09p,
  ABSTRACT   = {Sets of desirable gambles constitute a quite general type of uncertainty model with an interesting geometrical interpretation. We study exchangeability assessments for such models, and prove a counterpart of de Finetti's finite representation theorem. We show that this representation theorem has a very nice geometrical interpretation. We also lay bare the relationships between the representations of updated exchangeable models, and discuss conservative inference (natural extension) under exchangeability.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {Augustin+CMT-ISIPTA09b},
  EPRINT     = {1854/LU-718913},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherence; exchangeability; sets of desirable gambles; weak desirability; representation; desirability; natural extension; real desirability; updating},
  PAGES      = {159–168},
  TITLE      = {Exchangeability for sets of desirable gambles},
}

@INPROCEEDINGS{Shariatmadar+QC-ISIPTA09a,
  AUTHOR     = {Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {ISIPTA '09: Program \& Abstracts},
  EPRINT     = {1854/LU-718910},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {vacuous prevision; possibility distribution; maximinity; constrained optimization; p-box; linear prevision; maximality},
  PAGES      = {34–34},
  TITLE      = {A constrained optimization problem under uncertainty},
  YEAR       = {2009},
  XDATA      = {ISIPTA09},
}

@XDATA{ISIPTA11,
  EVENTDATE    = {2011-07-25/2011-07-28},
  EVENTTITLE   = {ISIPTA '11},
  ORGANIZATION = {SIPTA},
  VENUE        = {Innsbruck, Austria},
}

@PROCEEDINGS{-ISIPTA11b,
  DATE  = {2011},
  TITLE = {Program and Abstracts},
  XDATA = {ISIPTA11},
}

@INPROCEEDINGS{Quaeghebeur+CH-ISIPTA11a,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Filip Hermans},
  CROSSREF   = {-ISIPTA11b},
  EPRINT     = {1854/LU-1863955},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {acceptability; desirability; favorability; indifference; preference},
  PAGES      = {29},
  TITLE      = {Generalizing nonstrict and strict preference desirability},
}

@INPROCEEDINGS{Camp+CBQH-ISIPTA11a,
  AUTHOR     = {Arthur Van Camp and Gert de Cooman and Jasper De Bock and Erik Quaeghebeur and Filip Hermans},
  CROSSREF   = {-ISIPTA11b},
  EPRINT     = {1854/LU-1863971},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {hidden Markov models; learning; imprecise Dirichlet model; expected counts},
  PAGES      = {34},
  TITLE      = {Learning imprecise hidden Markov models},
}

@INPROCEEDINGS{Shariatmadar+QC-ISIPTA11a,
  AUTHOR     = {Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {-ISIPTA11b},
  EPRINT     = {1854/LU-1225787},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {maximality; linear programming; maximinity; possibility distribution; vacuous prevision},
  PAGES      = {31},
  TITLE      = {Linear programming under vacuous and possibilistic uncertainty},
}

@XDATA{ISIPTA13,
  EVENTDATE    = {2013-07-02/2013-07-05},
  EVENTTITLE   = {ISIPTA '13},
  ORGANIZATION = {SIPTA},
  VENUE        = {Compiègne, France},
}

@PROCEEDINGS{Cozman+DDS-ISIPTA13b,
  DATE   = {2013},
  EDITOR = {Fabio Cozman and Thierry Denœux and Sébastien Destercke and Teddy Seidenfeld},
  TITLE  = {Proceedings of the Eight International Symposium on Imprecise Probability: Theories and Applications},
  XDATA  = {ISIPTA13},
}

@INPROCEEDINGS{Quaeghebeur-ISIPTA13p,
  ABSTRACT   = {Lower previsions defined on a finite set of gambles can be looked at as points in a finite-dimensional real vector space. Within that vector space, the sets of sure loss avoiding and coherent lower previsions form convex polyhedra. We present procedures for obtaining characterizations of these polyhedra in terms of a minimal, finite number of linear constraints. As compared to the previously known procedure, these procedures are more efficient and much more straightforward. Next, we take a look at a procedure for correcting incoherent lower previsions based on pointwise dominance. This procedure can be formulated as a multi-objective linear program, and the availability of the finite characterizations provide an avenue for making these programs computationally feasible.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Cozman+DDS-ISIPTA13b},
  KEYWORDS   = {avoiding sure loss; coherence; linear constraint; polytope; enumeration; projection; multi-objective linear programming; incoherence; dominance},
  PAGES      = {275–284},
  TITLE      = {Characterizing coherence, correcting incoherence },
}

@XDATA{SMPS06,
  EVENTDATE  = {2006-09-05/2006-09-07},
  EVENTTITLE = {SMPS 2006},
  VENUE      = {Bristol, England},
}

@PROCEEDINGS{Lawry+MBLGGH-SMPS06b,
  EDITOR    = {Jonathan Lawry and Enrique Miranda and A. Bugarin and Shoumei Li and María Ángeles Gil and Przemysław Grzegorzewski and Olgierd Hryniewicz},
  ISBN      = {978-3540347767},
  ISSN      = {1615-3871},
  PUBLISHER = {Springer},
  TITLE     = {Soft Methods for Integrated Uncertainty Modelling},
  SERIES    = {Advances in Soft Computing},
  VOLUME    = {6},
  XDATA     = {SMPS06},
  YEAR      = {2006},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-SMPS06p,
  ABSTRACT   = {We consider lower probabilities on finite possibility spaces as models for the uncertainty about the state. These generalizations of classical probabilities can have some interesting properties; for example: k-monotonicity, avoiding sure loss, coherence, permutation invariance. The sets formed by all the lower probabilities satisfying zero or more of these properties are convex. We show how the extreme points and rays of these sets – the extreme lower probabilities – can be calculated and we give an illustration of our results.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  CROSSREF   = {Lawry+MBLGGH-SMPS06b},
  DOI        = {10.1007/3-540-34777-1_26},
  EPRINT     = {1854/LU-406341},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {extreme points; Lower probabilities; imprecise probabilities},
  PAGES      = {211–221},
  TITLE      = {Extreme lower probabilities},
}

@XDATA{SMPS08,
  EVENTDATE  = {2008-09-08/2008-09-10},
  EVENTTITLE = {SMPS 2008},
  VENUE      = {Toulouse, France},
}

@PROCEEDINGS{Dubois+LPGGH-SMPS08b,
  DATE      = {2008},
  EDITOR    = {Didier Dubois and M. A. Lubiano and H. Prade and María Ángeles Gil and Przemysław Grzegorzewski and Olgierd Hryniewicz},
  PUBLISHER = {Springer},
  SERIES    = {Advances in Soft Computing},
  TITLE     = {Soft methods for handling variability and imprecision},
  VOLUME    = {48},
  XDATA     = {SMPS08},
}

@INPROCEEDINGS{Quaeghebeur-SMPS08p,
  ABSTRACT   = {We give a definition for lower and upper covariance in Walley's theory of imprecise probabilities (or coherent lower previsions) that is direct, i.e., does not refer to credal sets. It generalizes Walley's definition for lower and upper variance. Just like Walley's definition of lower and upper variance, our definition for lower and upper covariance is compatible with the credal set approach; i.e., we also provide a covariance envelope theorem. Our approach mirrors the one taken by Walley: we first reformulate the calculation of a covariance as an optimization problem and then generalize this optimization problem to lower and upper previsions. We also briefly discuss the still unclear meaning of lower and upper (co)variances and mention some ideas about generalizations to other central moments.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Dubois+LPGGH-SMPS08b},
  DOI        = {10.1007/978-3-540-85027-4_39},
  EPRINT     = {1854/LU-445579},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {central moment; covariance; envelope theorem; variance; theory of imprecise probabilities},
  PAGES      = {323–330},
  TITLE      = {Lower and upper covariance},
}

@XDATA{SMPS12,
  EVENTDATE  = {2012-10-04/2012-10-06},
  EVENTTITLE = {SMPS 2012},
  VENUE      = {Konstanz, Germany},
}

@PROCEEDINGS{Kruse+BMGGH-SMPS12b,
  DATE      = {2013},
  EDITOR    = {Rudolf Kruse and Michael R. Berthold and Christian Moewes and María Ángeles Gil and Przemysław Grzegorzewski and Olgierd Hryniewicz},
  PUBLISHER = {Springer},
  SERIES    = {Advances in Soft Computing},
  TITLE     = {Synergies of Soft Computing and Statistics for Intelligent Data Analysis},
  VOLUME    = {190},
  XDATA     = {SMPS12},
}

@INPROCEEDINGS{Quaeghebeur-SMPS12p,
  ABSTRACT   = {Uncertainty models such as sets of desirable gambles and (conditional) lower previsions can be represented as convex cones. Checking the consistency of and drawing inferences from such models requires solving feasibility and optimization problems. We consider finitely generated such models. For closed cones, we can use linear programming; for conditional lower prevision-based cones, there is an efficient algorithm using an iteration of linear programs. We present an efficient algorithm for general cones that also uses an iteration of linear programs.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Kruse+BMGGH-SMPS12b},
  DOI        = {10.1007/978-3-642-33042-1_6},
  EPRINT     = {1854/LU-3007274},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Consistency; convex cones; feasibility; inference; linear programming},
  PAGES      = {45–54},
  TITLE      = {The CONEstrip algorithm},
}

@XDATA{NLMUA2011,
  EVENTDATE  = {2011-09-07/2011-09-09},
  EVENTTITLE = {NLMUA 2011},
  VENUE      = {Beijing, China},
}

@PROCEEDINGS{Li+WOKMG-NLMUA11b,
  EDITOR    = {Shoumei Li and Xia Wang and Yoshiaki Okazaki and Jun Kawabe and Toshiaki Murofushi and Li Guan},
  PUBLISHER = {Springer},
  SERIES    = {Advances in Intelligent and Soft Computing},
  TITLE     = {Nonlinear Mathematics for Uncertainty and its Applications},
  VOLUME    = {100},
  YEAR      = {2011},
  XDATA     = {NLMUA2011},
}

@INPROCEEDINGS{Quaeghebeur-NLMUA11p,
  ABSTRACT   = {Drawing inferences from general lower probabilities on finite possibility spaces usually involves solving linear programming problems. For some applications this may be too computationally demanding. Some special classes of lower probabilities allow for using computationally less demanding techniques. One such class is formed by the completely monotone lower probabilities, for which inferences can be drawn efficiently once their Mö bius transform has been calculated. One option is therefore to draw approximate inferences by using a completely monotone approximation to a general lower probability; this must be an outer approximation to avoid drawing inferences that are not implied by the approximated lower probability. In this paper, we discuss existing and new algorithms for performing this approximation, discuss their relative strengths and weaknesses, and illustrate how each one works and performs.},
  AUTHOR     = {Erik Quaeghebeur},
  CROSSREF   = {Li+WOKMG-NLMUA11b},
  DOI        = {10.1007/978-3-642-22833-9_20},
  EPRINT     = {1854/LU-1864309},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {outer approximation; lower probabilities; complete monotonicity; belief functions; Möbius transform},
  PAGES      = {169–178},
  TITLE      = {Completely monotone outer approximations of lower probabilities on finite possibility spaces},
}

@XDATA{IPMU96,
  EVENTDATE  = {1996-07-01/1996-07-05},
  EVENTTITLE = {IPMU '96},
  VENUE      = {Granada, Spain},
}

@PROCEEDINGS{-IPMU96b,
  DATE  = {1996},
  TITLE = {Proceedings of the Sixth International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems: IPMU 96},
  XDATA = {IPMU96},
}

@INPROCEEDINGS{Vicig-IPMU96p,
  AUTHOR   = {Paolo Vicig},
  CROSSREF = {-IPMU96b},
  FILE     = {files/Vicig-IPMU96p.pdf},
  PAGES    = {61–66},
  TITLE    = {An algorithm for imprecise conditional probability assessments in expert systems},
  VOLUME   = {1},
}

@INPROCEEDINGS{Moral+Wilson-IPMU96p,
  ANNOTATION = {ook op papier},
  CROSSREF   = {-IPMU96b},
  AUTHOR     = {Serafín Moral and Nic Wilson},
  PAGES      = {1337–1344},
  TITLE      = {Importance sampling algorithms for the calculation of Dempster-Shafer belief},
  VOLUME     = {3},
}

@XDATA{IPMU02,
  EVENTDATE  = {2002},
  EVENTTITLE = {IPMU 2002},
}

@PROCEEDINGS{-IPMU02b,
  DATE  = {2002},
  TITLE = {Proceedings of the Ninth International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems},
  XDATA = {IPMU02},
}

@INPROCEEDINGS{Miranda+CC-IPMU02p,
  ABSTRACT   = {We discuss how lower previsions induced by multi-valued mappings fit into the framework of the behavioural theory of imprecise probabilities, and show how the notions of coherence and natural extension from that theory can be used to prove and generalise existing results in an elegant and straightforward manner. This provides a clear example for their explanatory and unifying power.},
  ANNOTATION = {uitgebreide versie, ook op papier},
  CROSSREF   = {-IPMU02b},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Inés Couso},
  KEYWORDS   = {coherence; conditioning; evidence theory},
  TITLE      = {Lower previsions induced by multi-valued mappings},
}

@XDATA{IPMU06,
  EVENTDATE  = {2006-07-02/2006-07-02},
  EVENTTITLE = {IPMU 2006},
  VENUE      = {Paris, France},
}

@PROCEEDINGS{-IPMU06b,
  DATE       = {2006},
  PUBLISHER  = {Editions E.D.K.},
  TITLEADDON = {Proceedings of the Eleventh International Conference on Information Processing and Management of Uncertainty in Knowledge-based Systems},
  TITLE      = {Information Processing and Management of Uncertainty in Knowledge-based Systems},
  XDATA      = {IPMU06},
}

@INPROCEEDINGS{Miranda+CQ-IPMU06p,
  ABSTRACT   = {We study the moment problem for finitely additive probabilities and show that the information provided by the moments is equivalent to the one given by the associated lower and upper distribution functions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {-IPMU06b},
  EPRINT     = {1854/LU-344503},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherent lower previsions; moment problem; lower and upper distribution functions},
  PAGES      = {89–96},
  TITLE      = {The moment problem for finitely additive probabilities},
  VOLUME     = {1},
}

@COLLECTION{Bouchon+YMR-UIIS08b,
  DATE      = {2008},
  EDITOR    = {Bernadette Bouchon-Meunier and Ronald R. Yager and C. Marsala and M. Rifqi},
  ISBN      = {978-981-279-234-1},
  PUBLISHER = {World Scientific},
  TITLE     = {Uncertainty and Intelligent Information Systems},
  URL       = {http://www.worldscibooks.com/compsci/6747.html},
}

@INCOLLECTION{Miranda+CQ-UIIS08c,
  ABSTRACT   = {We study the moment problem for finitely additive probabilities and show that the information provided by the moments is equivalent to the one given by the associated lower and upper distribution functions.},
  AUTHOR     = {Enrique Miranda and Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {Bouchon+YMR-UIIS08b},
  CHAPTER    = {3},
  EPRINT     = {1854/LU-430153},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {coherent lower previsions; moment problem; lower and upper distribution functions},
  PAGES      = {33–45},
  TITLE      = {The moment problem for finitely additive probabilities},
}

@XDATA{IPMU10,
  EVENTDATE  = {2010-06-28/2010-07-02},
  EVENTTITLE = {IPMU 2010},
  VENUE      = {Dortmund, Germany},
}

@PROCEEDINGS{Hüllermeier+KH-IPMU10b,
  DATE      = {2010},
  EDITOR    = {Eyke Hüllermeier and Rudolf Kruse and Frank Hoffmann},
  PUBLISHER = {Springer},
  SERIES    = {Communications in Computer and Information Science},
  VOLUME    = {80},
  XDATA     = {IPMU10},
}

@INPROCEEDINGS{Cooman+Quaeghebeur-IPMU10p,
  ABSTRACT   = {Sets of desirable gambles constitute a quite general type of uncertainty model with an interesting geometrical interpretation. We study infinite exchangeability assessments for them, and give a counterpart of de Finetti's infinite representation theorem. We show how the infinite representation in terms of frequency vectors is tied up with multivariate Bernstein (basis) polynomials. We also lay bare the relationships between the representations of updated exchangeable models, and discuss conservative inference (natural extension) under exchangeability.},
  AUTHOR     = {Gert de Cooman and Erik Quaeghebeur},
  CROSSREF   = {Hüllermeier+KH-IPMU10b},
  DOI        = {10.1007/978-3-642-14055-6_7},
  EPRINT     = {1854/LU-984155},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {sets of desirable gambles; weak desirability; natural extension; coherence; desirability; exchangeability; representation; updating},
  PAGES      = {60–69},
  TITLE      = {Infinite exchangeability for sets of desirable gambles},
}

@XDATA{IPMU12,
  EVENTDATE  = {2012-07-09/2012-07-13},
  EVENTTITLE = {IPMU 2012},
  VENUE      = {Catania, Italy},
}

@PROCEEDINGS{Greco+BCFMY-IPMU12b,
  DATE      = {2012},
  EDITOR    = {Salvatore Greco and Bernadette Bouchon-Meunier and Giulianella Coletti and Mario Fedrizzi and Benedetto Matarazzo and Ronald R. Yager},
  ISBN      = {978-3-642-31718-7},
  ISSN      = {1865-0929},
  PUBLISHER = {Springer},
  SERIES    = {Communications in Computer and Information Science},
  TITLE     = {Advances in Computational Intelligence},
  VOLUME    = {299},
  XDATA     = {IPMU12},
}

@INPROCEEDINGS{Quaeghebeur+HSC-IPMU12p,
  ABSTRACT   = {We consider linear programming problems with uncertain constraint coefficients described by intervals or, more generally, possibility distributions. The uncertainty is given a behavioral interpretation using coherent lower previsions from the theory of imprecise probabilities. We give a meaning to the linear programming problems by reformulating them as decision problems under such imprecise-probabilistic uncertainty. We provide expressions for and illustrations of the maximin and maximal solutions of these decision problems and present computational approaches for dealing with them.},
  AUTHOR     = {Erik Quaeghebeur and Nathan Huntley and Keivan Shariatmadar and Gert de Cooman},
  CROSSREF   = {Greco+BCFMY-IPMU12b},
  DOI        = {10.1007/978-3-642-31718-7_45},
  EPRINT     = {1854/LU-2090091},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {linear program; interval uncertainty; vacuous lower prevision; possibility distribution; coherent lower prevision; imprecise probabilities; decision making; maximinity; maximality},
  PAGES      = {430–439},
  TITLE      = {Maximin and Maximal Solutions for Linear Programming Problems with Possibilistic Uncertainty},
}

@XDATA{FLINS10,
  EVENTDATE  = {2010-08-02/2010-08-04},
  EVENTTITLE = {FLINS 2010},
  VENUE      = {Chengdu, China},
}

@PROCEEDINGS{Ruan+LXCK-FLINS10b,
  DATE       = {2010},
  EDITOR     = {Da Ruan and Yianrui Li and Yang Xu and Guoqing Chen and Etienne E. Kerre},
  LOCATION   = {Singapore},
  PUBLISHER  = {World Scientific},
  SERIES     = {Proceedings Series on Computer Engineering and Information Science},
  TITLE      = {Computational intelligence: foundations and applications},
  XDATA      = {FLINS10},
}

@INPROCEEDINGS{Quaeghebeur+SC-FLINS10p,
  ABSTRACT   = {We investigate a constrained optimization problem for which there is uncertainty about a constraint parameter. Our aim is to reformulate it as a (constrained) optimization problem without uncertainty. This is done by recasting the original problem as a decision problem under uncertainty. We give results for a number of different types of uncertainty models—linear and vacuous previsions, and possibility distributions—and for two different optimality criteria for decision problems under uncertainty—maximinity and maximality.},
  AUTHOR     = {Erik Quaeghebeur and Keivan Shariatmadar and Gert de Cooman},
  CROSSREF   = {Ruan+LXCK-FLINS10b},
  DOI        = {10.1142/9789814324700_0120},
  EPRINT     = {1854/LU-973379},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {possibility distribution; linear prevision; maximinity; maximality; vacuous prevision; constrained optimization},
  PAGES      = {791–796},
  TITLE      = {A constrained optimization problem under uncertainty},
}

@XDATA{FLINS12,
  EVENTDATE  = {2012-08-26/2012-08-29},
  EVENTTITLE = {FLINS 2012},
  VENUE      = {Istanbul, Turkey},
}

@PROCEEDINGS{Kahraman+KB-FLINS12b,
  DATE       = {2012},
  EDITOR     = {Cengiz Kahraman and Etienne E. Kerre and Faik Tunc Bozbura},
  PUBLISHER  = {World Scientific},
  SERIES     = {Proceedings Series on Computer Engineering and Information Science},
  TITLE      = {Uncertainty Modeling in Knowledge Engineering and Decision Making},
  VOLUME     = {7},
  XDATA      = {FLINS12},
}

@INPROCEEDINGS{Huntley+QSQCK-FLINS12p,
  ABSTRACT   = {We present a software implementation of the methods for solving linear programming problems under uncertainty from previous work. Uncertainties about constraint parameters can be expressed as intervals or trapezoidal possibility distributions. The software computes the solutions for the optimality criteria maximin and maximality. For maximality with possibility distributions, only an approximate solution is obtained.},
  AUTHOR     = {Nathan Huntley and Rolando Quiñones and Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman and Etienne E. Kerre},
  CROSSREF   = {Kahraman+KB-FLINS12b},
  DOI        = {10.1142/9789814417747_0075},
  EPRINT     = {1854/LU-3028486},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {linear programming; uncertainty; maximin; maximality; implementation},
  PAGES      = {465–470},
  TITLE      = {Implementation of maximin and maximal solutions for linear programming problems under uncertainty},
}

@INPROCEEDINGS{Cooman+QM-ISI07p,
  ABSTRACT     = {This paper deals with belief models, and in particular lower previsions, for both (finite) collections and (infinite) sequences of exchangeable random variables taking a finite number of values. When such collections or sequences are assumed to be exchangeable, this more or less means that their specific order is irrelevant. We show that exchangeable lower previsions can be written as a combination of (i) a coherent prevision expressing that permutations of realisations of such collections or sequences are considered equally likely, and (ii) a coherent lower prevision for the `frequency' of occurrence of the different values the random variables can take. This is the essence of representation in de Finetti's sense: we generalise his results to coherent lower previsions, both for finite collections and infinite sequences. We also solve a more practical problem: how to extend a number of lower prevision assessments to an exchangeable lower prevision that is as conservative as possible.},
  AUTHOR       = {Gert de Cooman and Erik Quaeghebeur and Enrique Miranda},
  BOOKTITLE    = {Bulletin of the International Statistical Institute 56th Session – Proceedings},
  EPRINT       = {1854/LU-377955},
  EPRINTTYPE   = {hdl},
  NUMBER       = {1556},
  ORGANIZATION = {International Statistical Institute},
  TITLE        = {Representing and assessing exchangeable lower previsions},
  VENUE        = {Lisboa, Portugal},
  YEAR         = {2007},
}

@INPROCEEDINGS{Shariatmadar+ACBQK-USD10p,
  ABSTRACT   = {We consider the problem of modelling the load on a bridge pillar when hit by a vehicle. This load depends on a number of uncertain variables, such as the mass of the vehicle and its speed on impact. The objective of our study is to analyse their effect on the load. More specifically, we are interested in finding the minimum distance of the pillar to the side of the road passing under the bridge such that a given constraint on the load is satisfied in 99\% of impact cases, i.e., such that the probability of satisfying the constraint is 0.99. In addition, we look for solutions to the following optimisation problem: find the distance that minimises a given cost function while still satisfying a given constraint on the load. This optimisation problem under uncertain constraints is not a well-posed problem, so we turn it into a decision problem under uncertainty. For both problems, we consider two typical cases. In the first, so-called precise-probability case, all uncertain variables involved are modelled using probability distributions, and in the second, so-called imprecise-probability case, the uncertainty for at least some of the variables (in casu the mass) is modelled by an interval of possible values, which is a special imprecise-probabilistic model. In the first case, we compute the joint distribution using simple Monte Carlo simulation, and in the second case, we combine Monte Carlo simulation with newly developed techniques in the field of imprecise probabilities. For the optimisation problem with uncertain constraints, this leads to two distinct approaches with different optimality criteria, namely maximality and maximinity, which we discuss and compare.},
  AUTHOR     = {Keivan Shariatmadar and Raluca Andrei and Gert de Cooman and Pieter Baekeland and Erik Quaeghebeur and Etienne E. Kerre},
  BOOKTITLE  = {Proceedings of ISMA2010: international conference on noise and vibration engineering including USD2010},
  EDITOR     = {P. Sas and B. Bergen},
  EPRINT     = {1854/LU-97337},
  EPRINTTYPE = {hdl},
  ISBN       = {9789073802872},
  KEYWORDS   = {vehicle impact; constrained optimisation; decision making; maximinity; linear-vacuous prevision; uncertainty; bridge collision; maximality; Vehicle–pillar collision; linear prevision},
  PAGES      = {5057–5065},
  PUBLISHER  = {KU Leuven. Department of Mechanical Engineering},
  TITLE      = {Optimisation under uncertainty applied to a bridge collision problem},
  VENUE      = {Leuven, Belgium},
  YEAR       = {2010},
}

@INPROCEEDINGS{Quaeghebeur-DynComp03a,
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Proceedings of the 7th workshop on dynamics and computation: Iterated games and cooperation},
  EDITOR     = {Vincent Blondel and Patrick Deleenheer and Rudolphe Sepulchre},
  EPRINT     = {1854/LU-212736},
  EPRINTTYPE = {hdl},
  PAGES      = {28–29},
  TITLE      = {Fictitious play: two viewpoints and two versions},
  VENUE      = {Leuven, Belgium},
  YEAR       = {2003},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-BeNeLux04a,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {Book of Abstracts 23rd Benelux Meeting on Systems and Control},
  EDITOR     = {Bram de Jager and Vincent Verdult},
  EPRINT     = {1854/LU-213489},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2004-03-17/2004-03-19},
  PAGES      = {113},
  TITLE      = {Command line completion: an illustration of learning and decision making using the imprecise Dirichlet model},
  VENUE      = {Helvoirt, the Netherlands},
  YEAR       = {2004},
}

@INPROCEEDINGS{Quaeghebeur-GeoMIP11a,
  ABSTRACT   = {The criteria that characterize many interesting classes of lower previsions, such as coherent or k-monotone lower probabilities, can in finite spaces often be seen as a set of linear constraints on the set of lower previsions in the class, which therefore is a convex polyhedron. It can be equivalently characterized by its set of vertices. For all interesting classes that I studied, the set of vertices or necessary and sufficient constraints is finite. In the presentation I aim to make these representations a bit more concrete to people, so that their possible uses – both in applications and theory – can be discussed in a tangible way.},
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Geometry of Imprecise Probability and related Statistical Methods, Workshop abstracts},
  EPRINT     = {1854/LU-1974606},
  EPRINTTYPE = {hdl},
  TITLE      = {Finitary characterizations of sets of lower previsions},
  VENUE      = {Durham, UK},
  YEAR       = {2011},
}

@INPROCEEDINGS{Quaeghebeur+CH-RatDec12a,
  ABSTRACT   = {Uncertainty and preference is often modeled using linear previsions and linear orders. Some more expressive models use sets of probabilities, lower previsions, or partial orders (see, e.g., the work of Seidenfeld et al. and Walley). In the discussion of these more expressive models, or even to justify them, alternative representations in terms of sets of so-called acceptable, favorable, or desirable gambles appear (cf. the work of Williams, Seidenfeld et al., and Walley). Such ‘sets of gambles’-based models are attractive because of their geometric nature. We generalize these ‘sets of gambles’-based models by considering a pair of sets, one with accepted gambles and one with rejected gambles. We develop a framework based on a small number of axioms—No Confusion, Deductive Closure, No Limbo, and Indifference to Status Quo—and provide an interesting characterization of the resulting models. Furthermore, we define a pair of equivalent gamble relations that generalize the partial orders mentioned earlier; the corresponding characterization result is also given.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Filip Hermans},
  BOOKTITLE  = {Frontiers of Rationality and Decision, Abstracts},
  EPRINT     = {1854/LU-2977779},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2012-08-29/2012-08-31},
  KEYWORDS   = {statements; preference; accept; reject; acceptability; indifference; favorability; desirability; prevision},
  PAGETOTAL  = {2},
  TITLE      = {Modeling uncertainty using accept \& reject statements},
  VENUE      = {Groningen, the Netherlands},
  YEAR       = {2012},
}

@INPROCEEDINGS{Quaeghebeur+Cooman-PhDSymp03a,
  ABSTRACT   = {A method of command line completion based on probabilistic models is described. The method supplements the existing deterministic ones. The probabilistic models are developed within the context of imprecise probabilities. An imprecise Dirichlet model is used to represent the assessments about all possible completions and to allow for learning by observing the commands typed previously. Due to the use of imprecise probabilities a partial (instead of a linear) ordering of the possible completion actions will be constructed during decision making. Markov models can additionally be incorporated to take recurring sequences of commands into account.},
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {Proceedings of the Fourth UGent-FTW PhD Symposium},
  EPRINT     = {1854/LU-289414},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {decision making; learning; command line completion; imprecise Dirichlet model; Markov model},
  PAGETOTAL  = {2},
  PUBLISHER  = {Ghent University Faculty of Engineering},
  TITLE      = {Command line completion: an illustration of learning and decision making using the imprecise Dirichlet model},
  VENUE      = {Ghent, Belgium},
  YEAR       = {2003},
}

@INPROCEEDINGS{Quaeghebeur+CD-PhDSymp05a,
  AUTHOR     = {Erik Quaeghebeur and Gert de Cooman and Dirk Aeyels},
  BOOKTITLE  = {Proceedings of the Sixth UGent-FirW PhD Symposium},
  EPRINT     = {1854/LU-325534},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2005-11-30},
  TITLE      = {Building classifiers that cope with small training sets},
  VENUE      = {Ghent, Belgium},
  YEAR       = {2005},
}

@INPROCEEDINGS{Quaeghebeur-IAP02a,
  ABSTRACT   = {The objective of our research is first of all the development of a method for learning the transition probabilities in (possibly hidden) Markov models using imprecise probabilities, and next the application of this method to some real-life problems. The learning model used will be the imprecise Dirichlet model, an extension of the precise Dirichlet model to the theory of imprecise probabilities. Possible applications are gene-sequence alignment and pre-fetching of web pages.},
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attraction Pole IAP V/22 Study Day, Posters},
  EPRINT     = {1854/LU-1974568},
  EPRINTTYPE = {hdl},
  TITLE      = {Learning in Markov models using the imprecise Dirichlet model},
  VENUE      = {Louvain-la-Neuve, Belgium},
  YEAR       = {2002},
}

@INPROCEEDINGS{Cooman+HQ-IAP07a,
  ABSTRACT   = {An imprecise Markov chain is defined by a closed convex set of transition matrices instead of a unique one for a classical precise Markov chain. These imprecise Markov chains allow us to model situations where we do not have enough information to specify a unique transition matrix, or to approximate the behaviour of non‐stationary Markov chains. We show that there are efficient, dynamic programming‐ like ways to work and reason with these imprecise Markov chains; e.g. to calculate the resulting distribution over the states at any time instant. We prove that this distribution converges in time, similarly to the precise case and under very mild conditions. We thus effectively prove a Perron-Frobenius theorem for a special class of non‐linear systems.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attaction Pole IAP VI/4-DYSCO, Abstracts},
  EPRINT     = {1854/LU-1974573},
  EPRINTTYPE = {hdl},
  PAGES      = {14–14},
  TITLE      = {Limit behaviour for imprecise Markov Chains},
  VENUE      = {Brussels, Belgium},
  YEAR       = {2007},
}

@INPROCEEDINGS{Cooman+HQ-DYSCO07a,
  ABSTRACT   = {Event trees are a graphical model of a set of possible situations and the possible paths going through them, from the initial situation to the terminal situations. With each situation, there is associated a local uncertainty model that represents beliefs about the next situation. The uncertainty models can be classical, precise probabilities; they can also be of a more general, imprecise probabilistic type, in which case they can be seen as sets of classical probabilities (yielding probability intervals). To work with such event trees, we must combine these local uncertainty models. We show this can be done efficiently by back-propagation through the tree, both for precise and imprecise probabilistic models, and we illustrate this using an imprecise probabilistic counterpart of the classical Markov chain. This allows us to perform a robustness analysis for Markov chains very efficiently.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attraction Pole IAP VI/4 Kickoff meeting, Posters},
  EPRINT     = {1854/LU-1974570},
  EPRINTTYPE = {hdl},
  TITLE      = {Propagating imprecise probabilities through event trees},
  VENUE      = {Louvain-la-Neuve, Belgium},
  YEAR       = {2007},
}

@INPROCEEDINGS{Cooman+HQ-DYSCO09a,
  ABSTRACT   = {We replace strong independence in credal networks with the weaker notion of epistemic irrelevance. Focusing on directed trees, we show how to combine the local credal sets in the networks into an overall joint model, and use this to construct and justify an exact message-passing algorithm that computes updated beliefs for a variable in the network. The algorithm, which is essentially linear in the number of nodes, is formulated entirely in terms of coherent lower previsions. We supply examples of the algorithm's operation, and report an application to on-line character recognition that illustrates the advantages of the model for prediction.},
  AUTHOR     = {Gert de Cooman and Filip Hermans and Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attraction Pole IAP VI/4 DYSCO Study Day, Posters},
  EPRINT     = {1854/LU-1974578},
  EPRINTTYPE = {hdl},
  EVENTDATE  = {2009-05-28},
  TITLE      = {Belief propagation in imprecise Markov trees},
  VENUE      = {Mons, Belgium},
  YEAR       = {2009},
}

@INPROCEEDINGS{Shariatmadar+QC-DYSCO10a,
  AUTHOR     = {Keivan Shariatmadar and Erik Quaeghebeur and Gert de Cooman},
  BOOKTITLE  = {Interuniversity Attaction Pole IAP VI/4-DYSCO, Book of abstracts},
  EPRINT     = {1854/LU-1060040},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {expectation; constrained optimisation; maximality; vacuous; decision theory; maximinity},
  PAGES      = {14–14},
  TITLE      = {Dealing with uncertain constraints in optimisation using decision theory},
  VENUE      = {Ghent, Belgium},
  YEAR       = {2010},
}

@INPROCEEDINGS{Quaeghebeur-DYSCO10a,
  ABSTRACT   = {The standard coherence criterion for lower previsions is expressed using an infinite number of linear constraints. For lower previsions that are essentially defined on some finite set of gambles on a finite possibility space, we present a reformulation of this criterion that only uses a finite number of constraints. Any such lower prevision is coherent if it lies within the convex polytope defined by these constraints. The vertices of this polytope are the extreme coherent lower previsions for the given set of gambles. Our reformulation makes it possible to compute them. We show how this is done and illustrate the procedure and its results.},
  AUTHOR     = {Erik Quaeghebeur},
  BOOKTITLE  = {Interuniversity Attaction Pole IAP VI/4-DYSCO, Book of abstracts},
  EPRINT     = {1854/LU-1974580},
  EPRINTTYPE = {hdl},
  PAGES      = {19–19},
  TITLE      = {Characterizing the set of coherent lower previsions with a finite number of constraints or vertices},
  VENUE      = {Court-St-Etienne, Belgium},
  YEAR       = {2010},
}

@PROCEEDINGS{Klee-SMP63b,
  DATE       = {1963},
  EDITOR     = {Klee, Jr., Victor L.},
  PUBLISHER  = {American Mathematical Society},
  SERIES     = {Proceedings of Symposia in Pure Mathematics},
  TITLE      = {Convexity},
  TITLEADDON = {Proceedings of the Seventh Symposium in Pure Mathematics of the American Mathematical Society},
  URL        = {http://books.google.com/books?id=MuEFJR7Ek4EC},
}

@PROCEEDINGS{-CIM28b,
  DATE      = {1928},
  LOCATION  = {Bologna},
  PUBLISHER = {N. Zanichelli},
  TITLE     = {Atti del congresso internationale dei matematici},
}

@INPROCEEDINGS{Finetti-CIM28p,
  AUTHOR    = {Bruno de Finetti},
  CROSSREF  = {-CIM28b},
  PAGES     = {179–190},
  TITLE     = {Funzione caratteristica di un fenomeno aleatorio},
  VOLUME    = {VI},
}

@PROCEEDINGS{-ICLMPS75b,
  TITLE     = {Fifth International Congress of Logic, Methodology and Philosophy of Science},
  DATE      = {1975},
}

@INPROCEEDINGS{Williams-ICLMPS75p,
  AUTHOR    = {Peter M. Williams},
  CROSSREF  = {-ICLMPS75b},
  PAGES     = {29–33},
  TITLE     = {Coherence, strict coherence and zero probabilities},
  VOLUME    = {VI},
}

@BOOK{Walley-SRIP91b,
  AUTHOR    = {Peter Walley},
  FILE      = {files/Walley-SRIP91b.pdf},
  LOCATION  = {London},
  PUBLISHER = {Chapman \& Hall},
  SERIES    = {Monographs on Statistics and Applied Probability},
  TITLE     = {Statistical reasoning with imprecise probabilities},
  VOLUME    = {42},
  YEAR      = {1991},
}

@BOOK{Pourret+NM-BNPGA08b,
  EDITOR    = {Olivier Pourret and Patrick Naïm and Bruce Marcot},
  ISBN      = {978-0-470-06030-8},
  PUBLISHER = {Wiley},
  TITLE     = {Bayesian networks: a practical guide to applications},
  YEAR      = {2008},
}

@BOOK{Koller+Friedman-PGM09b,
  AUTHOR    = {Daphne Koller and Nir Friedman},
  ISBN      = {978-0-262-01319-2},
  PUBLISHER = {MIT Press},
  SERIES    = {Adaptive Computation and Machine Learning},
  TITLE     = {Probabilistic Graphical Models},
  YEAR      = {2009},
}

@REPORT{Walley+Bernard-CAF99r,
  ANNOTATION  = {geannoteerde kopie},
  AUTHOR      = {Peter Walley and Jean-Marc Bernard},
  INSTITUTION = {Université de Paris 8},
  NUMBER      = {CAF-9901},
  TITLE       = {Imprecise Probabilistic Prediction for Categorical Data},
  TYPE        = {techreport},
  YEAR        = {1999},
}

@REPORT{Quaeghebeur-WLMMEUI04r,
  AUTHOR     = {Erik Quaeghebeur},
  EPRINT     = {1854/LU-1976594},
  EPRINTTYPE = {hdl},
  KEYWORDS   = {Markov model; imprecise Dirichlet model; weak law},
  SERIES     = {Working paper},
  TITLE      = {Weak law for Markov model estimation using the IDM},
  TYPE       = {techreport},
  YEAR       = {2004},
}

@online{Fukuda-polyfaq,
  AUTHOR = {Komei Fukuda},
  DATE   = {2004-06-18},
  TITLE  = {Frequently asked questions in polyhedral computation},
  URL    = {http://www.ifor.math.ethz.ch/~fukuda/polyfaq},
}
